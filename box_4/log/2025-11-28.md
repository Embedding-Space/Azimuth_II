# 2025-11-28 08:05:53

This morning we are trying to fully understand the training step as a set of mathematical operations. We're talking about building a notebook that trains a model through a few steps step-by-step, examining the model's inner state as we go, to fully understand each operation that takes place. My mind has been locked into a sort of particle-physicist mindset. Run a giant experiment, collect lottabytes of data, then spend a year analyzing that data every which way. We don't have to live like that. We can turn the crank on the machine so it advances a single cog at a time and watch everything that happens in as much detail as we care to see. This is our goal for today.

# 2025-11-28 09:36:04

Achieved goal earlier than expected. Turned out to be very easy. Alpha just wrote the notebook (we talked about it first) and then I stepped through it cell by cell. See [dead-token-dynamics.md](/lore/dead-token-dynamics.md) and [dead-token-dynamics.ipynb](/lore/dead-token-dynamics.ipynb).

Have been left with new question. If displacement is antiparallel to h_mean, why does the token cloud move away from the origin in a straight line? Will explore.

# 2025-11-28 14:47:52

Tokens move in straight lines because the Flannel-type model was learning to predict "," and "the" over and over, presumably because they appear in every batch and so are likely to be right sometimes. Alpha called this unigram, I think. Should ask her about that.

We are moving on to Marble. Marble will be series of experients to find interesting LLM architectures. Interesting means:

1. model learns instead of settling into quick equilibrium
2. dead tokens show lifecycle phases
3. fimbulwinter onset is observable
4. h_mean shows real dynamics

Most of this was Alpha's idea.