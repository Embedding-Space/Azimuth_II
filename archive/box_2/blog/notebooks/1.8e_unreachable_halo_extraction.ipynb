{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.8e: Unreachable Token Extraction\n",
    "\n",
    "This notebook extracts and saves the set of unreachable tokens for downstream analysis.\n",
    "\n",
    "## The Question\n",
    "\n",
    "In 1.8d, we discovered:\n",
    "- **3,357 total unreachable tokens** in the vocabulary\n",
    "- **1,934 overlap with cluster** (87.4% of cluster)\n",
    "- **1,423 unreachable tokens OUTSIDE the cluster**\n",
    "\n",
    "**Hypothesis:** The 1,423 form a diffuse halo around the cluster—tokens that escaped the core singularity via early stochastic gradient kicks (bfloat16 cell-hopping) but remained in orbit due to lack of differential training signal.\n",
    "\n",
    "## Method\n",
    "\n",
    "Load 1.8d results and save clean masks/IDs for:\n",
    "1. **All unreachable tokens** (3,357)\n",
    "2. **Unreachable halo** (1,423 outside cluster)\n",
    "3. **Cluster** (2,212 from 1.4h)\n",
    "\n",
    "These will enable three-population visualization in 1.8f."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "MODEL_NAME = \"Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "# Input paths\n",
    "REACHABILITY_PATH = f'../tensors/{MODEL_NAME}/1.8d_full_vocab_reachability.safetensors'\n",
    "CLUSTER_TOKENS_PATH = f'../tensors/{MODEL_NAME}/1.4h_cluster_tokens.safetensors'\n",
    "\n",
    "# Output\n",
    "OUTPUT_PATH = f'../tensors/{MODEL_NAME}/1.8e_unreachable_tokens.safetensors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors.torch import load_file, save_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Reachability Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading reachability data from 1.8d...\n",
      "\n",
      "✓ Loaded reachability data\n",
      "  All unreachable: 3,357 tokens\n",
      "  Unreachable outside cluster: 1,423 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading reachability data from 1.8d...\\n\")\n",
    "\n",
    "reach_data = load_file(REACHABILITY_PATH)\n",
    "\n",
    "all_unreachable = reach_data['all_unreachable']\n",
    "unreachable_outside_cluster = reach_data['unreachable_outside_cluster']\n",
    "\n",
    "print(f\"✓ Loaded reachability data\")\n",
    "print(f\"  All unreachable: {len(all_unreachable):,} tokens\")\n",
    "print(f\"  Unreachable outside cluster: {len(unreachable_outside_cluster):,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cluster Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading cluster tokens from 1.4h...\n",
      "\n",
      "✓ Loaded cluster tokens\n",
      "  Cluster size: 2,212 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoading cluster tokens from 1.4h...\\n\")\n",
    "\n",
    "cluster_data = load_file(CLUSTER_TOKENS_PATH)\n",
    "cluster_token_ids = cluster_data['cluster_token_ids']\n",
    "\n",
    "print(f\"✓ Loaded cluster tokens\")\n",
    "print(f\"  Cluster size: {len(cluster_token_ids):,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vocabulary Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating boolean masks for full vocabulary...\n",
      "\n",
      "Vocabulary size: 151,936 tokens\n",
      "\n",
      "✓ Masks created\n",
      "  Unreachable mask: 3,357 True\n",
      "  Halo mask: 1,423 True\n",
      "  Cluster mask: 2,212 True\n",
      "\n",
      "Validation:\n",
      "  Halo ∩ Cluster: 0 tokens\n",
      "  ✓ Halo and cluster are disjoint (as expected)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCreating boolean masks for full vocabulary...\\n\")\n",
    "\n",
    "# Determine vocabulary size from max token ID\n",
    "vocab_size = max(\n",
    "    all_unreachable.max().item(),\n",
    "    cluster_token_ids.max().item()\n",
    ") + 1\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size:,} tokens\\n\")\n",
    "\n",
    "# Create boolean masks\n",
    "unreachable_mask = torch.zeros(vocab_size, dtype=torch.bool)\n",
    "unreachable_mask[all_unreachable] = True\n",
    "\n",
    "halo_mask = torch.zeros(vocab_size, dtype=torch.bool)\n",
    "halo_mask[unreachable_outside_cluster] = True\n",
    "\n",
    "cluster_mask = torch.zeros(vocab_size, dtype=torch.bool)\n",
    "cluster_mask[cluster_token_ids] = True\n",
    "\n",
    "# Verify mutual exclusivity (halo and cluster should be disjoint)\n",
    "overlap = (halo_mask & cluster_mask).sum().item()\n",
    "\n",
    "print(f\"✓ Masks created\")\n",
    "print(f\"  Unreachable mask: {unreachable_mask.sum().item():,} True\")\n",
    "print(f\"  Halo mask: {halo_mask.sum().item():,} True\")\n",
    "print(f\"  Cluster mask: {cluster_mask.sum().item():,} True\")\n",
    "print(f\"\\nValidation:\")\n",
    "print(f\"  Halo ∩ Cluster: {overlap} tokens\")\n",
    "if overlap == 0:\n",
    "    print(f\"  ✓ Halo and cluster are disjoint (as expected)\")\n",
    "else:\n",
    "    print(f\"  ⚠️  WARNING: Halo and cluster overlap!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SUMMARY: THREE POPULATIONS\n",
      "======================================================================\n",
      "\n",
      "Population breakdown:\n",
      "  1. Cluster (tight singularity): 2,212 tokens (1.46%)\n",
      "  2. Halo (diffuse unreachables): 1,423 tokens (0.94%)\n",
      "  3. Bulk (healthy tokens): 148,579 tokens (97.79%)\n",
      "\n",
      "Total unreachable: 3,357 tokens\n",
      "  = Cluster ∩ Unreachable (tensor([False, False, False,  ..., False, False, False]).sum()) + Halo (1,423)\n",
      "  = 1,934 + 1,423 = 3,357\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SUMMARY: THREE POPULATIONS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "n_cluster = cluster_mask.sum().item()\n",
    "n_halo = halo_mask.sum().item()\n",
    "n_unreachable = unreachable_mask.sum().item()\n",
    "n_bulk = vocab_size - n_unreachable\n",
    "\n",
    "print(f\"Population breakdown:\")\n",
    "print(f\"  1. Cluster (tight singularity): {n_cluster:,} tokens ({100*n_cluster/vocab_size:.2f}%)\")\n",
    "print(f\"  2. Halo (diffuse unreachables): {n_halo:,} tokens ({100*n_halo/vocab_size:.2f}%)\")\n",
    "print(f\"  3. Bulk (healthy tokens): {n_bulk:,} tokens ({100*n_bulk/vocab_size:.2f}%)\")\n",
    "print(f\"\\nTotal unreachable: {n_unreachable:,} tokens\")\n",
    "print(f\"  = Cluster ∩ Unreachable ({cluster_mask & unreachable_mask}.sum()) + Halo ({n_halo:,})\")\n",
    "print(f\"  = {(cluster_mask & unreachable_mask).sum().item():,} + {n_halo:,} = {n_unreachable:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "\n",
      "✓ Saved to ../tensors/Qwen3-4B-Instruct-2507/1.8e_unreachable_tokens.safetensors\n",
      "\n",
      "Saved data:\n",
      "  Token IDs: all_unreachable_ids, halo_token_ids, cluster_token_ids\n",
      "  Masks: unreachable_mask, halo_mask, cluster_mask\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "save_file({\n",
    "    # Token IDs (sorted)\n",
    "    'all_unreachable_ids': all_unreachable,\n",
    "    'halo_token_ids': unreachable_outside_cluster,\n",
    "    'cluster_token_ids': cluster_token_ids,\n",
    "    \n",
    "    # Boolean masks (full vocabulary)\n",
    "    'unreachable_mask': unreachable_mask,\n",
    "    'halo_mask': halo_mask,\n",
    "    'cluster_mask': cluster_mask,\n",
    "}, OUTPUT_PATH)\n",
    "\n",
    "print(f\"✓ Saved to {OUTPUT_PATH}\")\n",
    "print(f\"\\nSaved data:\")\n",
    "print(f\"  Token IDs: all_unreachable_ids, halo_token_ids, cluster_token_ids\")\n",
    "print(f\"  Masks: unreachable_mask, halo_mask, cluster_mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook extracted and saved three token populations:\n",
    "\n",
    "**1. Cluster (2,212 tokens):**\n",
    "- Geometrically collapsed into tight singularity\n",
    "- 87.4% unreachable, 12.6% reachable but untrained\n",
    "- The \"frozen core\"\n",
    "\n",
    "**2. Halo (1,423 tokens):**\n",
    "- Unreachable tokens scattered in space\n",
    "- NOT part of geometric cluster\n",
    "- Hypothesis: escaped core via stochastic kicks but stayed in orbit\n",
    "\n",
    "**3. Bulk (~148k tokens):**\n",
    "- Normal, healthy vocabulary\n",
    "- Reachable by tokenizer, trained on real data\n",
    "- Escaped to live tokens region\n",
    "\n",
    "**Next:** Visualize all three populations in 1.8f to test spatial halo hypothesis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
