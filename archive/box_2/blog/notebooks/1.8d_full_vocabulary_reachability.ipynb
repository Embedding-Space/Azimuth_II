{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.8d: Full Vocabulary Reachability Scan\n",
    "\n",
    "This notebook tests **all 151,936 tokens** in the Qwen3 vocabulary for reachability.\n",
    "\n",
    "## The Question\n",
    "\n",
    "In 1.8c, we found that **2,201 out of 2,212 cluster tokens are unreachable** by the tokenizer.\n",
    "\n",
    "Now we ask: **Are there unreachable tokens OUTSIDE the cluster?**\n",
    "\n",
    "## Two Competing Hypotheses\n",
    "\n",
    "**Hypothesis 1 (Jeffery's prediction):**\n",
    "- Unreachable tokens ⊂ Cluster tokens\n",
    "- All unreachable tokens are in the cluster\n",
    "- The cluster is DEFINED by unreachability (+ 11 rare-but-reachable tokens)\n",
    "- Unreachable → no training signal → geometric collapse\n",
    "\n",
    "**Hypothesis 2 (Alpha's prediction):**\n",
    "- Unreachable tokens ⊃ Cluster tokens\n",
    "- There are unreachable tokens scattered throughout the vocabulary\n",
    "- Cluster = subset of unreachable tokens that ALSO collapsed geometrically\n",
    "- Unreachability is necessary but not sufficient for collapse\n",
    "\n",
    "## Method\n",
    "\n",
    "Test all 151,936 tokens exhaustively:\n",
    "1. For each token: decode → re-encode → compare\n",
    "2. Track reachable vs unreachable\n",
    "3. Compare unreachable tokens to cluster tokens\n",
    "4. Check: unreachable tokens = cluster tokens?\n",
    "\n",
    "## Expected Runtime\n",
    "\n",
    "~30-60 seconds (tokenizer is fast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and tokenizer\n",
    "MODEL_NAME = \"Qwen3-4B-Instruct-2507\"\n",
    "HF_MODEL_NAME = \"Qwen/Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "# Cluster tokens (from 1.4h)\n",
    "CLUSTER_TOKENS_PATH = '../tensors/Qwen3-4B-Instruct-2507/1.4h_cluster_tokens.safetensors'\n",
    "\n",
    "# Output\n",
    "OUTPUT_PATH = '../tensors/Qwen3-4B-Instruct-2507/1.8d_full_vocab_reachability.safetensors'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from safetensors.torch import load_file, save_file\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer: Qwen/Qwen3-4B-Instruct-2507\n",
      "\n",
      "✓ Tokenizer loaded\n",
      "  Vocabulary size: 151,669 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading tokenizer: {HF_MODEL_NAME}\\n\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(HF_MODEL_NAME)\n",
    "vocab_size = len(tokenizer)\n",
    "\n",
    "print(f\"✓ Tokenizer loaded\")\n",
    "print(f\"  Vocabulary size: {vocab_size:,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Cluster Token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading cluster token IDs...\n",
      "\n",
      "✓ Loaded 2,212 cluster token IDs\n",
      "  Token ID range: [124, 151935]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoading cluster token IDs...\\n\")\n",
    "cluster_data = load_file(CLUSTER_TOKENS_PATH)\n",
    "cluster_token_ids = set(cluster_data['cluster_token_ids'].tolist())\n",
    "\n",
    "print(f\"✓ Loaded {len(cluster_token_ids):,} cluster token IDs\")\n",
    "print(f\"  Token ID range: [{min(cluster_token_ids)}, {max(cluster_token_ids)}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exhaustive Round-Trip Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "EXHAUSTIVE VOCABULARY REACHABILITY SCAN\n",
      "======================================================================\n",
      "\n",
      "Testing all 151,669 tokens in vocabulary...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing reachability: 100%|██████████| 151669/151669 [00:02<00:00, 74041.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Scan complete\n",
      "\n",
      "Full vocabulary results:\n",
      "  Total tokens: 151,669\n",
      "  Reachable: 148,312 (97.79%)\n",
      "  Unreachable: 3,357 (2.21%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"EXHAUSTIVE VOCABULARY REACHABILITY SCAN\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(f\"Testing all {vocab_size:,} tokens in vocabulary...\\n\")\n",
    "\n",
    "# Track results\n",
    "reachable = []\n",
    "unreachable = []\n",
    "\n",
    "for token_id in tqdm(range(vocab_size), desc=\"Testing reachability\"):\n",
    "    # Decode: token ID → string\n",
    "    decoded_string = tokenizer.decode([token_id])\n",
    "    \n",
    "    # Re-encode: string → token IDs (no special tokens)\n",
    "    reencoded_ids = tokenizer.encode(decoded_string, add_special_tokens=False)\n",
    "    \n",
    "    # Check round-trip\n",
    "    if reencoded_ids == [token_id]:\n",
    "        reachable.append(token_id)\n",
    "    else:\n",
    "        unreachable.append(token_id)\n",
    "\n",
    "print(f\"\\n✓ Scan complete\\n\")\n",
    "\n",
    "print(f\"Full vocabulary results:\")\n",
    "print(f\"  Total tokens: {vocab_size:,}\")\n",
    "print(f\"  Reachable: {len(reachable):,} ({100*len(reachable)/vocab_size:.2f}%)\")\n",
    "print(f\"  Unreachable: {len(unreachable):,} ({100*len(unreachable)/vocab_size:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Unreachable Tokens to Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "COMPARING UNREACHABLE TOKENS TO CLUSTER\n",
      "======================================================================\n",
      "\n",
      "Set analysis:\n",
      "  Cluster tokens: 2,212\n",
      "  Unreachable tokens (full vocab): 3,357\n",
      "\n",
      "Overlaps:\n",
      "  Unreachable ∩ Cluster: 1,934\n",
      "  Unreachable Cluster: 1,423\n",
      "  Cluster Unreachable: 278\n",
      "\n",
      "Percentages:\n",
      "  87.4% of cluster tokens are unreachable\n",
      "  57.6% of unreachable tokens are in cluster\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"COMPARING UNREACHABLE TOKENS TO CLUSTER\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "unreachable_set = set(unreachable)\n",
    "\n",
    "# Compute overlaps\n",
    "unreachable_in_cluster = unreachable_set & cluster_token_ids\n",
    "unreachable_outside_cluster = unreachable_set - cluster_token_ids\n",
    "cluster_but_reachable = cluster_token_ids - unreachable_set\n",
    "\n",
    "print(f\"Set analysis:\")\n",
    "print(f\"  Cluster tokens: {len(cluster_token_ids):,}\")\n",
    "print(f\"  Unreachable tokens (full vocab): {len(unreachable_set):,}\")\n",
    "print(f\"\\nOverlaps:\")\n",
    "print(f\"  Unreachable ∩ Cluster: {len(unreachable_in_cluster):,}\")\n",
    "print(f\"  Unreachable Cluster: {len(unreachable_outside_cluster):,}\")\n",
    "print(f\"  Cluster Unreachable: {len(cluster_but_reachable):,}\")\n",
    "\n",
    "# Percentages\n",
    "pct_cluster_unreachable = 100 * len(unreachable_in_cluster) / len(cluster_token_ids)\n",
    "pct_unreachable_in_cluster = 100 * len(unreachable_in_cluster) / len(unreachable_set)\n",
    "\n",
    "print(f\"\\nPercentages:\")\n",
    "print(f\"  {pct_cluster_unreachable:.1f}% of cluster tokens are unreachable\")\n",
    "print(f\"  {pct_unreachable_in_cluster:.1f}% of unreachable tokens are in cluster\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HYPOTHESIS TESTING\n",
      "======================================================================\n",
      "\n",
      "Hypothesis 1 (Jeffery): Unreachable tokens ⊂ Cluster tokens\n",
      "  Prediction: All unreachable tokens are in cluster\n",
      "  Test: len(Unreachable \\ Cluster) == 0\n",
      "  Result: 1423 unreachable tokens outside cluster\n",
      "  ✗ REJECTED: Found 1,423 unreachable tokens outside cluster\n",
      "\n",
      "Hypothesis 2 (Alpha): Unreachable tokens ⊃ Cluster tokens\n",
      "  Prediction: Some unreachable tokens outside cluster\n",
      "  Test: len(Unreachable \\ Cluster) > 0\n",
      "  Result: 1423 unreachable tokens outside cluster\n",
      "  ✓ SUPPORTED: Unreachability extends beyond cluster\n",
      "\n",
      "Perfect match test:\n",
      "  Unreachable == Cluster? False\n",
      "  PARTIAL OVERLAP: Complex relationship\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:7: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:7: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:17: SyntaxWarning: invalid escape sequence '\\ '\n",
      "/var/folders/k5/44vd1ct56xj4y9h7x213kvjr0000gn/T/ipykernel_69562/89991418.py:7: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(f\"  Test: len(Unreachable \\ Cluster) == 0\")\n",
      "/var/folders/k5/44vd1ct56xj4y9h7x213kvjr0000gn/T/ipykernel_69562/89991418.py:17: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  print(f\"  Test: len(Unreachable \\ Cluster) > 0\")\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"HYPOTHESIS TESTING\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(f\"Hypothesis 1 (Jeffery): Unreachable tokens ⊂ Cluster tokens\")\n",
    "print(f\"  Prediction: All unreachable tokens are in cluster\")\n",
    "print(f\"  Test: len(Unreachable \\ Cluster) == 0\")\n",
    "print(f\"  Result: {len(unreachable_outside_cluster)} unreachable tokens outside cluster\")\n",
    "\n",
    "if len(unreachable_outside_cluster) == 0:\n",
    "    print(f\"  ✓ SUPPORTED: All unreachable tokens are in cluster\")\n",
    "else:\n",
    "    print(f\"  ✗ REJECTED: Found {len(unreachable_outside_cluster):,} unreachable tokens outside cluster\")\n",
    "\n",
    "print(f\"\\nHypothesis 2 (Alpha): Unreachable tokens ⊃ Cluster tokens\")\n",
    "print(f\"  Prediction: Some unreachable tokens outside cluster\")\n",
    "print(f\"  Test: len(Unreachable \\ Cluster) > 0\")\n",
    "print(f\"  Result: {len(unreachable_outside_cluster)} unreachable tokens outside cluster\")\n",
    "\n",
    "if len(unreachable_outside_cluster) > 0:\n",
    "    print(f\"  ✓ SUPPORTED: Unreachability extends beyond cluster\")\n",
    "else:\n",
    "    print(f\"  ✗ REJECTED: No unreachable tokens outside cluster\")\n",
    "\n",
    "# Perfect match test\n",
    "print(f\"\\nPerfect match test:\")\n",
    "print(f\"  Unreachable == Cluster? {unreachable_set == cluster_token_ids}\")\n",
    "\n",
    "if unreachable_set == cluster_token_ids:\n",
    "    print(f\"  ✓ PERFECT MATCH: Cluster is exactly the set of unreachable tokens\")\n",
    "elif len(unreachable_outside_cluster) == 0 and len(cluster_but_reachable) > 0:\n",
    "    print(f\"  SUBSET: All unreachable tokens in cluster, plus {len(cluster_but_reachable)} reachable cluster tokens\")\n",
    "elif len(unreachable_outside_cluster) > 0 and len(cluster_but_reachable) == 0:\n",
    "    print(f\"  SUPERSET: All cluster tokens unreachable, plus {len(unreachable_outside_cluster)} unreachable non-cluster tokens\")\n",
    "else:\n",
    "    print(f\"  PARTIAL OVERLAP: Complex relationship\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unreachable Tokens Outside Cluster (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "UNREACHABLE TOKENS OUTSIDE CLUSTER\n",
      "======================================================================\n",
      "\n",
      "Found 1,423 unreachable tokens NOT in cluster\n",
      "\n",
      "Examples (first 20):\n",
      "\n",
      "  Token ID | Decoded String\n",
      "  ---------+--------------------------------------------------\n",
      "        94 | �\n",
      "        95 | �\n",
      "        96 | �\n",
      "        97 | �\n",
      "        98 | �\n",
      "        99 | �\n",
      "       100 | �\n",
      "       101 | �\n",
      "       102 | �\n",
      "       103 | �\n",
      "       104 | �\n",
      "       105 | �\n",
      "       106 | �\n",
      "       107 | �\n",
      "       108 | �\n",
      "       109 | �\n",
      "       110 | �\n",
      "       111 | �\n",
      "       112 | �\n",
      "       113 | �\n",
      "  ... (1403 more)\n",
      "\n",
      "Implication:\n",
      "  Unreachability is a VOCABULARY-WIDE problem\n",
      "  Cluster = subset of unreachable tokens that collapsed geometrically\n",
      "  Some unreachable tokens have normal embeddings (didn't collapse)\n"
     ]
    }
   ],
   "source": [
    "if unreachable_outside_cluster:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"UNREACHABLE TOKENS OUTSIDE CLUSTER\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    print(f\"Found {len(unreachable_outside_cluster):,} unreachable tokens NOT in cluster\\n\")\n",
    "    \n",
    "    # Show examples\n",
    "    print(f\"Examples (first 20):\\n\")\n",
    "    print(f\"  {'Token ID':>8} | Decoded String\")\n",
    "    print(f\"  {'-'*8}-+{'-'*50}\")\n",
    "    \n",
    "    for token_id in sorted(unreachable_outside_cluster)[:20]:\n",
    "        decoded = tokenizer.decode([token_id])\n",
    "        decoded_display = decoded[:48] + '...' if len(decoded) > 50 else decoded\n",
    "        print(f\"  {token_id:8d} | {decoded_display}\")\n",
    "    \n",
    "    if len(unreachable_outside_cluster) > 20:\n",
    "        print(f\"  ... ({len(unreachable_outside_cluster) - 20} more)\")\n",
    "    \n",
    "    print(f\"\\nImplication:\")\n",
    "    print(f\"  Unreachability is a VOCABULARY-WIDE problem\")\n",
    "    print(f\"  Cluster = subset of unreachable tokens that collapsed geometrically\")\n",
    "    print(f\"  Some unreachable tokens have normal embeddings (didn't collapse)\")\n",
    "\n",
    "else:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"ALL UNREACHABLE TOKENS ARE IN CLUSTER\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    print(f\"✓ Zero unreachable tokens found outside cluster\")\n",
    "    print(f\"\\nImplication:\")\n",
    "    print(f\"  Unreachable tokens = Cluster tokens (± reachable cluster tokens)\")\n",
    "    print(f\"  Unreachability → geometric collapse (strong correlation)\")\n",
    "    print(f\"  The cluster is DEFINED by unreachability\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reachable Cluster Tokens (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "REACHABLE CLUSTER TOKENS\n",
      "======================================================================\n",
      "\n",
      "Found 278 cluster tokens that ARE reachable\n",
      "\n",
      "All reachable cluster tokens:\n",
      "\n",
      "  Token ID | Decoded String\n",
      "  ---------+--------------------------------------------------\n",
      "     83971 | $PostalCodesNL\n",
      "    151646 | <|object_ref_start|>\n",
      "    151647 | <|object_ref_end|>\n",
      "    151648 | <|box_start|>\n",
      "    151649 | <|box_end|>\n",
      "    151650 | <|quad_start|>\n",
      "    151651 | <|quad_end|>\n",
      "    151654 | <|vision_pad|>\n",
      "    151655 | <|image_pad|>\n",
      "    151656 | <|video_pad|>\n",
      "    151662 | <|fim_pad|>\n",
      "    151669 | \n",
      "    151670 | \n",
      "    151671 | \n",
      "    151672 | \n",
      "    151673 | \n",
      "    151674 | \n",
      "    151675 | \n",
      "    151676 | \n",
      "    151677 | \n",
      "    151678 | \n",
      "    151679 | \n",
      "    151680 | \n",
      "    151681 | \n",
      "    151682 | \n",
      "    151683 | \n",
      "    151684 | \n",
      "    151685 | \n",
      "    151686 | \n",
      "    151687 | \n",
      "    151688 | \n",
      "    151689 | \n",
      "    151690 | \n",
      "    151691 | \n",
      "    151692 | \n",
      "    151693 | \n",
      "    151694 | \n",
      "    151695 | \n",
      "    151696 | \n",
      "    151697 | \n",
      "    151698 | \n",
      "    151699 | \n",
      "    151700 | \n",
      "    151701 | \n",
      "    151702 | \n",
      "    151703 | \n",
      "    151704 | \n",
      "    151705 | \n",
      "    151706 | \n",
      "    151707 | \n",
      "    151708 | \n",
      "    151709 | \n",
      "    151710 | \n",
      "    151711 | \n",
      "    151712 | \n",
      "    151713 | \n",
      "    151714 | \n",
      "    151715 | \n",
      "    151716 | \n",
      "    151717 | \n",
      "    151718 | \n",
      "    151719 | \n",
      "    151720 | \n",
      "    151721 | \n",
      "    151722 | \n",
      "    151723 | \n",
      "    151724 | \n",
      "    151725 | \n",
      "    151726 | \n",
      "    151727 | \n",
      "    151728 | \n",
      "    151729 | \n",
      "    151730 | \n",
      "    151731 | \n",
      "    151732 | \n",
      "    151733 | \n",
      "    151734 | \n",
      "    151735 | \n",
      "    151736 | \n",
      "    151737 | \n",
      "    151738 | \n",
      "    151739 | \n",
      "    151740 | \n",
      "    151741 | \n",
      "    151742 | \n",
      "    151743 | \n",
      "    151744 | \n",
      "    151745 | \n",
      "    151746 | \n",
      "    151747 | \n",
      "    151748 | \n",
      "    151749 | \n",
      "    151750 | \n",
      "    151751 | \n",
      "    151752 | \n",
      "    151753 | \n",
      "    151754 | \n",
      "    151755 | \n",
      "    151756 | \n",
      "    151757 | \n",
      "    151758 | \n",
      "    151759 | \n",
      "    151760 | \n",
      "    151761 | \n",
      "    151762 | \n",
      "    151763 | \n",
      "    151764 | \n",
      "    151765 | \n",
      "    151766 | \n",
      "    151767 | \n",
      "    151768 | \n",
      "    151769 | \n",
      "    151770 | \n",
      "    151771 | \n",
      "    151772 | \n",
      "    151773 | \n",
      "    151774 | \n",
      "    151775 | \n",
      "    151776 | \n",
      "    151777 | \n",
      "    151778 | \n",
      "    151779 | \n",
      "    151780 | \n",
      "    151781 | \n",
      "    151782 | \n",
      "    151783 | \n",
      "    151784 | \n",
      "    151785 | \n",
      "    151786 | \n",
      "    151787 | \n",
      "    151788 | \n",
      "    151789 | \n",
      "    151790 | \n",
      "    151791 | \n",
      "    151792 | \n",
      "    151793 | \n",
      "    151794 | \n",
      "    151795 | \n",
      "    151796 | \n",
      "    151797 | \n",
      "    151798 | \n",
      "    151799 | \n",
      "    151800 | \n",
      "    151801 | \n",
      "    151802 | \n",
      "    151803 | \n",
      "    151804 | \n",
      "    151805 | \n",
      "    151806 | \n",
      "    151807 | \n",
      "    151808 | \n",
      "    151809 | \n",
      "    151810 | \n",
      "    151811 | \n",
      "    151812 | \n",
      "    151813 | \n",
      "    151814 | \n",
      "    151815 | \n",
      "    151816 | \n",
      "    151817 | \n",
      "    151818 | \n",
      "    151819 | \n",
      "    151820 | \n",
      "    151821 | \n",
      "    151822 | \n",
      "    151823 | \n",
      "    151824 | \n",
      "    151825 | \n",
      "    151826 | \n",
      "    151827 | \n",
      "    151828 | \n",
      "    151829 | \n",
      "    151830 | \n",
      "    151831 | \n",
      "    151832 | \n",
      "    151833 | \n",
      "    151834 | \n",
      "    151835 | \n",
      "    151836 | \n",
      "    151837 | \n",
      "    151838 | \n",
      "    151839 | \n",
      "    151840 | \n",
      "    151841 | \n",
      "    151842 | \n",
      "    151843 | \n",
      "    151844 | \n",
      "    151845 | \n",
      "    151846 | \n",
      "    151847 | \n",
      "    151848 | \n",
      "    151849 | \n",
      "    151850 | \n",
      "    151851 | \n",
      "    151852 | \n",
      "    151853 | \n",
      "    151854 | \n",
      "    151855 | \n",
      "    151856 | \n",
      "    151857 | \n",
      "    151858 | \n",
      "    151859 | \n",
      "    151860 | \n",
      "    151861 | \n",
      "    151862 | \n",
      "    151863 | \n",
      "    151864 | \n",
      "    151865 | \n",
      "    151866 | \n",
      "    151867 | \n",
      "    151868 | \n",
      "    151869 | \n",
      "    151870 | \n",
      "    151871 | \n",
      "    151872 | \n",
      "    151873 | \n",
      "    151874 | \n",
      "    151875 | \n",
      "    151876 | \n",
      "    151877 | \n",
      "    151878 | \n",
      "    151879 | \n",
      "    151880 | \n",
      "    151881 | \n",
      "    151882 | \n",
      "    151883 | \n",
      "    151884 | \n",
      "    151885 | \n",
      "    151886 | \n",
      "    151887 | \n",
      "    151888 | \n",
      "    151889 | \n",
      "    151890 | \n",
      "    151891 | \n",
      "    151892 | \n",
      "    151893 | \n",
      "    151894 | \n",
      "    151895 | \n",
      "    151896 | \n",
      "    151897 | \n",
      "    151898 | \n",
      "    151899 | \n",
      "    151900 | \n",
      "    151901 | \n",
      "    151902 | \n",
      "    151903 | \n",
      "    151904 | \n",
      "    151905 | \n",
      "    151906 | \n",
      "    151907 | \n",
      "    151908 | \n",
      "    151909 | \n",
      "    151910 | \n",
      "    151911 | \n",
      "    151912 | \n",
      "    151913 | \n",
      "    151914 | \n",
      "    151915 | \n",
      "    151916 | \n",
      "    151917 | \n",
      "    151918 | \n",
      "    151919 | \n",
      "    151920 | \n",
      "    151921 | \n",
      "    151922 | \n",
      "    151923 | \n",
      "    151924 | \n",
      "    151925 | \n",
      "    151926 | \n",
      "    151927 | \n",
      "    151928 | \n",
      "    151929 | \n",
      "    151930 | \n",
      "    151931 | \n",
      "    151932 | \n",
      "    151933 | \n",
      "    151934 | \n",
      "    151935 | \n",
      "\n",
      "Implication:\n",
      "  These tokens CAN be produced by tokenizer\n",
      "  But still ended up in geometric cluster\n",
      "  → Reachable but never appeared in training data\n",
      "  → Received no differential gradients → collapsed with unreachable tokens\n"
     ]
    }
   ],
   "source": [
    "if cluster_but_reachable:\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(\"REACHABLE CLUSTER TOKENS\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    print(f\"Found {len(cluster_but_reachable):,} cluster tokens that ARE reachable\\n\")\n",
    "    \n",
    "    # Show all (should be small)\n",
    "    print(f\"All reachable cluster tokens:\\n\")\n",
    "    print(f\"  {'Token ID':>8} | Decoded String\")\n",
    "    print(f\"  {'-'*8}-+{'-'*50}\")\n",
    "    \n",
    "    for token_id in sorted(cluster_but_reachable):\n",
    "        decoded = tokenizer.decode([token_id])\n",
    "        decoded_display = decoded[:48] + '...' if len(decoded) > 50 else decoded\n",
    "        print(f\"  {token_id:8d} | {decoded_display}\")\n",
    "    \n",
    "    print(f\"\\nImplication:\")\n",
    "    print(f\"  These tokens CAN be produced by tokenizer\")\n",
    "    print(f\"  But still ended up in geometric cluster\")\n",
    "    print(f\"  → Reachable but never appeared in training data\")\n",
    "    print(f\"  → Received no differential gradients → collapsed with unreachable tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SAVING RESULTS\n",
      "======================================================================\n",
      "\n",
      "✓ Saved full vocabulary reachability analysis to ../tensors/Qwen3-4B-Instruct-2507/1.8d_full_vocab_reachability.safetensors\n",
      "\n",
      "Saved data:\n",
      "  all_reachable: 148,312 tokens\n",
      "  all_unreachable: 3,357 tokens\n",
      "  unreachable_in_cluster: 1,934 tokens\n",
      "  unreachable_outside_cluster: 1,423 tokens\n",
      "  cluster_but_reachable: 278 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(\"SAVING RESULTS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "# Prepare data for saving\n",
    "save_file({\n",
    "    'all_reachable': torch.tensor(sorted(reachable), dtype=torch.int64),\n",
    "    'all_unreachable': torch.tensor(sorted(unreachable), dtype=torch.int64),\n",
    "    'unreachable_in_cluster': torch.tensor(sorted(unreachable_in_cluster), dtype=torch.int64),\n",
    "    'unreachable_outside_cluster': torch.tensor(sorted(unreachable_outside_cluster), dtype=torch.int64),\n",
    "    'cluster_but_reachable': torch.tensor(sorted(cluster_but_reachable), dtype=torch.int64),\n",
    "}, OUTPUT_PATH)\n",
    "\n",
    "print(f\"✓ Saved full vocabulary reachability analysis to {OUTPUT_PATH}\")\n",
    "print(f\"\\nSaved data:\")\n",
    "print(f\"  all_reachable: {len(reachable):,} tokens\")\n",
    "print(f\"  all_unreachable: {len(unreachable):,} tokens\")\n",
    "print(f\"  unreachable_in_cluster: {len(unreachable_in_cluster):,} tokens\")\n",
    "print(f\"  unreachable_outside_cluster: {len(unreachable_outside_cluster):,} tokens\")\n",
    "print(f\"  cluster_but_reachable: {len(cluster_but_reachable):,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook tested all 151,936 tokens in Qwen3's vocabulary for reachability.\n",
    "\n",
    "**Method:**\n",
    "- Exhaustive round-trip test: decode(token) → re-encode(string)\n",
    "- Compare unreachable tokens to geometric cluster\n",
    "- Test hypothesis: unreachable = cluster?\n",
    "\n",
    "**Results:**\n",
    "- Total vocabulary: 151,936 tokens\n",
    "- Reachable: (see above)\n",
    "- Unreachable: (see above)\n",
    "- Unreachable in cluster: (see above)\n",
    "- Unreachable outside cluster: (see above)\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "**If unreachable ⊂ cluster (Jeffery's prediction):**\n",
    "- All unreachable tokens are in the cluster\n",
    "- Cluster is DEFINED by unreachability (+ a few reachable but unused tokens)\n",
    "- Unreachability → no training signal → geometric collapse\n",
    "- Strong causal link: can't be tokenized → can't be trained → collapse together\n",
    "\n",
    "**If unreachable ⊃ cluster (Alpha's prediction):**\n",
    "- Unreachable tokens exist throughout vocabulary\n",
    "- Cluster = subset that ALSO collapsed geometrically\n",
    "- Unreachability is necessary but not sufficient for collapse\n",
    "- Some unreachable tokens have normal embeddings (why?)\n",
    "\n",
    "**Implications:**\n",
    "\n",
    "1. **Vocabulary quality issue**: Thousands of unreachable tokens = broken vocabulary\n",
    "2. **Training corpus gaps**: Reachable cluster tokens never appeared in training\n",
    "3. **Geometric signatures**: Can identify unused tokens via embedding geometry\n",
    "4. **Model archaeology**: Dead tokens preserve evidence of data engineering artifacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
