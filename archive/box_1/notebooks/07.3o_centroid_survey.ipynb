{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07.3o: Centroid Survey\n",
    "\n",
    "**Compute embedding matrix centroids across multiple models**\n",
    "\n",
    "We've discovered that Qwen2.5 and Qwen3 have black holes (dead vocabulary frozen at initialization) that are OFF-AXIS from the main token cloud centroid. The centroid separation in Qwen2.5-3B is 0.202.\n",
    "\n",
    "Question: Is this off-center distribution universal, or specific to Qwen? Do other models (Llama, Gemma, earlier Qwen versions) have centroids near the origin, or do they also show this \"cosmic wind\" bias?\n",
    "\n",
    "This notebook loads a model's embedding matrix and computes:\n",
    "1. Centroid location (mean of all token vectors)\n",
    "2. L2 norm of centroid (distance from origin)\n",
    "3. L∞ norm of centroid (max component magnitude)\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to analyze\n",
    "MODEL_NAME = \"unsloth/Llama-3.2-3B-Instruct\"\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Extract Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: unsloth/Llama-3.2-3B-Instruct\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a43b655b3a453e982c8997db1c5ac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded\n",
      "Embedding matrix shape: torch.Size([128256, 3072])\n",
      "Vocabulary size: 128,256\n",
      "Hidden dimension: 3,072\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading model: {MODEL_NAME}\\n\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "\n",
    "# Extract unembedding matrix (lm_head)\n",
    "gamma = model.lm_head.weight.data.clone().to(torch.float32)\n",
    "vocab_size, hidden_dim = gamma.shape\n",
    "\n",
    "print(f\"✓ Model loaded\")\n",
    "print(f\"Embedding matrix shape: {gamma.shape}\")\n",
    "print(f\"Vocabulary size: {vocab_size:,}\")\n",
    "print(f\"Hidden dimension: {hidden_dim:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid statistics:\n",
      "  Shape: torch.Size([3072])\n",
      "  Mean component: -7.738500e-05\n",
      "  Std component: 7.510118e-03\n",
      "  Min component: -6.513356e-02\n",
      "  Max component: 7.285625e-02\n"
     ]
    }
   ],
   "source": [
    "# Centroid = mean of all token vectors\n",
    "centroid = gamma.mean(dim=0)\n",
    "\n",
    "print(f\"Centroid statistics:\")\n",
    "print(f\"  Shape: {centroid.shape}\")\n",
    "print(f\"  Mean component: {centroid.mean().item():.6e}\")\n",
    "print(f\"  Std component: {centroid.std().item():.6e}\")\n",
    "print(f\"  Min component: {centroid.min().item():.6e}\")\n",
    "print(f\"  Max component: {centroid.max().item():.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Centroid norms:\n",
      "  L2 (Euclidean): 0.416207\n",
      "  L∞ (Chebyshev): 7.285625e-02\n",
      "  L1 (Manhattan): 12.792192\n"
     ]
    }
   ],
   "source": [
    "# L2 norm (Euclidean distance from origin)\n",
    "l2_norm = torch.norm(centroid, p=2).item()\n",
    "\n",
    "# L∞ norm (Chebyshev distance from origin, max component magnitude)\n",
    "l_inf_norm = torch.abs(centroid).max().item()\n",
    "\n",
    "# L1 norm (Manhattan distance)\n",
    "l1_norm = torch.abs(centroid).sum().item()\n",
    "\n",
    "print(f\"\\nCentroid norms:\")\n",
    "print(f\"  L2 (Euclidean): {l2_norm:.6f}\")\n",
    "print(f\"  L∞ (Chebyshev): {l_inf_norm:.6e}\")\n",
    "print(f\"  L1 (Manhattan): {l1_norm:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Typical Token Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token L2 norm distribution:\n",
      "  Mean: 1.086129\n",
      "  Median: 1.090577\n",
      "  Std: 0.113058\n",
      "  Min: 0.622125\n",
      "  Max: 1.469457\n",
      "\n",
      "Centroid L2 norm as fraction of mean token norm: 0.3832\n"
     ]
    }
   ],
   "source": [
    "# Compute L2 norms of all token vectors\n",
    "token_norms = torch.norm(gamma, p=2, dim=1)\n",
    "\n",
    "print(f\"\\nToken L2 norm distribution:\")\n",
    "print(f\"  Mean: {token_norms.mean().item():.6f}\")\n",
    "print(f\"  Median: {token_norms.median().item():.6f}\")\n",
    "print(f\"  Std: {token_norms.std().item():.6f}\")\n",
    "print(f\"  Min: {token_norms.min().item():.6f}\")\n",
    "print(f\"  Max: {token_norms.max().item():.6f}\")\n",
    "\n",
    "# Centroid as fraction of typical token norm\n",
    "mean_token_norm = token_norms.mean().item()\n",
    "centroid_ratio = l2_norm / mean_token_norm\n",
    "\n",
    "print(f\"\\nCentroid L2 norm as fraction of mean token norm: {centroid_ratio:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CENTROID SURVEY SUMMARY\n",
      "================================================================================\n",
      "Model: unsloth/Llama-3.2-3B-Instruct\n",
      "Embedding dimensions: 128,256 × 3,072\n",
      "\n",
      "Centroid L2 norm: 0.416207\n",
      "Centroid L∞ norm: 7.285625e-02\n",
      "Mean token L2 norm: 1.086129\n",
      "Centroid / Token ratio: 0.3832\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"CENTROID SURVEY SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Embedding dimensions: {vocab_size:,} × {hidden_dim:,}\")\n",
    "print()\n",
    "print(f\"Centroid L2 norm: {l2_norm:.6f}\")\n",
    "print(f\"Centroid L∞ norm: {l_inf_norm:.6e}\")\n",
    "print(f\"Mean token L2 norm: {mean_token_norm:.6f}\")\n",
    "print(f\"Centroid / Token ratio: {centroid_ratio:.4f}\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelnel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
