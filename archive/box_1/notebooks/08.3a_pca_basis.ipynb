{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 08.3a: PCA Basis for Trained Embeddings\n",
    "\n",
    "**Compute principal component basis from final trained embedding matrix**\n",
    "\n",
    "After training our tiny transformer, we have a 128×64 embedding matrix that evolved from initialization through 5000 training steps. To visualize the geometry (sky maps, density plots, etc.), we need a coordinate system.\n",
    "\n",
    "This notebook computes all 64 principal components and saves them for use in visualization notebooks.\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: final trained embedding matrix\n",
    "EMBEDDING_PATH = \"../data/embeddings_128vocab_qweninit/step_0005000.safetensors\"\n",
    "\n",
    "# Output: PCA basis (saved alongside embeddings)\n",
    "PCA_BASIS_PATH = \"../data/embeddings_128vocab_qweninit/step_0005000_pca_basis.safetensors\"\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from safetensors.torch import load_file, save_file\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Load Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from: ../data/embeddings_128vocab_qweninit/step_0005000.safetensors\n",
      "\n",
      "✓ Embeddings loaded\n",
      "Shape: torch.Size([128, 64])\n",
      "Vocabulary: 128 tokens\n",
      "Dimensions: 64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading embeddings from: {EMBEDDING_PATH}\\n\")\n",
    "\n",
    "gamma = load_file(EMBEDDING_PATH)['embeddings']\n",
    "vocab_size, hidden_dim = gamma.shape\n",
    "\n",
    "print(f\"✓ Embeddings loaded\")\n",
    "print(f\"Shape: {gamma.shape}\")\n",
    "print(f\"Vocabulary: {vocab_size} tokens\")\n",
    "print(f\"Dimensions: {hidden_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Compute Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Token L2 norms:\n",
      "  Min: 7.527178\n",
      "  Max: 8.430494\n",
      "  Mean: 7.749794\n",
      "  Median: 7.639194\n",
      "\n",
      "Centroid:\n",
      "  L2 norm: 7.731306\n",
      "  As fraction of mean token norm: 0.9976\n"
     ]
    }
   ],
   "source": [
    "# Token norms\n",
    "norms = torch.norm(gamma, p=2, dim=1)\n",
    "\n",
    "# Centroid\n",
    "centroid = gamma.mean(dim=0)\n",
    "centroid_norm = centroid.norm().item()\n",
    "\n",
    "print(f\"\\nToken L2 norms:\")\n",
    "print(f\"  Min: {norms.min().item():.6f}\")\n",
    "print(f\"  Max: {norms.max().item():.6f}\")\n",
    "print(f\"  Mean: {norms.mean().item():.6f}\")\n",
    "print(f\"  Median: {norms.median().item():.6f}\")\n",
    "\n",
    "print(f\"\\nCentroid:\")\n",
    "print(f\"  L2 norm: {centroid_norm:.6f}\")\n",
    "print(f\"  As fraction of mean token norm: {centroid_norm / norms.mean().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Center the Cloud\n",
    "\n",
    "Compute γ' = γ - μ (center at origin for PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centered cloud:\n",
      "  New centroid L2 norm: 5.995414e-07\n",
      "  (Should be ~0)\n"
     ]
    }
   ],
   "source": [
    "gamma_prime = gamma - centroid\n",
    "\n",
    "# Verify centering\n",
    "new_centroid = gamma_prime.mean(dim=0)\n",
    "print(f\"Centered cloud:\")\n",
    "print(f\"  New centroid L2 norm: {new_centroid.norm().item():.6e}\")\n",
    "print(f\"  (Should be ~0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Compute PCA\n",
    "\n",
    "Use SVD to find principal components: γ' = U Σ V^T\n",
    "\n",
    "The columns of V are the principal components (eigenvectors of covariance matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing PCA via SVD...\n",
      "\n",
      "✓ SVD complete\n",
      "Principal components: torch.Size([64, 64])\n",
      "Eigenvalues: torch.Size([64])\n",
      "\n",
      "Variance explained by top components:\n",
      "  PC 1: 66.20%  (cumulative: 66.20%)\n",
      "  PC 2: 10.48%  (cumulative: 76.69%)\n",
      "  PC 3:  5.14%  (cumulative: 81.83%)\n",
      "  PC 4:  3.94%  (cumulative: 85.77%)\n",
      "  PC 5:  3.53%  (cumulative: 89.29%)\n",
      "  PC 6:  1.97%  (cumulative: 91.27%)\n",
      "  PC 7:  1.81%  (cumulative: 93.08%)\n",
      "  PC 8:  1.61%  (cumulative: 94.68%)\n",
      "  PC 9:  1.19%  (cumulative: 95.88%)\n",
      "  PC10:  0.78%  (cumulative: 96.66%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nComputing PCA via SVD...\\n\")\n",
    "\n",
    "# SVD: gamma_prime = U @ diag(S) @ V^T\n",
    "# V columns are principal components\n",
    "U, S, Vt = torch.linalg.svd(gamma_prime, full_matrices=False)\n",
    "\n",
    "# V is Vt transposed\n",
    "V = Vt.T\n",
    "\n",
    "# Eigenvalues are singular values squared, divided by (n-1)\n",
    "eigenvalues = (S ** 2) / (vocab_size - 1)\n",
    "\n",
    "print(f\"✓ SVD complete\")\n",
    "print(f\"Principal components: {V.shape}\")\n",
    "print(f\"Eigenvalues: {eigenvalues.shape}\")\n",
    "\n",
    "# Show variance explained\n",
    "total_variance = eigenvalues.sum()\n",
    "variance_explained = eigenvalues / total_variance\n",
    "cumulative_variance = torch.cumsum(variance_explained, dim=0)\n",
    "\n",
    "print(f\"\\nVariance explained by top components:\")\n",
    "for i in range(min(10, len(eigenvalues))):\n",
    "    print(f\"  PC{i+1:2d}: {100 * variance_explained[i].item():5.2f}%  (cumulative: {100 * cumulative_variance[i].item():5.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Save PCA Basis\n",
    "\n",
    "Save all principal components with string keys ('1', '2', ..., '64') plus eigenvalues and centroid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved PCA basis to: ../data/embeddings_128vocab_qweninit/step_0005000_pca_basis.safetensors\n",
      "\n",
      "Contents:\n",
      "  eigenvalues: torch.Size([64])\n",
      "  centroid: torch.Size([64])\n",
      "  Principal components '1' through '64': each torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Build dictionary with string keys\n",
    "save_dict = {\n",
    "    'eigenvalues': eigenvalues,\n",
    "    'centroid': centroid,\n",
    "}\n",
    "\n",
    "# Add each principal component (clone to avoid shared memory)\n",
    "for i in range(hidden_dim):\n",
    "    save_dict[str(i + 1)] = V[:, i].clone()\n",
    "\n",
    "# Save\n",
    "save_file(save_dict, PCA_BASIS_PATH)\n",
    "\n",
    "print(f\"\\n✓ Saved PCA basis to: {PCA_BASIS_PATH}\")\n",
    "print(f\"\\nContents:\")\n",
    "print(f\"  eigenvalues: {eigenvalues.shape}\")\n",
    "print(f\"  centroid: {centroid.shape}\")\n",
    "print(f\"  Principal components '1' through '{hidden_dim}': each {V[:, 0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Verify Orthonormality\n",
    "\n",
    "Check that principal components are orthonormal (Q^T Q = I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gram matrix (Q^T Q) for first 3 PCs:\n",
      "[[ 9.9999994e-01 -1.6242453e-08 -4.7340816e-08]\n",
      " [-1.6242453e-08  1.0000008e+00 -1.6752810e-07]\n",
      " [-4.7340816e-08 -1.6752810e-07  1.0000005e+00]]\n",
      "\n",
      "(Should be identity matrix)\n",
      "\n",
      "Frobenius norm of (Q^T Q - I): 9.941829e-07\n",
      "(Should be ~0)\n"
     ]
    }
   ],
   "source": [
    "# Check first 3 PCs (the ones we'll use for visualization)\n",
    "Q = V[:, :3]\n",
    "gram = Q.T @ Q\n",
    "\n",
    "print(f\"\\nGram matrix (Q^T Q) for first 3 PCs:\")\n",
    "print(gram.numpy())\n",
    "print(f\"\\n(Should be identity matrix)\")\n",
    "\n",
    "# Check deviation from identity\n",
    "I = torch.eye(3)\n",
    "error = torch.norm(gram - I, p='fro').item()\n",
    "print(f\"\\nFrobenius norm of (Q^T Q - I): {error:.6e}\")\n",
    "print(f\"(Should be ~0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PCA BASIS COMPUTED\n",
      "================================================================================\n",
      "Embedding matrix: 128 tokens × 64 dimensions\n",
      "Centroid L2 norm: 7.731306\n",
      "\n",
      "Principal components: 64\n",
      "Top 3 explain 81.83% of variance\n",
      "\n",
      "Output: ../data/embeddings_128vocab_qweninit/step_0005000_pca_basis.safetensors\n",
      "\n",
      "Ready for visualization with 07.2a (or adapted sky map notebook)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"PCA BASIS COMPUTED\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Embedding matrix: {vocab_size} tokens × {hidden_dim} dimensions\")\n",
    "print(f\"Centroid L2 norm: {centroid_norm:.6f}\")\n",
    "print(f\"\\nPrincipal components: {hidden_dim}\")\n",
    "print(f\"Top 3 explain {100 * cumulative_variance[2].item():.2f}% of variance\")\n",
    "print(f\"\\nOutput: {PCA_BASIS_PATH}\")\n",
    "print(f\"\\nReady for visualization with 07.2a (or adapted sky map notebook)\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
