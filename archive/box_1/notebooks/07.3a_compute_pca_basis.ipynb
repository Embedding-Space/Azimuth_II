{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 07.3a: Compute PCA Basis Vectors\n",
    "\n",
    "**Goal:** Compute complete PCA basis for the centered token cloud and save all 2560 principal components.\n",
    "\n",
    "This notebook:\n",
    "1. Loads centered embedding matrix γ'\n",
    "2. Computes covariance matrix and eigendecomposition\n",
    "3. Saves **all 2560 principal components** in ranked order (descending by variance)\n",
    "4. Saves eigenvalues for variance analysis\n",
    "\n",
    "**Output:** `pca_basis_vectors.safetensors` containing:\n",
    "- Keys '1' through '2560': principal component vectors\n",
    "- Key 'eigenvalues': all 2560 eigenvalues (variance along each PC)\n",
    "\n",
    "**Usage:** Load this basis in 07.2a and specify any three PCs to define your coordinate system:\n",
    "- Standard view: PCs 1, 2, 3 (maximum variance directions)\n",
    "- Alternative view: PCs 10, 11, 12 (lower variance structure)\n",
    "- Noise floor: PCs 2550, 2551, 2552 (minimal variance directions)\n",
    "\n",
    "**Run once:** This is a generator notebook. Run it once to create the basis file, then use 07.2a repeatedly to visualize from different orientations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR_DIR = \"../data/tensors\"\n",
    "\n",
    "# Input: centered embedding matrix\n",
    "INPUT_FILE = \"gamma_centered_qwen3_4b_instruct_2507.safetensors\"\n",
    "INPUT_KEY = \"gamma_centered\"\n",
    "\n",
    "# Output: PCA basis vectors and eigenvalues\n",
    "OUTPUT_FILE = \"pca_basis_vectors.safetensors\"\n",
    "\n",
    "# Random seed (for reproducibility if using approximate methods)\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from safetensors.torch import load_file, save_file\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"Imports loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading centered embedding matrix...\n",
      "  Shape: (151,936, 2,560)\n",
      "  Dtype: torch.float32\n",
      "  Device: cpu\n",
      "\n",
      "Mean vector norm: 3.952082e-08 (should be ~0 if centered)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(TENSOR_DIR)\n",
    "\n",
    "print(\"Loading centered embedding matrix...\")\n",
    "gamma_prime_data = load_file(data_dir / INPUT_FILE)\n",
    "gamma_prime = gamma_prime_data[INPUT_KEY]\n",
    "\n",
    "N, d = gamma_prime.shape\n",
    "\n",
    "print(f\"  Shape: ({N:,}, {d:,})\")\n",
    "print(f\"  Dtype: {gamma_prime.dtype}\")\n",
    "print(f\"  Device: {gamma_prime.device}\")\n",
    "print()\n",
    "\n",
    "# Verify it's actually centered\n",
    "mean_vec = gamma_prime.mean(dim=0)\n",
    "mean_norm = torch.norm(mean_vec).item()\n",
    "print(f\"Mean vector norm: {mean_norm:.6e} (should be ~0 if centered)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Step 2: Compute Covariance Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing covariance matrix...\n",
      "  This will create a (2,560 × 2,560) matrix\n",
      "  Memory required: ~0.03 GB (float32)\n",
      "\n",
      "Covariance matrix computed.\n",
      "  Shape: torch.Size([2560, 2560])\n",
      "  Dtype: torch.float32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing covariance matrix...\")\n",
    "print(f\"  This will create a ({d:,} × {d:,}) matrix\")\n",
    "print(f\"  Memory required: ~{d*d*4 / 1e9:.2f} GB (float32)\")\n",
    "print()\n",
    "\n",
    "# Cov(γ') = (γ')ᵀ γ' / (N-1)\n",
    "Cov = (gamma_prime.T @ gamma_prime) / (N - 1)\n",
    "\n",
    "print(f\"Covariance matrix computed.\")\n",
    "print(f\"  Shape: {Cov.shape}\")\n",
    "print(f\"  Dtype: {Cov.dtype}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Step 3: Eigendecomposition\n",
    "\n",
    "Compute all eigenvalues and eigenvectors of the covariance matrix.\n",
    "\n",
    "**Note:** This is the most computationally expensive step. For a 2560×2560 matrix, this may take several seconds to a minute depending on hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing eigendecomposition...\n",
      "  (This may take 30-60 seconds for 2560×2560 matrix)\n",
      "\n",
      "Eigendecomposition complete.\n",
      "  Eigenvalues shape: torch.Size([2560])\n",
      "  Eigenvectors shape: torch.Size([2560, 2560])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing eigendecomposition...\")\n",
    "print(\"  (This may take 30-60 seconds for 2560×2560 matrix)\")\n",
    "print()\n",
    "\n",
    "# torch.linalg.eigh is for symmetric/Hermitian matrices (faster and more stable)\n",
    "eigenvalues, eigenvectors = torch.linalg.eigh(Cov)\n",
    "\n",
    "print(\"Eigendecomposition complete.\")\n",
    "print(f\"  Eigenvalues shape: {eigenvalues.shape}\")\n",
    "print(f\"  Eigenvectors shape: {eigenvectors.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Step 4: Sort by Variance (Descending)\n",
    "\n",
    "Sort eigenvalues and eigenvectors in descending order so PC1 has the highest variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorting by variance (descending)...\n",
      "  Sorted.\n",
      "\n",
      "Top 10 principal components:\n",
      "  PC   Eigenvalue      Variance %   Cumulative %   \n",
      "  --------------------------------------------------\n",
      "  1    1.048719e-02    0.94         0.94           \n",
      "  2    3.177739e-03    0.28         1.22           \n",
      "  3    2.791374e-03    0.25         1.47           \n",
      "  4    2.616169e-03    0.23         1.71           \n",
      "  5    1.973001e-03    0.18         1.88           \n",
      "  6    1.805293e-03    0.16         2.04           \n",
      "  7    1.609086e-03    0.14         2.19           \n",
      "  8    1.549411e-03    0.14         2.33           \n",
      "  9    1.468294e-03    0.13         2.46           \n",
      "  10   1.389096e-03    0.12         2.58           \n",
      "\n",
      "Bottom 5 principal components:\n",
      "  PC   Eigenvalue      Variance %  \n",
      "  -----------------------------------\n",
      "  2556 5.328412e-05    0.00        \n",
      "  2557 5.124237e-05    0.00        \n",
      "  2558 3.992779e-05    0.00        \n",
      "  2559 1.252859e-05    0.00        \n",
      "  2560 9.613870e-06    0.00        \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sorting by variance (descending)...\")\n",
    "\n",
    "# torch.linalg.eigh returns eigenvalues in ascending order, so flip\n",
    "eigenvalues = eigenvalues.flip(0)\n",
    "eigenvectors = eigenvectors.flip(1)  # Flip columns\n",
    "\n",
    "print(\"  Sorted.\")\n",
    "print()\n",
    "\n",
    "# Report statistics\n",
    "total_variance = eigenvalues.sum()\n",
    "\n",
    "print(\"Top 10 principal components:\")\n",
    "print(f\"  {'PC':<4} {'Eigenvalue':<15} {'Variance %':<12} {'Cumulative %':<15}\")\n",
    "print(\"  \" + \"-\" * 50)\n",
    "\n",
    "cumulative = 0.0\n",
    "for i in range(10):\n",
    "    var_explained = eigenvalues[i] / total_variance\n",
    "    cumulative += var_explained\n",
    "    print(f\"  {i+1:<4} {eigenvalues[i].item():<15.6e} {var_explained.item()*100:<12.2f} {cumulative.item()*100:<15.2f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Bottom 5 principal components:\")\n",
    "print(f\"  {'PC':<4} {'Eigenvalue':<15} {'Variance %':<12}\")\n",
    "print(\"  \" + \"-\" * 35)\n",
    "\n",
    "for i in range(5):\n",
    "    pc_idx = d - 5 + i\n",
    "    var_explained = eigenvalues[pc_idx] / total_variance\n",
    "    print(f\"  {pc_idx+1:<4} {eigenvalues[pc_idx].item():<15.6e} {var_explained.item()*100:<12.2f}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Step 5: Verify Orthonormality\n",
    "\n",
    "Sanity check: eigenvectors should be orthonormal by construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying orthonormality of first 3 PCs...\n",
      "  Dot products (should be ~0):\n",
      "    PC1 · PC2: 1.618173e-07\n",
      "    PC1 · PC3: 3.725290e-09\n",
      "    PC2 · PC3: 1.713634e-07\n",
      "\n",
      "  Norms (should be ~1):\n",
      "    ||PC1||: 1.000000\n",
      "    ||PC2||: 0.999999\n",
      "    ||PC3||: 1.000000\n",
      "\n",
      "✓ Basis is orthonormal.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying orthonormality of first 3 PCs...\")\n",
    "\n",
    "pc1 = eigenvectors[:, 0]\n",
    "pc2 = eigenvectors[:, 1]\n",
    "pc3 = eigenvectors[:, 2]\n",
    "\n",
    "# Dot products (should be ~0 for orthogonality)\n",
    "dot_12 = (pc1 @ pc2).item()\n",
    "dot_13 = (pc1 @ pc3).item()\n",
    "dot_23 = (pc2 @ pc3).item()\n",
    "\n",
    "# Norms (should be ~1)\n",
    "norm_1 = torch.norm(pc1).item()\n",
    "norm_2 = torch.norm(pc2).item()\n",
    "norm_3 = torch.norm(pc3).item()\n",
    "\n",
    "print(f\"  Dot products (should be ~0):\")\n",
    "print(f\"    PC1 · PC2: {dot_12:.6e}\")\n",
    "print(f\"    PC1 · PC3: {dot_13:.6e}\")\n",
    "print(f\"    PC2 · PC3: {dot_23:.6e}\")\n",
    "print()\n",
    "print(f\"  Norms (should be ~1):\")\n",
    "print(f\"    ||PC1||: {norm_1:.6f}\")\n",
    "print(f\"    ||PC2||: {norm_2:.6f}\")\n",
    "print(f\"    ||PC3||: {norm_3:.6f}\")\n",
    "print()\n",
    "\n",
    "# Overall check\n",
    "max_dot = max(abs(dot_12), abs(dot_13), abs(dot_23))\n",
    "max_norm_error = max(abs(norm_1 - 1), abs(norm_2 - 1), abs(norm_3 - 1))\n",
    "\n",
    "if max_dot < 1e-5 and max_norm_error < 1e-5:\n",
    "    print(\"✓ Basis is orthonormal.\")\n",
    "else:\n",
    "    print(\"⚠ Warning: Basis may not be perfectly orthonormal.\")\n",
    "    print(f\"  Max dot product: {max_dot:.6e}\")\n",
    "    print(f\"  Max norm error: {max_norm_error:.6e}\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Step 6: Save All Principal Components\n",
    "\n",
    "Save all 2560 principal components to safetensors with string keys '1' through '2560'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing to save all principal components...\n",
      "  Prepared 2,560 principal components + eigenvalues\n",
      "  Total keys: 2,561\n",
      "\n",
      "Saving to ../data/tensors/pca_basis_vectors.safetensors...\n",
      "✓ Saved successfully.\n",
      "\n",
      "File size: 26.41 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing to save all principal components...\")\n",
    "\n",
    "# Build dictionary with string keys\n",
    "save_dict = {}\n",
    "\n",
    "for i in range(d):\n",
    "    pc_idx = i + 1  # 1-indexed\n",
    "    pc_vector = eigenvectors[:, i]\n",
    "    save_dict[str(pc_idx)] = pc_vector\n",
    "\n",
    "# Add eigenvalues\n",
    "save_dict['eigenvalues'] = eigenvalues\n",
    "\n",
    "print(f\"  Prepared {d:,} principal components + eigenvalues\")\n",
    "print(f\"  Total keys: {len(save_dict):,}\")\n",
    "print()\n",
    "\n",
    "# Save to file\n",
    "output_path = data_dir / OUTPUT_FILE\n",
    "print(f\"Saving to {output_path}...\")\n",
    "\n",
    "save_file(save_dict, output_path)\n",
    "\n",
    "print(f\"✓ Saved successfully.\")\n",
    "print()\n",
    "\n",
    "# Report file size\n",
    "file_size_mb = output_path.stat().st_size / 1e6\n",
    "print(f\"File size: {file_size_mb:.2f} MB\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Step 7: Verification - Load and Check\n",
    "\n",
    "Verify we can load the saved basis successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying saved file...\n",
      "  Total keys in file: 2561\n",
      "\n",
      "Checking sample principal components:\n",
      "  PC1: shape torch.Size([2560]), norm 1.000000\n",
      "  PC10: shape torch.Size([2560]), norm 1.000000\n",
      "  PC100: shape torch.Size([2560]), norm 1.000000\n",
      "  PC1000: shape torch.Size([2560]), norm 1.000000\n",
      "  PC2560: shape torch.Size([2560]), norm 1.000000\n",
      "\n",
      "Eigenvalues: shape torch.Size([2560])\n",
      "  First 3: [0.010487192310392857, 0.0031777385156601667, 0.0027913739904761314]\n",
      "  Last 3: [3.992778874817304e-05, 1.2528589650173672e-05, 9.613870133762248e-06]\n",
      "\n",
      "✓ Verification complete.\n"
     ]
    }
   ],
   "source": [
    "print(\"Verifying saved file...\")\n",
    "\n",
    "# Load back\n",
    "loaded = load_file(output_path)\n",
    "\n",
    "print(f\"  Total keys in file: {len(loaded)}\")\n",
    "print()\n",
    "\n",
    "# Check a few random PCs\n",
    "test_indices = [1, 10, 100, 1000, 2560]\n",
    "print(\"Checking sample principal components:\")\n",
    "for idx in test_indices:\n",
    "    key = str(idx)\n",
    "    if key in loaded:\n",
    "        vec = loaded[key]\n",
    "        norm = torch.norm(vec).item()\n",
    "        print(f\"  PC{idx}: shape {vec.shape}, norm {norm:.6f}\")\n",
    "    else:\n",
    "        print(f\"  PC{idx}: ⚠ NOT FOUND\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Check eigenvalues\n",
    "if 'eigenvalues' in loaded:\n",
    "    eigs = loaded['eigenvalues']\n",
    "    print(f\"Eigenvalues: shape {eigs.shape}\")\n",
    "    print(f\"  First 3: {eigs[:3].tolist()}\")\n",
    "    print(f\"  Last 3: {eigs[-3:].tolist()}\")\n",
    "else:\n",
    "    print(\"⚠ Eigenvalues NOT FOUND\")\n",
    "\n",
    "print()\n",
    "print(\"✓ Verification complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PCA BASIS GENERATION COMPLETE\n",
      "============================================================\n",
      "\n",
      "Input: gamma_centered_qwen3_4b_instruct_2507.safetensors\n",
      "  Tokens: 151,936\n",
      "  Dimensions: 2,560\n",
      "\n",
      "Output: pca_basis_vectors.safetensors\n",
      "  Principal components: 2,560 (keys '1' through '2560')\n",
      "  Eigenvalues: (key 'eigenvalues')\n",
      "  File size: 26.41 MB\n",
      "\n",
      "Variance summary:\n",
      "  Top 3 PCs explain 1.47% of variance\n",
      "  Top 10 PCs explain 2.58% of variance\n",
      "  Top 100 PCs explain 10.16% of variance\n",
      "\n",
      "Usage in 07.2a:\n",
      "  BASIS_FILE = 'pca_basis_vectors.safetensors'\n",
      "  BASIS_KEYS = {\n",
      "      'north': '1',      # PC1 (highest variance)\n",
      "      'meridian': '2',   # PC2\n",
      "      'equinox': '3'     # PC3\n",
      "  }\n",
      "\n",
      "  Or try different orientations:\n",
      "  BASIS_KEYS = {'north': '10', 'meridian': '11', 'equinox': '12'}\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"PCA BASIS GENERATION COMPLETE\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "print(f\"Input: {INPUT_FILE}\")\n",
    "print(f\"  Tokens: {N:,}\")\n",
    "print(f\"  Dimensions: {d:,}\")\n",
    "print()\n",
    "print(f\"Output: {OUTPUT_FILE}\")\n",
    "print(f\"  Principal components: {d:,} (keys '1' through '{d}')\")\n",
    "print(f\"  Eigenvalues: (key 'eigenvalues')\")\n",
    "print(f\"  File size: {file_size_mb:.2f} MB\")\n",
    "print()\n",
    "print(\"Variance summary:\")\n",
    "print(f\"  Top 3 PCs explain {(eigenvalues[:3].sum() / total_variance * 100).item():.2f}% of variance\")\n",
    "print(f\"  Top 10 PCs explain {(eigenvalues[:10].sum() / total_variance * 100).item():.2f}% of variance\")\n",
    "print(f\"  Top 100 PCs explain {(eigenvalues[:100].sum() / total_variance * 100).item():.2f}% of variance\")\n",
    "print()\n",
    "print(\"Usage in 07.2a:\")\n",
    "print(\"  BASIS_FILE = 'pca_basis_vectors.safetensors'\")\n",
    "print(\"  BASIS_KEYS = {\")\n",
    "print(\"      'north': '1',      # PC1 (highest variance)\")\n",
    "print(\"      'meridian': '2',   # PC2\")\n",
    "print(\"      'equinox': '3'     # PC3\")\n",
    "print(\"  }\")\n",
    "print()\n",
    "print(\"  Or try different orientations:\")\n",
    "print(\"  BASIS_KEYS = {'north': '10', 'meridian': '11', 'equinox': '12'}\")\n",
    "print()\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
