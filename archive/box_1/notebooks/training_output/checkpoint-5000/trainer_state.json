{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.6019744762822057,
  "eval_steps": 500,
  "global_step": 5000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.012039489525644112,
      "grad_norm": 0.212890625,
      "learning_rate": 0.0009802,
      "loss": 3.3351,
      "step": 100
    },
    {
      "epoch": 0.024078979051288224,
      "grad_norm": 0.185546875,
      "learning_rate": 0.0009602,
      "loss": 3.079,
      "step": 200
    },
    {
      "epoch": 0.036118468576932336,
      "grad_norm": 0.33203125,
      "learning_rate": 0.0009402000000000001,
      "loss": 3.0137,
      "step": 300
    },
    {
      "epoch": 0.04815795810257645,
      "grad_norm": 0.48046875,
      "learning_rate": 0.0009202,
      "loss": 2.9018,
      "step": 400
    },
    {
      "epoch": 0.06019744762822056,
      "grad_norm": 0.3046875,
      "learning_rate": 0.0009002,
      "loss": 2.8546,
      "step": 500
    },
    {
      "epoch": 0.07223693715386467,
      "grad_norm": 0.2431640625,
      "learning_rate": 0.0008802,
      "loss": 2.8313,
      "step": 600
    },
    {
      "epoch": 0.08427642667950878,
      "grad_norm": 0.287109375,
      "learning_rate": 0.0008602,
      "loss": 2.8055,
      "step": 700
    },
    {
      "epoch": 0.0963159162051529,
      "grad_norm": 0.44921875,
      "learning_rate": 0.0008401999999999999,
      "loss": 2.7772,
      "step": 800
    },
    {
      "epoch": 0.10835540573079701,
      "grad_norm": 0.65234375,
      "learning_rate": 0.0008202000000000001,
      "loss": 2.7505,
      "step": 900
    },
    {
      "epoch": 0.12039489525644112,
      "grad_norm": 0.7265625,
      "learning_rate": 0.0008002,
      "loss": 2.7167,
      "step": 1000
    },
    {
      "epoch": 0.13243438478208525,
      "grad_norm": 0.62109375,
      "learning_rate": 0.0007802,
      "loss": 2.6878,
      "step": 1100
    },
    {
      "epoch": 0.14447387430772934,
      "grad_norm": 0.7421875,
      "learning_rate": 0.0007602,
      "loss": 2.6568,
      "step": 1200
    },
    {
      "epoch": 0.15651336383337347,
      "grad_norm": 0.828125,
      "learning_rate": 0.0007402,
      "loss": 2.6215,
      "step": 1300
    },
    {
      "epoch": 0.16855285335901757,
      "grad_norm": 0.921875,
      "learning_rate": 0.0007201999999999999,
      "loss": 2.5962,
      "step": 1400
    },
    {
      "epoch": 0.1805923428846617,
      "grad_norm": 1.015625,
      "learning_rate": 0.0007002000000000001,
      "loss": 2.5684,
      "step": 1500
    },
    {
      "epoch": 0.1926318324103058,
      "grad_norm": 0.88671875,
      "learning_rate": 0.0006802,
      "loss": 2.5439,
      "step": 1600
    },
    {
      "epoch": 0.20467132193594992,
      "grad_norm": 0.97265625,
      "learning_rate": 0.0006602,
      "loss": 2.5238,
      "step": 1700
    },
    {
      "epoch": 0.21671081146159402,
      "grad_norm": 1.2265625,
      "learning_rate": 0.0006402000000000001,
      "loss": 2.5088,
      "step": 1800
    },
    {
      "epoch": 0.22875030098723814,
      "grad_norm": 1.421875,
      "learning_rate": 0.0006202,
      "loss": 2.4867,
      "step": 1900
    },
    {
      "epoch": 0.24078979051288224,
      "grad_norm": 1.3671875,
      "learning_rate": 0.0006002,
      "loss": 2.4769,
      "step": 2000
    },
    {
      "epoch": 0.2528292800385264,
      "grad_norm": 1.203125,
      "learning_rate": 0.0005802,
      "loss": 2.471,
      "step": 2100
    },
    {
      "epoch": 0.2648687695641705,
      "grad_norm": 1.2109375,
      "learning_rate": 0.0005602000000000001,
      "loss": 2.4494,
      "step": 2200
    },
    {
      "epoch": 0.2769082590898146,
      "grad_norm": 1.140625,
      "learning_rate": 0.0005402,
      "loss": 2.4474,
      "step": 2300
    },
    {
      "epoch": 0.2889477486154587,
      "grad_norm": 1.71875,
      "learning_rate": 0.0005202,
      "loss": 2.4374,
      "step": 2400
    },
    {
      "epoch": 0.30098723814110284,
      "grad_norm": 1.3515625,
      "learning_rate": 0.0005002,
      "loss": 2.4284,
      "step": 2500
    },
    {
      "epoch": 0.31302672766674694,
      "grad_norm": 1.390625,
      "learning_rate": 0.0004802,
      "loss": 2.4223,
      "step": 2600
    },
    {
      "epoch": 0.32506621719239104,
      "grad_norm": 1.3984375,
      "learning_rate": 0.0004602,
      "loss": 2.4187,
      "step": 2700
    },
    {
      "epoch": 0.33710570671803514,
      "grad_norm": 1.890625,
      "learning_rate": 0.00044019999999999997,
      "loss": 2.4002,
      "step": 2800
    },
    {
      "epoch": 0.3491451962436793,
      "grad_norm": 2.046875,
      "learning_rate": 0.0004202,
      "loss": 2.3986,
      "step": 2900
    },
    {
      "epoch": 0.3611846857693234,
      "grad_norm": 1.5703125,
      "learning_rate": 0.0004002,
      "loss": 2.3908,
      "step": 3000
    },
    {
      "epoch": 0.3732241752949675,
      "grad_norm": 1.4296875,
      "learning_rate": 0.00038019999999999997,
      "loss": 2.3829,
      "step": 3100
    },
    {
      "epoch": 0.3852636648206116,
      "grad_norm": 1.71875,
      "learning_rate": 0.00036020000000000003,
      "loss": 2.389,
      "step": 3200
    },
    {
      "epoch": 0.39730315434625574,
      "grad_norm": 1.4921875,
      "learning_rate": 0.00034020000000000003,
      "loss": 2.3863,
      "step": 3300
    },
    {
      "epoch": 0.40934264387189984,
      "grad_norm": 1.9140625,
      "learning_rate": 0.0003202,
      "loss": 2.3822,
      "step": 3400
    },
    {
      "epoch": 0.42138213339754393,
      "grad_norm": 1.359375,
      "learning_rate": 0.00030020000000000003,
      "loss": 2.3818,
      "step": 3500
    },
    {
      "epoch": 0.43342162292318803,
      "grad_norm": 1.375,
      "learning_rate": 0.00028020000000000003,
      "loss": 2.3792,
      "step": 3600
    },
    {
      "epoch": 0.4454611124488322,
      "grad_norm": 1.34375,
      "learning_rate": 0.0002602,
      "loss": 2.3786,
      "step": 3700
    },
    {
      "epoch": 0.4575006019744763,
      "grad_norm": 1.984375,
      "learning_rate": 0.0002402,
      "loss": 2.3757,
      "step": 3800
    },
    {
      "epoch": 0.4695400915001204,
      "grad_norm": 1.6171875,
      "learning_rate": 0.0002202,
      "loss": 2.3695,
      "step": 3900
    },
    {
      "epoch": 0.4815795810257645,
      "grad_norm": 1.59375,
      "learning_rate": 0.0002002,
      "loss": 2.3652,
      "step": 4000
    },
    {
      "epoch": 0.49361907055140863,
      "grad_norm": 1.5234375,
      "learning_rate": 0.00018020000000000002,
      "loss": 2.3592,
      "step": 4100
    },
    {
      "epoch": 0.5056585600770528,
      "grad_norm": 1.7109375,
      "learning_rate": 0.00016020000000000002,
      "loss": 2.3628,
      "step": 4200
    },
    {
      "epoch": 0.5176980496026968,
      "grad_norm": 1.578125,
      "learning_rate": 0.0001402,
      "loss": 2.3682,
      "step": 4300
    },
    {
      "epoch": 0.529737539128341,
      "grad_norm": 1.3828125,
      "learning_rate": 0.00012020000000000001,
      "loss": 2.3678,
      "step": 4400
    },
    {
      "epoch": 0.541777028653985,
      "grad_norm": 1.3515625,
      "learning_rate": 0.0001002,
      "loss": 2.3631,
      "step": 4500
    },
    {
      "epoch": 0.5538165181796292,
      "grad_norm": 1.796875,
      "learning_rate": 8.02e-05,
      "loss": 2.3599,
      "step": 4600
    },
    {
      "epoch": 0.5658560077052733,
      "grad_norm": 1.4921875,
      "learning_rate": 6.02e-05,
      "loss": 2.3629,
      "step": 4700
    },
    {
      "epoch": 0.5778954972309174,
      "grad_norm": 1.4453125,
      "learning_rate": 4.02e-05,
      "loss": 2.3578,
      "step": 4800
    },
    {
      "epoch": 0.5899349867565615,
      "grad_norm": 1.5,
      "learning_rate": 2.02e-05,
      "loss": 2.3598,
      "step": 4900
    },
    {
      "epoch": 0.6019744762822057,
      "grad_norm": 1.34375,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 2.3536,
      "step": 5000
    }
  ],
  "logging_steps": 100,
  "max_steps": 5000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 10000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 12299796480000.0,
  "train_batch_size": 32,
  "trial_name": null,
  "trial_params": null
}
