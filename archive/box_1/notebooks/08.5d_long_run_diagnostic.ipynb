{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08.5d: Long Run Diagnostic\n",
    "\n",
    "**Quick diagnostic check for late-stage black hole fission**\n",
    "\n",
    "This notebook loads the final snapshot from a long training run and checks:\n",
    "- How many black holes exist at the end?\n",
    "- What is the total population in black holes?\n",
    "- What is the size of the largest black hole?\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "If bfloat16 diffusion causes late-stage fission, we expect:\n",
    "- **Multiple black holes** at step 100,000 (not just 1)\n",
    "- **Total population ‚âà 51** (the dead tokens)\n",
    "- **Fragment sizes < 51** (the original cluster broke apart)\n",
    "\n",
    "If we see this, we've confirmed that dead tokens can spontaneously fragment over long training times.\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to analyze\n",
    "DATA_DIR = \"../data\"\n",
    "RUN_NAME = \"embeddings_128vocab_qweninit_run_1001\"\n",
    "EMBEDDING_FILE = \"embedding_evolution.safetensors\"\n",
    "EMBEDDING_KEY = \"embedding_history\"\n",
    "\n",
    "# Black hole detection\n",
    "BLACK_HOLE_THRESHOLD = 1e-10  # Chebyshev distance threshold for bit-identical\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from safetensors.torch import load_file\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Union-Find for Black Hole Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Union-Find functions defined\n"
     ]
    }
   ],
   "source": [
    "class UnionFind:\n",
    "    \"\"\"Union-Find data structure for finding connected components.\"\"\"\n",
    "    def __init__(self, n):\n",
    "        self.parent = list(range(n))\n",
    "        self.rank = [0] * n\n",
    "    \n",
    "    def find(self, x):\n",
    "        if self.parent[x] != x:\n",
    "            self.parent[x] = self.find(self.parent[x])  # Path compression\n",
    "        return self.parent[x]\n",
    "    \n",
    "    def union(self, x, y):\n",
    "        root_x = self.find(x)\n",
    "        root_y = self.find(y)\n",
    "        \n",
    "        if root_x == root_y:\n",
    "            return\n",
    "        \n",
    "        # Union by rank\n",
    "        if self.rank[root_x] < self.rank[root_y]:\n",
    "            self.parent[root_x] = root_y\n",
    "        elif self.rank[root_x] > self.rank[root_y]:\n",
    "            self.parent[root_y] = root_x\n",
    "        else:\n",
    "            self.parent[root_y] = root_x\n",
    "            self.rank[root_x] += 1\n",
    "    \n",
    "    def get_components(self):\n",
    "        \"\"\"Return list of connected components (each component is a list of indices).\"\"\"\n",
    "        components = defaultdict(list)\n",
    "        for i in range(len(self.parent)):\n",
    "            root = self.find(i)\n",
    "            components[root].append(i)\n",
    "        return list(components.values())\n",
    "\n",
    "\n",
    "def find_black_holes(embeddings, threshold):\n",
    "    \"\"\"\n",
    "    Find black holes in an embedding matrix.\n",
    "    \n",
    "    Args:\n",
    "        embeddings: (vocab_size, hidden_dim) tensor\n",
    "        threshold: Chebyshev distance threshold for considering tokens identical\n",
    "    \n",
    "    Returns:\n",
    "        black_holes: list of lists, each sublist contains token IDs in a black hole\n",
    "    \"\"\"\n",
    "    n = embeddings.shape[0]\n",
    "    \n",
    "    # Compute pairwise Chebyshev distances\n",
    "    diff = embeddings.unsqueeze(0) - embeddings.unsqueeze(1)  # (n, n, d)\n",
    "    distances = torch.abs(diff).max(dim=2)[0]  # (n, n)\n",
    "    \n",
    "    # Build adjacency graph\n",
    "    adjacency = (distances < threshold)\n",
    "    \n",
    "    # Union-Find\n",
    "    uf = UnionFind(n)\n",
    "    triu_indices = torch.triu_indices(n, n, offset=1)\n",
    "    adjacent_pairs = triu_indices[:, adjacency[triu_indices[0], triu_indices[1]]]\n",
    "    \n",
    "    for k in range(adjacent_pairs.shape[1]):\n",
    "        i, j = adjacent_pairs[0, k].item(), adjacent_pairs[1, k].item()\n",
    "        uf.union(i, j)\n",
    "    \n",
    "    # Get components with population ‚â• 2\n",
    "    components = uf.get_components()\n",
    "    black_holes = [comp for comp in components if len(comp) >= 2]\n",
    "    \n",
    "    return black_holes\n",
    "\n",
    "\n",
    "print(\"‚úì Union-Find functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Final Snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from: ../data/embeddings_128vocab_qweninit_run_1001/embedding_evolution.safetensors\n",
      "File size: 1.64 GB\n",
      "\n",
      "Shape: torch.Size([100001, 128, 64])\n",
      "dtype: torch.bfloat16\n",
      "\n",
      "‚úì Loaded 100001 snapshots\n"
     ]
    }
   ],
   "source": [
    "run_dir = Path(DATA_DIR) / RUN_NAME\n",
    "embedding_path = run_dir / EMBEDDING_FILE\n",
    "\n",
    "if not embedding_path.exists():\n",
    "    raise FileNotFoundError(f\"Embedding file not found: {embedding_path}\")\n",
    "\n",
    "print(f\"Loading embeddings from: {embedding_path}\")\n",
    "print(f\"File size: {embedding_path.stat().st_size / 1e9:.2f} GB\\n\")\n",
    "\n",
    "# Load full history\n",
    "data = load_file(embedding_path)\n",
    "embedding_history = data[EMBEDDING_KEY]\n",
    "\n",
    "print(f\"Shape: {embedding_history.shape}\")\n",
    "print(f\"dtype: {embedding_history.dtype}\")\n",
    "print(f\"\\n‚úì Loaded {embedding_history.shape[0]} snapshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Final State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing step 100000...\n",
      "\n",
      "================================================================================\n",
      "FINAL STATE (Step 100000)\n",
      "================================================================================\n",
      "\n",
      "Number of black holes: 1\n",
      "Total population in black holes: 51\n",
      "Largest black hole size: 51\n",
      "\n",
      "Black hole size distribution: [51]\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Get the last step\n",
    "final_step = embedding_history.shape[0] - 1\n",
    "final_embeddings = embedding_history[final_step].float()  # Convert to float for computation\n",
    "\n",
    "print(f\"Analyzing step {final_step}...\\n\")\n",
    "\n",
    "# Find black holes\n",
    "black_holes = find_black_holes(final_embeddings, BLACK_HOLE_THRESHOLD)\n",
    "\n",
    "# Compute statistics\n",
    "num_black_holes = len(black_holes)\n",
    "total_population = sum(len(bh) for bh in black_holes)\n",
    "largest_bh_size = max((len(bh) for bh in black_holes), default=0)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"FINAL STATE (Step {final_step})\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Number of black holes: {num_black_holes}\")\n",
    "print(f\"Total population in black holes: {total_population}\")\n",
    "print(f\"Largest black hole size: {largest_bh_size}\")\n",
    "\n",
    "if num_black_holes > 0:\n",
    "    sizes = sorted([len(bh) for bh in black_holes], reverse=True)\n",
    "    print(f\"\\nBlack hole size distribution: {sizes}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "INTERPRETATION:\n",
      "\n",
      "‚ö†Ô∏è  Single black hole detected.\n",
      "   Dead token cluster remained intact.\n",
      "   NO late-stage fission observed.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nINTERPRETATION:\\n\")\n",
    "\n",
    "if num_black_holes == 0:\n",
    "    print(\"‚ùå No black holes detected.\")\n",
    "    print(\"   All tokens have separated into singletons.\")\n",
    "    print(\"   Complete evaporation occurred.\")\n",
    "\n",
    "elif num_black_holes == 1:\n",
    "    print(\"‚ö†Ô∏è  Single black hole detected.\")\n",
    "    if total_population >= 50:\n",
    "        print(\"   Dead token cluster remained intact.\")\n",
    "        print(\"   NO late-stage fission observed.\")\n",
    "    else:\n",
    "        print(f\"   Population ({total_population}) < 51 suggests partial evaporation.\")\n",
    "        print(\"   Some dead tokens may have escaped via bfloat16 diffusion.\")\n",
    "\n",
    "else:  # num_black_holes > 1\n",
    "    print(f\"üéâ MULTIPLE BLACK HOLES DETECTED! ({num_black_holes} total)\")\n",
    "    print(\"   Late-stage fission CONFIRMED.\")\n",
    "    \n",
    "    if total_population >= 50:\n",
    "        print(f\"   Total population ({total_population}) ‚âà 51 ‚Üí dead token cluster fragmented.\")\n",
    "        print(\"   This is consistent with bfloat16 diffusion hypothesis!\")\n",
    "    else:\n",
    "        print(f\"   Total population ({total_population}) < 51 suggests mixed dynamics:\")\n",
    "        print(\"   - Some fission (cluster broke apart)\")\n",
    "        print(\"   - Some evaporation (tokens escaped to singletons)\")\n",
    "    \n",
    "    if num_black_holes > 10:\n",
    "        print(f\"\\n   ‚ö†Ô∏è  VERY HIGH fragmentation ({num_black_holes} BHs).\")\n",
    "        print(\"   Possible cascading fission or spontaneous formation events.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to Initial State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPARISON TO INITIAL STATE\n",
      "================================================================================\n",
      "\n",
      "Step 0:\n",
      "  Black holes: 1\n",
      "  Population: 128\n",
      "\n",
      "Step 100000:\n",
      "  Black holes: 1\n",
      "  Population: 51\n",
      "\n",
      "Change:\n",
      "  Œî Black holes: +0\n",
      "  Œî Population: -77\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Analyze step 0 for comparison\n",
    "initial_embeddings = embedding_history[0].float()\n",
    "initial_black_holes = find_black_holes(initial_embeddings, BLACK_HOLE_THRESHOLD)\n",
    "\n",
    "initial_num = len(initial_black_holes)\n",
    "initial_pop = sum(len(bh) for bh in initial_black_holes)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"COMPARISON TO INITIAL STATE\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Step 0:\")\n",
    "print(f\"  Black holes: {initial_num}\")\n",
    "print(f\"  Population: {initial_pop}\")\n",
    "\n",
    "print(f\"\\nStep {final_step}:\")\n",
    "print(f\"  Black holes: {num_black_holes}\")\n",
    "print(f\"  Population: {total_population}\")\n",
    "\n",
    "print(f\"\\nChange:\")\n",
    "print(f\"  Œî Black holes: {num_black_holes - initial_num:+d}\")\n",
    "print(f\"  Œî Population: {total_population - initial_pop:+d}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
