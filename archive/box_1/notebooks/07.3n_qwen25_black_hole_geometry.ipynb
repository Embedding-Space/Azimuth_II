{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07.3n: Qwen2.5 Black Hole Geometry\n",
    "\n",
    "**Geometric analysis of the 60 black hole vectors in Qwen2.5-3B-Instruct**\n",
    "\n",
    "We discovered that Qwen2.5-3B-Instruct has 2,152 duplicate tokens that collapse to 60 unique vectors (black holes). This is similar to Qwen3-4B-Instruct's 2,100 tokens → 13 unique vectors.\n",
    "\n",
    "Key question: Are Qwen2.5's black holes co-located at the same tight scale as Qwen3's? If so, that's a fingerprint proving the same initialization procedure was used in both models, despite different hidden dimensions (2048 vs 2560).\n",
    "\n",
    "## Analysis Plan\n",
    "\n",
    "1. Load Qwen2.5-3B-Instruct embedding matrix\n",
    "2. Identify the 60 unique black hole vectors\n",
    "3. Compute centroid of full vocabulary\n",
    "4. Compute centroid of black holes\n",
    "5. Measure distance between centroids\n",
    "6. Compute all pairwise distances between black holes\n",
    "7. Compare scale to bfloat16 quantization (2× ULP threshold)\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model and Extract Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: Qwen/Qwen2.5-3B-Instruct\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193b115a9b244aeba81dc8855c726fa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded\n",
      "Embedding matrix shape: torch.Size([151936, 2048])\n",
      "Vocabulary size: 151,936\n",
      "Hidden dimension: 2,048\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading model: {MODEL_NAME}\\n\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"cpu\"\n",
    ")\n",
    "\n",
    "# Extract unembedding matrix\n",
    "gamma = model.lm_head.weight.data.clone().to(torch.float32)\n",
    "vocab_size, hidden_dim = gamma.shape\n",
    "\n",
    "print(f\"✓ Model loaded\")\n",
    "print(f\"Embedding matrix shape: {gamma.shape}\")\n",
    "print(f\"Vocabulary size: {vocab_size:,}\")\n",
    "print(f\"Hidden dimension: {hidden_dim:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Black Holes\n",
    "\n",
    "Use `torch.unique()` to deduplicate and identify the 60 unique black hole vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding black holes...\n",
      "\n",
      "Black hole vectors: 60\n",
      "Duplicate tokens: 2,212\n",
      "Tokens per black hole (mean): 36.9\n",
      "Tokens per black hole (median): 6\n",
      "Largest black hole: 600 tokens\n"
     ]
    }
   ],
   "source": [
    "print(\"Finding black holes...\\n\")\n",
    "\n",
    "unique_vectors, inverse_indices, counts = torch.unique(\n",
    "    gamma,\n",
    "    dim=0,\n",
    "    return_inverse=True,\n",
    "    return_counts=True\n",
    ")\n",
    "\n",
    "# Identify black hole vectors (shared by 2+ tokens)\n",
    "black_hole_mask = counts > 1\n",
    "black_hole_vectors = unique_vectors[black_hole_mask]\n",
    "black_hole_counts = counts[black_hole_mask]\n",
    "\n",
    "n_black_holes = len(black_hole_vectors)\n",
    "n_duplicate_tokens = black_hole_counts.sum().item()\n",
    "\n",
    "print(f\"Black hole vectors: {n_black_holes:,}\")\n",
    "print(f\"Duplicate tokens: {n_duplicate_tokens:,}\")\n",
    "print(f\"Tokens per black hole (mean): {n_duplicate_tokens / n_black_holes:.1f}\")\n",
    "print(f\"Tokens per black hole (median): {black_hole_counts.median().item():.0f}\")\n",
    "print(f\"Largest black hole: {black_hole_counts.max().item()} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full vocabulary centroid:\n",
      "  L2 norm: 0.298720\n",
      "  Mean component: -9.587228e-05\n",
      "  Std component: 6.601759e-03\n",
      "\n",
      "Black hole centroid:\n",
      "  L2 norm: 0.404852\n",
      "  Mean component: -4.744114e-05\n",
      "  Std component: 8.948124e-03\n",
      "\n",
      "Distance between centroids:\n",
      "  L2 distance: 0.202457\n",
      "  As fraction of full centroid norm: 0.6777\n"
     ]
    }
   ],
   "source": [
    "# Full vocabulary centroid\n",
    "centroid_full = gamma.mean(dim=0)\n",
    "print(f\"Full vocabulary centroid:\")\n",
    "print(f\"  L2 norm: {centroid_full.norm().item():.6f}\")\n",
    "print(f\"  Mean component: {centroid_full.mean().item():.6e}\")\n",
    "print(f\"  Std component: {centroid_full.std().item():.6e}\")\n",
    "\n",
    "# Black hole centroid\n",
    "centroid_bh = black_hole_vectors.mean(dim=0)\n",
    "print(f\"\\nBlack hole centroid:\")\n",
    "print(f\"  L2 norm: {centroid_bh.norm().item():.6f}\")\n",
    "print(f\"  Mean component: {centroid_bh.mean().item():.6e}\")\n",
    "print(f\"  Std component: {centroid_bh.std().item():.6e}\")\n",
    "\n",
    "# Distance between centroids\n",
    "centroid_distance = (centroid_full - centroid_bh).norm().item()\n",
    "print(f\"\\nDistance between centroids:\")\n",
    "print(f\"  L2 distance: {centroid_distance:.6f}\")\n",
    "print(f\"  As fraction of full centroid norm: {centroid_distance / centroid_full.norm().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Hole Pairwise Distances\n",
    "\n",
    "Compute L2, L∞, and L1 distances between all pairs of black holes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing pairwise distances for 60 black holes...\n",
      "\n",
      "L2 distances (Euclidean):\n",
      "  Min: 1.490116e-08\n",
      "  Max: 1.299978e-04\n",
      "  Mean: 6.577558e-05\n",
      "  Median: 7.954951e-05\n",
      "\n",
      "L∞ distances (Chebyshev):\n",
      "  Min: 1.490116e-08\n",
      "  Max: 6.103516e-05\n",
      "  Mean: 4.459896e-05\n",
      "  Median: 6.103516e-05\n",
      "\n",
      "L1 distances (Manhattan):\n",
      "  Min: 1.490116e-08\n",
      "  Max: 4.203320e-04\n",
      "  Mean: 1.575693e-04\n",
      "  Median: 1.775920e-04\n"
     ]
    }
   ],
   "source": [
    "print(f\"Computing pairwise distances for {n_black_holes} black holes...\\n\")\n",
    "\n",
    "# Pairwise differences\n",
    "v1 = black_hole_vectors.unsqueeze(1)  # (n, 1, d)\n",
    "v2 = black_hole_vectors.unsqueeze(0)  # (1, n, d)\n",
    "diffs = v1 - v2  # (n, n, d)\n",
    "\n",
    "# L2 distances\n",
    "l2_distances = torch.norm(diffs, p=2, dim=2)\n",
    "\n",
    "# L∞ (Chebyshev) distances\n",
    "l_inf_distances = torch.abs(diffs).max(dim=2)[0]\n",
    "\n",
    "# L1 distances\n",
    "l1_distances = torch.abs(diffs).sum(dim=2)\n",
    "\n",
    "# Mask out diagonal (self-distances)\n",
    "mask = ~torch.eye(n_black_holes, dtype=torch.bool)\n",
    "l2_nonzero = l2_distances[mask]\n",
    "l_inf_nonzero = l_inf_distances[mask]\n",
    "l1_nonzero = l1_distances[mask]\n",
    "\n",
    "print(\"L2 distances (Euclidean):\")\n",
    "print(f\"  Min: {l2_nonzero.min().item():.6e}\")\n",
    "print(f\"  Max: {l2_nonzero.max().item():.6e}\")\n",
    "print(f\"  Mean: {l2_nonzero.mean().item():.6e}\")\n",
    "print(f\"  Median: {l2_nonzero.median().item():.6e}\")\n",
    "\n",
    "print(\"\\nL∞ distances (Chebyshev):\")\n",
    "print(f\"  Min: {l_inf_nonzero.min().item():.6e}\")\n",
    "print(f\"  Max: {l_inf_nonzero.max().item():.6e}\")\n",
    "print(f\"  Mean: {l_inf_nonzero.mean().item():.6e}\")\n",
    "print(f\"  Median: {l_inf_nonzero.median().item():.6e}\")\n",
    "\n",
    "print(\"\\nL1 distances (Manhattan):\")\n",
    "print(f\"  Min: {l1_nonzero.min().item():.6e}\")\n",
    "print(f\"  Max: {l1_nonzero.max().item():.6e}\")\n",
    "print(f\"  Mean: {l1_nonzero.mean().item():.6e}\")\n",
    "print(f\"  Median: {l1_nonzero.median().item():.6e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bfloat16 Quantization Analysis\n",
    "\n",
    "Compare black hole separations to bfloat16 ULP (Unit in Last Place) to determine if they're at quantization scale.\n",
    "\n",
    "For bfloat16:\n",
    "- 1 sign bit\n",
    "- 8 exponent bits\n",
    "- 7 mantissa bits\n",
    "\n",
    "ULP for a value x: `2^(floor(log2(|x|)) - 6)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typical black hole component magnitude: 5.927444e-03\n",
      "Estimated exponent: 2^-8\n",
      "bfloat16 ULP at this scale: 6.103516e-05\n",
      "2× ULP threshold: 1.220703e-04\n",
      "\n",
      "Comparison to observed L∞ distances:\n",
      "  Min L∞ / ULP: 0.00\n",
      "  Max L∞ / ULP: 1.00\n",
      "  Mean L∞ / ULP: 0.73\n",
      "\n",
      "Pairs within 2× ULP threshold:\n",
      "  Count: 3,540 / 3,540\n",
      "  Percentage: 100.0%\n"
     ]
    }
   ],
   "source": [
    "# Estimate typical ULP scale from black hole centroid components\n",
    "typical_magnitude = torch.abs(centroid_bh).mean().item()\n",
    "exponent = np.floor(np.log2(typical_magnitude))\n",
    "ulp = 2 ** (exponent - 6)  # bfloat16 has 7 mantissa bits\n",
    "\n",
    "print(f\"Typical black hole component magnitude: {typical_magnitude:.6e}\")\n",
    "print(f\"Estimated exponent: 2^{exponent:.0f}\")\n",
    "print(f\"bfloat16 ULP at this scale: {ulp:.6e}\")\n",
    "print(f\"2× ULP threshold: {2 * ulp:.6e}\")\n",
    "\n",
    "# Compare to observed distances\n",
    "print(f\"\\nComparison to observed L∞ distances:\")\n",
    "print(f\"  Min L∞ / ULP: {l_inf_nonzero.min().item() / ulp:.2f}\")\n",
    "print(f\"  Max L∞ / ULP: {l_inf_nonzero.max().item() / ulp:.2f}\")\n",
    "print(f\"  Mean L∞ / ULP: {l_inf_nonzero.mean().item() / ulp:.2f}\")\n",
    "\n",
    "# How many pairs are within 2× ULP?\n",
    "within_2ulp = (l_inf_nonzero <= 2 * ulp).sum().item()\n",
    "total_pairs = len(l_inf_nonzero)\n",
    "pct_within_2ulp = 100 * within_2ulp / total_pairs\n",
    "\n",
    "print(f\"\\nPairs within 2× ULP threshold:\")\n",
    "print(f\"  Count: {within_2ulp:,} / {total_pairs:,}\")\n",
    "print(f\"  Percentage: {pct_within_2ulp:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Hole Norms\n",
    "\n",
    "Analyze the L2 norms of black hole vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black hole L2 norms:\n",
      "  Min: 0.404852\n",
      "  Max: 0.404856\n",
      "  Mean: 0.404852\n",
      "  Median: 0.404852\n",
      "  Std: 0.000001\n",
      "\n",
      "Full vocabulary L2 norms (for comparison):\n",
      "  Mean: 1.088976\n",
      "  Median: 1.113063\n",
      "  Std: 0.159866\n"
     ]
    }
   ],
   "source": [
    "black_hole_norms = torch.norm(black_hole_vectors, p=2, dim=1)\n",
    "\n",
    "print(\"Black hole L2 norms:\")\n",
    "print(f\"  Min: {black_hole_norms.min().item():.6f}\")\n",
    "print(f\"  Max: {black_hole_norms.max().item():.6f}\")\n",
    "print(f\"  Mean: {black_hole_norms.mean().item():.6f}\")\n",
    "print(f\"  Median: {black_hole_norms.median().item():.6f}\")\n",
    "print(f\"  Std: {black_hole_norms.std().item():.6f}\")\n",
    "\n",
    "# Compare to full vocabulary norms\n",
    "full_norms = torch.norm(gamma, p=2, dim=1)\n",
    "print(f\"\\nFull vocabulary L2 norms (for comparison):\")\n",
    "print(f\"  Mean: {full_norms.mean().item():.6f}\")\n",
    "print(f\"  Median: {full_norms.median().item():.6f}\")\n",
    "print(f\"  Std: {full_norms.std().item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "QWEN2.5-3B-INSTRUCT BLACK HOLE GEOMETRY\n",
      "================================================================================\n",
      "Model: Qwen/Qwen2.5-3B-Instruct\n",
      "Embedding dimensions: 151,936 × 2,048\n",
      "\n",
      "Black holes: 60 unique vectors\n",
      "Duplicate tokens: 2,212\n",
      "Deduplication ratio: 36.9× average\n",
      "\n",
      "Centroid separation: 0.202457\n",
      "Black hole pairwise distances (L∞):\n",
      "  Range: [1.490e-08, 6.104e-05]\n",
      "  Median: 6.104e-05\n",
      "\n",
      "Quantization scale (bfloat16):\n",
      "  Typical ULP: 6.104e-05\n",
      "  Max L∞ / ULP: 1.0×\n",
      "  Pairs within 2× ULP: 100.0%\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'='*80}\")\n",
    "print(\"QWEN2.5-3B-INSTRUCT BLACK HOLE GEOMETRY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Embedding dimensions: {vocab_size:,} × {hidden_dim:,}\")\n",
    "print()\n",
    "print(f\"Black holes: {n_black_holes} unique vectors\")\n",
    "print(f\"Duplicate tokens: {n_duplicate_tokens:,}\")\n",
    "print(f\"Deduplication ratio: {n_duplicate_tokens / n_black_holes:.1f}× average\")\n",
    "print()\n",
    "print(f\"Centroid separation: {centroid_distance:.6f}\")\n",
    "print(f\"Black hole pairwise distances (L∞):\")\n",
    "print(f\"  Range: [{l_inf_nonzero.min().item():.3e}, {l_inf_nonzero.max().item():.3e}]\")\n",
    "print(f\"  Median: {l_inf_nonzero.median().item():.3e}\")\n",
    "print()\n",
    "print(f\"Quantization scale (bfloat16):\")\n",
    "print(f\"  Typical ULP: {ulp:.3e}\")\n",
    "print(f\"  Max L∞ / ULP: {l_inf_nonzero.max().item() / ulp:.1f}×\")\n",
    "print(f\"  Pairs within 2× ULP: {pct_within_2ulp:.1f}%\")\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
