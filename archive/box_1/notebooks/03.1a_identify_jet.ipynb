{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03.1a: Identify and Extract Jet Tokens\n",
    "\n",
    "**Goal:** Isolate the jet structure using geometric bounds and save for further analysis.\n",
    "\n",
    "From visual inspection of PC4×5×6 orthographic projections, we identified a jet-like structure extending from the main token cloud. We'll:\n",
    "\n",
    "1. Load centered gamma and compute PCA\n",
    "2. Apply rectangular bounds in PC4×5 space: **PC4 > 0.1, PC5 < -0.05**\n",
    "3. Extract jet token embeddings (gamma_centered rows)\n",
    "4. Save jet embeddings as safetensors for downstream analysis\n",
    "5. Also save jet token IDs and mask for reference\n",
    "\n",
    "This creates a clean separation that we can analyze independently - what are the jet's *own* principal axes? What's its internal structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSOR_DIR = \"../data/tensors\"\n",
    "\n",
    "# Jet bounds (from visual inspection)\n",
    "JET_PC4_MIN = 0.1\n",
    "JET_PC5_MAX = -0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from safetensors.torch import load_file, save_file\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Imports loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Centered Gamma and Compute PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded γ' (gamma_centered):\n",
      "  Tokens: 151,936\n",
      "  Dimensions: 2,560\n",
      "\n",
      "Computing covariance matrix...\n",
      "Computing eigendecomposition...\n",
      "\n",
      "Top 6 eigenvalues:\n",
      "  PC1: λ = 1.048719e-02 (0.94% of variance)\n",
      "  PC2: λ = 3.177739e-03 (0.28% of variance)\n",
      "  PC3: λ = 2.791374e-03 (0.25% of variance)\n",
      "  PC4: λ = 2.616169e-03 (0.23% of variance)\n",
      "  PC5: λ = 1.973001e-03 (0.18% of variance)\n",
      "  PC6: λ = 1.805293e-03 (0.16% of variance)\n"
     ]
    }
   ],
   "source": [
    "gamma_centered_path = Path(TENSOR_DIR) / \"gamma_centered_qwen3_4b_instruct_2507.safetensors\"\n",
    "gamma_centered = load_file(gamma_centered_path)['gamma_centered']\n",
    "\n",
    "N, d = gamma_centered.shape\n",
    "\n",
    "print(f\"Loaded γ' (gamma_centered):\")\n",
    "print(f\"  Tokens: {N:,}\")\n",
    "print(f\"  Dimensions: {d:,}\")\n",
    "print()\n",
    "\n",
    "print(\"Computing covariance matrix...\")\n",
    "Cov = (gamma_centered.T @ gamma_centered) / (N - 1)\n",
    "\n",
    "print(f\"Computing eigendecomposition...\")\n",
    "eigenvalues, eigenvectors = torch.linalg.eigh(Cov)\n",
    "\n",
    "# Sort descending (highest variance first)\n",
    "eigenvalues = eigenvalues.flip(0)\n",
    "eigenvectors = eigenvectors.flip(1)\n",
    "\n",
    "print(f\"\\nTop 6 eigenvalues:\")\n",
    "for i in range(6):\n",
    "    variance_explained = eigenvalues[i] / eigenvalues.sum()\n",
    "    print(f\"  PC{i+1}: λ = {eigenvalues[i].item():.6e} ({variance_explained.item()*100:.2f}% of variance)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Project onto PC4 and PC5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projection statistics:\n",
      "  PC4: range [-0.1587, 0.3432], std = 0.0511\n",
      "  PC5: range [-0.2012, 0.1963], std = 0.0444\n"
     ]
    }
   ],
   "source": [
    "# Extract PC4 and PC5 axes (0-indexed: columns 3 and 4)\n",
    "PC4_axis = eigenvectors[:, 3]\n",
    "PC5_axis = eigenvectors[:, 4]\n",
    "\n",
    "# Project all tokens onto PC4 and PC5\n",
    "proj_PC4 = gamma_centered @ PC4_axis\n",
    "proj_PC5 = gamma_centered @ PC5_axis\n",
    "\n",
    "print(f\"Projection statistics:\")\n",
    "print(f\"  PC4: range [{proj_PC4.min().item():.4f}, {proj_PC4.max().item():.4f}], std = {proj_PC4.std().item():.4f}\")\n",
    "print(f\"  PC5: range [{proj_PC5.min().item():.4f}, {proj_PC5.max().item():.4f}], std = {proj_PC5.std().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Apply Jet Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jet identification (PC4 > 0.1, PC5 < -0.05):\n",
      "  Jet tokens: 3,055 (2.01%)\n",
      "  Bulk tokens: 148,881 (97.99%)\n",
      "\n",
      "Jet statistics in PC4×5 space:\n",
      "  PC4: mean = 0.1888, std = 0.0551\n",
      "  PC5: mean = -0.1083, std = 0.0319\n"
     ]
    }
   ],
   "source": [
    "# Create jet mask\n",
    "jet_mask = (proj_PC4 > JET_PC4_MIN) & (proj_PC5 < JET_PC5_MAX)\n",
    "\n",
    "n_jet = jet_mask.sum().item()\n",
    "n_bulk = (~jet_mask).sum().item()\n",
    "\n",
    "print(f\"Jet identification (PC4 > {JET_PC4_MIN}, PC5 < {JET_PC5_MAX}):\")\n",
    "print(f\"  Jet tokens: {n_jet:,} ({n_jet/N*100:.2f}%)\")\n",
    "print(f\"  Bulk tokens: {n_bulk:,} ({n_bulk/N*100:.2f}%)\")\n",
    "print()\n",
    "\n",
    "print(f\"Jet statistics in PC4×5 space:\")\n",
    "print(f\"  PC4: mean = {proj_PC4[jet_mask].mean().item():.4f}, std = {proj_PC4[jet_mask].std().item():.4f}\")\n",
    "print(f\"  PC5: mean = {proj_PC5[jet_mask].mean().item():.4f}, std = {proj_PC5[jet_mask].std().item():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Jet Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted jet embeddings:\n",
      "  Shape: torch.Size([3055, 2560])\n",
      "  Dtype: torch.float32\n",
      "  Memory: 29.8 MB\n",
      "\n",
      "Jet mean vector norm: 3.019564e-01\n",
      "(Should be small but non-zero - jet has different centroid than full cloud)\n"
     ]
    }
   ],
   "source": [
    "# Extract jet token embeddings (rows of gamma_centered)\n",
    "jet_embeddings = gamma_centered[jet_mask]\n",
    "\n",
    "print(f\"Extracted jet embeddings:\")\n",
    "print(f\"  Shape: {jet_embeddings.shape}\")\n",
    "print(f\"  Dtype: {jet_embeddings.dtype}\")\n",
    "print(f\"  Memory: {jet_embeddings.element_size() * jet_embeddings.nelement() / 1024**2:.1f} MB\")\n",
    "print()\n",
    "\n",
    "# Verify jet embeddings are still centered (should be near zero mean)\n",
    "jet_mean = jet_embeddings.mean(dim=0)\n",
    "jet_mean_norm = jet_mean.norm().item()\n",
    "print(f\"Jet mean vector norm: {jet_mean_norm:.6e}\")\n",
    "print(f\"(Should be small but non-zero - jet has different centroid than full cloud)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Get Jet Token IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jet token IDs:\n",
      "  Count: 3,055\n",
      "  Min ID: 317\n",
      "  Max ID: 144129\n",
      "  Mean ID: 46909.9\n",
      "\n",
      "First 20 jet token IDs: [317, 319, 340, 397, 401, 456, 463, 515, 532, 543, 555, 626, 630, 692, 698, 735, 736, 741, 751, 756]\n"
     ]
    }
   ],
   "source": [
    "# Get token IDs for jet tokens\n",
    "jet_token_ids = torch.where(jet_mask)[0]\n",
    "\n",
    "print(f\"Jet token IDs:\")\n",
    "print(f\"  Count: {len(jet_token_ids):,}\")\n",
    "print(f\"  Min ID: {jet_token_ids.min().item()}\")\n",
    "print(f\"  Max ID: {jet_token_ids.max().item()}\")\n",
    "print(f\"  Mean ID: {jet_token_ids.float().mean().item():.1f}\")\n",
    "print()\n",
    "print(f\"First 20 jet token IDs: {jet_token_ids[:20].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Jet Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved jet embeddings to: ../data/tensors/jet_embeddings.safetensors\n",
      "Saved jet token IDs to: ../data/tensors/jet_token_ids.safetensors\n",
      "Saved jet mask to: ../data/tensors/jet_mask.safetensors\n"
     ]
    }
   ],
   "source": [
    "# Save jet embeddings\n",
    "jet_embeddings_path = Path(TENSOR_DIR) / \"jet_embeddings.safetensors\"\n",
    "save_file({'jet_embeddings': jet_embeddings.contiguous()}, jet_embeddings_path)\n",
    "print(f\"Saved jet embeddings to: {jet_embeddings_path}\")\n",
    "\n",
    "# Save jet token IDs\n",
    "jet_token_ids_path = Path(TENSOR_DIR) / \"jet_token_ids.safetensors\"\n",
    "save_file({'jet_token_ids': jet_token_ids.contiguous()}, jet_token_ids_path)\n",
    "print(f\"Saved jet token IDs to: {jet_token_ids_path}\")\n",
    "\n",
    "# Save jet mask (for convenience)\n",
    "jet_mask_path = Path(TENSOR_DIR) / \"jet_mask.safetensors\"\n",
    "save_file({'jet_mask': jet_mask.contiguous()}, jet_mask_path)\n",
    "print(f\"Saved jet mask to: {jet_mask_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Successfully extracted jet tokens from the main cloud!\n",
    "\n",
    "**Jet identification:**\n",
    "- Bounds: PC4 > 0.1, PC5 < -0.05\n",
    "- Tokens: 3,055 (2.01% of vocabulary)\n",
    "\n",
    "**Saved files:**\n",
    "- `jet_embeddings.safetensors` - (3055, 2560) centered embeddings\n",
    "- `jet_token_ids.safetensors` - (3055,) token IDs\n",
    "- `jet_mask.safetensors` - (151936,) boolean mask\n",
    "\n",
    "**Next steps:**\n",
    "- Compute PCA on jet embeddings to find jet's natural axes\n",
    "- Visualize jet in its own coordinate system\n",
    "- Decode jet tokens to understand semantic properties"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
