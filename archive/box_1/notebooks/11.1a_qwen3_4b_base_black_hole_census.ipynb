{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Hole Census: Qwen3-4B-Base\n",
    "\n",
    "**Hypothesis test:** If black holes form at initialization and diffuse during post-training, then:\n",
    "- Qwen3-4B-Base (pretrained only) should have C_b = 1 black hole with population P_b ≥ 2,211\n",
    "- Qwen3-4B-Instruct-2507 (post-trained) has C_i = 13 black holes with population P_i ≈ 2,211\n",
    "\n",
    "This notebook counts black holes in the Base model to test the prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mathematical Background\n",
    "\n",
    "A **black hole** is a set of tokens that share identical embedding vectors in γ-space:\n",
    "\n",
    "$$\\text{BH}_i = \\{t_j : \\gamma_{t_j} = v_i\\}$$\n",
    "\n",
    "where $|\\text{BH}_i| \\geq 2$ (degenerate tokens).\n",
    "\n",
    "**Black hole count** C = number of distinct shared vectors  \n",
    "**Black hole population** P = total number of tokens in all black holes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen3-4B-Base\"\n",
    "DEVICE = \"mps\"  # Apple Silicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen/Qwen3-4B-Base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9602917573d40d99a09b7967e94dde6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading {MODEL_NAME}...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=DEVICE\n",
    ")\n",
    "print(\"Model loaded successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Unembedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 151,936\n",
      "Hidden dimension: 2,560\n",
      "Dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "gamma = model.lm_head.weight.data.cpu()  # [vocab_size, hidden_dim]\n",
    "vocab_size, hidden_dim = gamma.shape\n",
    "\n",
    "print(f\"Vocabulary size: {vocab_size:,}\")\n",
    "print(f\"Hidden dimension: {hidden_dim:,}\")\n",
    "print(f\"Dtype: {gamma.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Black Holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding unique vectors...\n",
      "Total tokens: 151,936\n",
      "Unique vectors: 149,806\n",
      "Duplicate vectors eliminated: 2,130\n"
     ]
    }
   ],
   "source": [
    "# Find unique vectors and their inverse mapping\n",
    "print(\"Finding unique vectors...\")\n",
    "unique_vectors, inverse_indices = torch.unique(gamma, dim=0, return_inverse=True)\n",
    "\n",
    "print(f\"Total tokens: {vocab_size:,}\")\n",
    "print(f\"Unique vectors: {len(unique_vectors):,}\")\n",
    "print(f\"Duplicate vectors eliminated: {vocab_size - len(unique_vectors):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Black Hole Populations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BLACK HOLE CENSUS: Qwen3-4B-Base\n",
      "============================================================\n",
      "Black hole count (C_b): 62\n",
      "Total black hole population (P_b): 2,192\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count how many tokens map to each unique vector\n",
    "vector_populations = Counter(inverse_indices.tolist())\n",
    "\n",
    "# Black holes are vectors with population ≥ 2\n",
    "black_holes = {vec_id: pop for vec_id, pop in vector_populations.items() if pop >= 2}\n",
    "\n",
    "C_b = len(black_holes)  # Black hole count\n",
    "P_b = sum(black_holes.values())  # Total black hole population\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BLACK HOLE CENSUS: Qwen3-4B-Base\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Black hole count (C_b): {C_b}\")\n",
    "print(f\"Total black hole population (P_b): {P_b:,}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black Hole Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Black hole populations (sorted by size):\n",
      "\n",
      "BH #1: 582 tokens\n",
      "BH #2: 456 tokens\n",
      "BH #3: 296 tokens\n",
      "BH #4: 159 tokens\n",
      "BH #5: 99 tokens\n",
      "BH #6: 80 tokens\n",
      "BH #7: 56 tokens\n",
      "BH #8: 52 tokens\n",
      "BH #9: 45 tokens\n",
      "BH #10: 36 tokens\n",
      "BH #11: 30 tokens\n",
      "BH #12: 29 tokens\n",
      "BH #13: 26 tokens\n",
      "BH #14: 24 tokens\n",
      "BH #15: 19 tokens\n",
      "BH #16: 16 tokens\n",
      "BH #17: 15 tokens\n",
      "BH #18: 10 tokens\n",
      "BH #19: 8 tokens\n",
      "BH #20: 8 tokens\n",
      "BH #21: 8 tokens\n",
      "BH #22: 7 tokens\n",
      "BH #23: 7 tokens\n",
      "BH #24: 7 tokens\n",
      "BH #25: 6 tokens\n",
      "BH #26: 6 tokens\n",
      "BH #27: 6 tokens\n",
      "BH #28: 5 tokens\n",
      "BH #29: 5 tokens\n",
      "BH #30: 5 tokens\n",
      "BH #31: 5 tokens\n",
      "BH #32: 4 tokens\n",
      "BH #33: 4 tokens\n",
      "BH #34: 4 tokens\n",
      "BH #35: 3 tokens\n",
      "BH #36: 3 tokens\n",
      "BH #37: 3 tokens\n",
      "BH #38: 3 tokens\n",
      "BH #39: 3 tokens\n",
      "BH #40: 3 tokens\n",
      "BH #41: 3 tokens\n",
      "BH #42: 3 tokens\n",
      "BH #43: 3 tokens\n",
      "BH #44: 3 tokens\n",
      "BH #45: 3 tokens\n",
      "BH #46: 2 tokens\n",
      "BH #47: 2 tokens\n",
      "BH #48: 2 tokens\n",
      "BH #49: 2 tokens\n",
      "BH #50: 2 tokens\n",
      "BH #51: 2 tokens\n",
      "BH #52: 2 tokens\n",
      "BH #53: 2 tokens\n",
      "BH #54: 2 tokens\n",
      "BH #55: 2 tokens\n",
      "BH #56: 2 tokens\n",
      "BH #57: 2 tokens\n",
      "BH #58: 2 tokens\n",
      "BH #59: 2 tokens\n",
      "BH #60: 2 tokens\n",
      "BH #61: 2 tokens\n",
      "BH #62: 2 tokens\n",
      "\n",
      "Largest black hole: 582 tokens\n",
      "Smallest black hole: 2 tokens\n"
     ]
    }
   ],
   "source": [
    "# Sort black holes by population (largest first)\n",
    "sorted_bhs = sorted(black_holes.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Black hole populations (sorted by size):\\n\")\n",
    "for i, (vec_id, pop) in enumerate(sorted_bhs, 1):\n",
    "    print(f\"BH #{i}: {pop:,} tokens\")\n",
    "\n",
    "if C_b > 0:\n",
    "    print(f\"\\nLargest black hole: {sorted_bhs[0][1]:,} tokens\")\n",
    "    if C_b > 1:\n",
    "        print(f\"Smallest black hole: {sorted_bhs[-1][1]:,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hypothesis: Black holes form at initialization, diffuse during post-training\n",
      "\n",
      "Predictions:\n",
      "  Base model should have C_b = 1 (single primordial cluster)\n",
      "  Base model should have P_b ≥ 2,211 (all unused tokens together)\n",
      "\n",
      "Observations:\n",
      "  C_b = 62\n",
      "  P_b = 2,192\n",
      "\n",
      "Result:\n",
      "  ✗ HYPOTHESIS CHALLENGED\n",
      "  Multiple black holes found in base model.\n",
      "  Diffusion may occur during pretraining, not just post-training.\n"
     ]
    }
   ],
   "source": [
    "P_i = 2211  # Known population from Qwen3-4B-Instruct-2507\n",
    "C_i = 13    # Known count from Qwen3-4B-Instruct-2507\n",
    "\n",
    "print(\"\\nHypothesis: Black holes form at initialization, diffuse during post-training\\n\")\n",
    "print(\"Predictions:\")\n",
    "print(f\"  Base model should have C_b = 1 (single primordial cluster)\")\n",
    "print(f\"  Base model should have P_b ≥ {P_i:,} (all unused tokens together)\\n\")\n",
    "\n",
    "print(\"Observations:\")\n",
    "print(f\"  C_b = {C_b}\")\n",
    "print(f\"  P_b = {P_b:,}\\n\")\n",
    "\n",
    "print(\"Result:\")\n",
    "if C_b == 1 and P_b >= P_i:\n",
    "    print(\"  ✓ HYPOTHESIS SUPPORTED\")\n",
    "    print(\"  Base model has single black hole with population ≥ Instruct total.\")\n",
    "elif C_b == 1 and P_b < P_i:\n",
    "    print(\"  ✗ PARTIAL SUPPORT\")\n",
    "    print(\"  Single black hole as predicted, but population smaller than expected.\")\n",
    "    print(\"  Some tokens may have been rescued during pretraining.\")\n",
    "elif C_b > 1:\n",
    "    print(\"  ✗ HYPOTHESIS CHALLENGED\")\n",
    "    print(\"  Multiple black holes found in base model.\")\n",
    "    print(\"  Diffusion may occur during pretraining, not just post-training.\")\n",
    "else:\n",
    "    print(\"  ✗ UNEXPECTED RESULT\")\n",
    "    print(\"  No black holes found in base model.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
