{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 12.2e: Qwen 3 4B Comprehensive Statistics\n",
    "\n",
    "**Goal:** Compute the EXACT SAME statistics as 12.2d, but for Qwen 3 4B Instruct 2507's actual dead token structure.\n",
    "\n",
    "## What We Compute (Single Model)\n",
    "\n",
    "Same 20+ metrics as 12.2d:\n",
    "- Basic counts (n_unique, n_black_holes, n_singletons, populations)\n",
    "- Per-black-hole statistics (largest, smallest, mean, median, top2, Gini)\n",
    "- Spatial extent (max/mean/median L∞ distances)\n",
    "- Topology (components, isolated nodes, largest component size/density, global density)\n",
    "\n",
    "## Approach\n",
    "\n",
    "- Load Qwen's gamma matrix and black hole mask (pre-computed)\n",
    "- Extract dead token embeddings (2,100 tokens)\n",
    "- Run `torch.unique()` to get unique vectors + counts\n",
    "- Compute all statistics using same functions as 12.2d\n",
    "- Save results to CSV: **one row** with all metrics\n",
    "\n",
    "## Output\n",
    "\n",
    "`../data/analysis/qwen_comprehensive.csv`\n",
    "\n",
    "**Runtime:** <1 second (single trial)\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "Having Qwen's stats in the EXACT same format as the synthetic trials lets us do direct comparisons in 12.3e:\n",
    "- Qwen value vs synthetic (mean ± std)\n",
    "- How many σ away is Qwen from the synthetic distribution?\n",
    "- Which metrics match perfectly (topology) vs which have variance (population)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-computed tensors\n",
    "GAMMA_PATH = \"../data/tensors/gamma_qwen3_4b_instruct_2507.safetensors\"\n",
    "MASK_PATH = \"../data/tensors/black_hole_mask.safetensors\"\n",
    "\n",
    "# Reference scale\n",
    "EPSILON = 6e-5  # bfloat16 ULP at Qwen magnitude\n",
    "\n",
    "# Adjacency threshold for topology\n",
    "TOUCHING_THRESHOLD = 2 * EPSILON\n",
    "\n",
    "# Output\n",
    "OUTPUT_CSV = \"../data/analysis/qwen_comprehensive.csv\"\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from safetensors.torch import load_file\n",
    "from pathlib import Path\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Helper Functions (Same as 12.2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def compute_gini_coefficient(populations):\n",
    "    \"\"\"\n",
    "    Compute Gini coefficient of inequality.\n",
    "    \"\"\"\n",
    "    if len(populations) <= 1:\n",
    "        return 0.0\n",
    "    \n",
    "    sorted_pops = torch.sort(populations.float())[0]\n",
    "    n = len(sorted_pops)\n",
    "    \n",
    "    indices = torch.arange(1, n + 1, dtype=torch.float32)\n",
    "    numerator = 2 * torch.sum(indices * sorted_pops)\n",
    "    denominator = n * torch.sum(sorted_pops)\n",
    "    \n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    gini = (numerator / denominator) - (n + 1) / n\n",
    "    return gini.item()\n",
    "\n",
    "\n",
    "def compute_l_inf_stats(unique_vectors, epsilon):\n",
    "    \"\"\"\n",
    "    Compute L∞ (Chebyshev) distance statistics.\n",
    "    \"\"\"\n",
    "    n = len(unique_vectors)\n",
    "    \n",
    "    if n <= 1:\n",
    "        return {'max_l_inf': 0.0, 'mean_l_inf': 0.0, 'median_l_inf': 0.0}\n",
    "    \n",
    "    # Compute pairwise L∞ distances (vectorized)\n",
    "    v1 = unique_vectors.unsqueeze(1)\n",
    "    v2 = unique_vectors.unsqueeze(0)\n",
    "    diffs = v1 - v2\n",
    "    l_inf_matrix = torch.abs(diffs).max(dim=2)[0]\n",
    "    \n",
    "    # Exclude diagonal\n",
    "    mask = ~torch.eye(n, dtype=torch.bool)\n",
    "    l_inf_values = l_inf_matrix[mask]\n",
    "    \n",
    "    # Normalize by epsilon\n",
    "    l_inf_values = l_inf_values / epsilon\n",
    "    \n",
    "    return {\n",
    "        'max_l_inf': l_inf_values.max().item(),\n",
    "        'mean_l_inf': l_inf_values.mean().item(),\n",
    "        'median_l_inf': l_inf_values.median().item(),\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_topology(unique_vectors, threshold):\n",
    "    \"\"\"\n",
    "    Compute graph topology statistics.\n",
    "    \"\"\"\n",
    "    n = len(unique_vectors)\n",
    "    \n",
    "    if n == 0:\n",
    "        return {\n",
    "            'n_components': 0,\n",
    "            'n_isolated': 0,\n",
    "            'largest_component_size': 0,\n",
    "            'largest_component_density': 0.0,\n",
    "            'global_density': 0.0,\n",
    "        }\n",
    "    \n",
    "    if n == 1:\n",
    "        return {\n",
    "            'n_components': 1,\n",
    "            'n_isolated': 1,\n",
    "            'largest_component_size': 1,\n",
    "            'largest_component_density': 1.0,\n",
    "            'global_density': 1.0,\n",
    "        }\n",
    "    \n",
    "    # Compute pairwise L∞ distances\n",
    "    v1 = unique_vectors.unsqueeze(1)\n",
    "    v2 = unique_vectors.unsqueeze(0)\n",
    "    diffs = v1 - v2\n",
    "    l_inf_matrix = torch.abs(diffs).max(dim=2)[0]\n",
    "    \n",
    "    # Build adjacency matrix\n",
    "    adjacency = (l_inf_matrix <= threshold) & (~torch.eye(n, dtype=torch.bool))\n",
    "    \n",
    "    # Convert to NetworkX graph\n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(range(n))\n",
    "    edges = torch.nonzero(adjacency, as_tuple=False).tolist()\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    # Connected components\n",
    "    components = list(nx.connected_components(G))\n",
    "    component_sizes = sorted([len(c) for c in components], reverse=True)\n",
    "    \n",
    "    n_components = len(components)\n",
    "    largest_size = component_sizes[0] if component_sizes else 0\n",
    "    \n",
    "    # Isolated nodes\n",
    "    n_isolated = sum(1 for node in G.nodes() if G.degree(node) == 0)\n",
    "    \n",
    "    # Density of largest component\n",
    "    if largest_size > 1:\n",
    "        largest_component = max(components, key=len)\n",
    "        subgraph = G.subgraph(largest_component)\n",
    "        n_edges = subgraph.number_of_edges()\n",
    "        max_edges = largest_size * (largest_size - 1) // 2\n",
    "        largest_density = n_edges / max_edges if max_edges > 0 else 0.0\n",
    "    else:\n",
    "        largest_density = 1.0 if largest_size == 1 else 0.0\n",
    "    \n",
    "    # Global density\n",
    "    n_edges = G.number_of_edges()\n",
    "    max_edges = n * (n - 1) // 2\n",
    "    global_density = n_edges / max_edges if max_edges > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'n_components': n_components,\n",
    "        'n_isolated': n_isolated,\n",
    "        'largest_component_size': largest_size,\n",
    "        'largest_component_density': largest_density,\n",
    "        'global_density': global_density,\n",
    "    }\n",
    "\n",
    "\n",
    "def compute_trial_statistics(embeddings, epsilon, threshold):\n",
    "    \"\"\"\n",
    "    Compute all statistics for a single trial.\n",
    "    \"\"\"\n",
    "    # Get unique vectors and counts\n",
    "    unique_vectors, _, counts = torch.unique(\n",
    "        embeddings,\n",
    "        dim=0,\n",
    "        return_inverse=True,\n",
    "        return_counts=True\n",
    "    )\n",
    "    \n",
    "    # Basic counts\n",
    "    n_tokens = len(embeddings)\n",
    "    n_unique = len(unique_vectors)\n",
    "    black_hole_mask = counts >= 2\n",
    "    n_black_holes = black_hole_mask.sum().item()\n",
    "    n_singletons = (~black_hole_mask).sum().item()\n",
    "    total_population = counts.sum().item()\n",
    "    black_hole_population = counts[black_hole_mask].sum().item() if n_black_holes > 0 else 0\n",
    "    \n",
    "    # Per-black-hole statistics\n",
    "    if n_black_holes > 0:\n",
    "        bh_populations = counts[black_hole_mask]\n",
    "        largest_bh = bh_populations.max().item()\n",
    "        smallest_bh = bh_populations.min().item()\n",
    "        mean_bh_size = bh_populations.float().mean().item()\n",
    "        median_bh_size = bh_populations.float().median().item()\n",
    "        \n",
    "        # Top-2 concentration\n",
    "        top_k = min(2, len(bh_populations))\n",
    "        top2_population = bh_populations.topk(top_k)[0].sum().item()\n",
    "        \n",
    "        # Gini coefficient\n",
    "        gini = compute_gini_coefficient(bh_populations)\n",
    "    else:\n",
    "        largest_bh = 0\n",
    "        smallest_bh = 0\n",
    "        mean_bh_size = 0.0\n",
    "        median_bh_size = 0.0\n",
    "        top2_population = 0\n",
    "        gini = 0.0\n",
    "    \n",
    "    # Spatial extent (L∞ distances)\n",
    "    l_inf_stats = compute_l_inf_stats(unique_vectors, epsilon)\n",
    "    \n",
    "    # Topology\n",
    "    topology_stats = compute_topology(unique_vectors, threshold)\n",
    "    \n",
    "    # Combine all statistics\n",
    "    return {\n",
    "        # Basic counts\n",
    "        'n_tokens': n_tokens,\n",
    "        'n_unique': n_unique,\n",
    "        'n_black_holes': n_black_holes,\n",
    "        'n_singletons': n_singletons,\n",
    "        'total_population': total_population,\n",
    "        'black_hole_population': black_hole_population,\n",
    "        \n",
    "        # Per-BH statistics\n",
    "        'largest_bh': largest_bh,\n",
    "        'smallest_bh': smallest_bh,\n",
    "        'mean_bh_size': mean_bh_size,\n",
    "        'median_bh_size': median_bh_size,\n",
    "        'top2_population': top2_population,\n",
    "        'gini_coefficient': gini,\n",
    "        \n",
    "        # Spatial extent\n",
    "        'max_l_inf': l_inf_stats['max_l_inf'],\n",
    "        'mean_l_inf': l_inf_stats['mean_l_inf'],\n",
    "        'median_l_inf': l_inf_stats['median_l_inf'],\n",
    "        \n",
    "        # Topology\n",
    "        'n_components': topology_stats['n_components'],\n",
    "        'n_isolated': topology_stats['n_isolated'],\n",
    "        'largest_component_size': topology_stats['largest_component_size'],\n",
    "        'largest_component_density': topology_stats['largest_component_density'],\n",
    "        'global_density': topology_stats['global_density'],\n",
    "    }\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Load Qwen Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen 3 4B Instruct 2507 data...\n",
      "\n",
      "✓ Gamma loaded\n",
      "  Shape: torch.Size([151936, 2560])\n",
      "  Dtype: torch.float32\n",
      "\n",
      "✓ Black hole mask loaded\n",
      "  Dead tokens: 2,100\n",
      "\n",
      "✓ Extracted dead token embeddings\n",
      "  Shape: torch.Size([2100, 2560])\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Qwen 3 4B Instruct 2507 data...\\n\")\n",
    "\n",
    "# Load gamma matrix (unembedding weights)\n",
    "gamma_data = load_file(GAMMA_PATH)\n",
    "gamma = gamma_data['gamma'].to(torch.float32)\n",
    "\n",
    "print(f\"✓ Gamma loaded\")\n",
    "print(f\"  Shape: {gamma.shape}\")\n",
    "print(f\"  Dtype: {gamma.dtype}\")\n",
    "\n",
    "# Load black hole mask\n",
    "mask_data = load_file(MASK_PATH)\n",
    "mask = mask_data['mask']\n",
    "\n",
    "print(f\"\\n✓ Black hole mask loaded\")\n",
    "print(f\"  Dead tokens: {mask.sum().item():,}\")\n",
    "\n",
    "# Extract dead token embeddings\n",
    "dead_token_embeddings = gamma[mask]\n",
    "\n",
    "print(f\"\\n✓ Extracted dead token embeddings\")\n",
    "print(f\"  Shape: {dead_token_embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Compute Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing comprehensive statistics for Qwen...\n",
      "\n",
      "✓ Statistics computed\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing comprehensive statistics for Qwen...\\n\")\n",
    "\n",
    "# Compute all statistics using the same function as 12.2d\n",
    "qwen_stats = compute_trial_statistics(dead_token_embeddings, EPSILON, TOUCHING_THRESHOLD)\n",
    "\n",
    "# Add a trial_id (just 0 for Qwen)\n",
    "qwen_stats['trial_id'] = 0\n",
    "\n",
    "print(\"✓ Statistics computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Display Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "QWEN 3 4B INSTRUCT 2507 COMPREHENSIVE STATISTICS\n",
      "======================================================================\n",
      "\n",
      "BASIC COUNTS:\n",
      "  Total tokens: 2100\n",
      "  Unique vectors: 13\n",
      "  Black holes (C ≥ 2): 13\n",
      "  Singletons (C = 1): 0\n",
      "  Total population: 2100\n",
      "  Black hole population: 2100\n",
      "\n",
      "PER-BLACK-HOLE STATISTICS:\n",
      "  Largest BH: 814\n",
      "  Smallest BH: 2\n",
      "  Mean BH size: 161.5\n",
      "  Median BH size: 6.0\n",
      "  Top-2 population: 1518 (72.3%)\n",
      "  Gini coefficient: 0.753\n",
      "\n",
      "SPATIAL EXTENT (units of ε):\n",
      "  Max L∞: 1.017\n",
      "  Mean L∞: 0.483\n",
      "  Median L∞: 0.509\n",
      "\n",
      "TOPOLOGY:\n",
      "  Connected components: 1\n",
      "  Isolated nodes: 0\n",
      "  Largest component size: 13\n",
      "  Largest component density: 1.000\n",
      "  Global density: 1.000\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"QWEN 3 4B INSTRUCT 2507 COMPREHENSIVE STATISTICS\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(\"BASIC COUNTS:\")\n",
    "print(f\"  Total tokens: {qwen_stats['n_tokens']}\")\n",
    "print(f\"  Unique vectors: {qwen_stats['n_unique']}\")\n",
    "print(f\"  Black holes (C ≥ 2): {qwen_stats['n_black_holes']}\")\n",
    "print(f\"  Singletons (C = 1): {qwen_stats['n_singletons']}\")\n",
    "print(f\"  Total population: {qwen_stats['total_population']}\")\n",
    "print(f\"  Black hole population: {qwen_stats['black_hole_population']}\")\n",
    "\n",
    "print(f\"\\nPER-BLACK-HOLE STATISTICS:\")\n",
    "print(f\"  Largest BH: {qwen_stats['largest_bh']}\")\n",
    "print(f\"  Smallest BH: {qwen_stats['smallest_bh']}\")\n",
    "print(f\"  Mean BH size: {qwen_stats['mean_bh_size']:.1f}\")\n",
    "print(f\"  Median BH size: {qwen_stats['median_bh_size']:.1f}\")\n",
    "print(f\"  Top-2 population: {qwen_stats['top2_population']} ({qwen_stats['top2_population']/qwen_stats['total_population']*100:.1f}%)\")\n",
    "print(f\"  Gini coefficient: {qwen_stats['gini_coefficient']:.3f}\")\n",
    "\n",
    "print(f\"\\nSPATIAL EXTENT (units of ε):\")\n",
    "print(f\"  Max L∞: {qwen_stats['max_l_inf']:.3f}\")\n",
    "print(f\"  Mean L∞: {qwen_stats['mean_l_inf']:.3f}\")\n",
    "print(f\"  Median L∞: {qwen_stats['median_l_inf']:.3f}\")\n",
    "\n",
    "print(f\"\\nTOPOLOGY:\")\n",
    "print(f\"  Connected components: {qwen_stats['n_components']}\")\n",
    "print(f\"  Isolated nodes: {qwen_stats['n_isolated']}\")\n",
    "print(f\"  Largest component size: {qwen_stats['largest_component_size']}\")\n",
    "print(f\"  Largest component density: {qwen_stats['largest_component_density']:.3f}\")\n",
    "print(f\"  Global density: {qwen_stats['global_density']:.3f}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Saved to ../data/analysis/qwen_comprehensive.csv\n",
      "  Columns: 21\n",
      "  File size: 0.44 KB\n",
      "\n",
      "======================================================================\n",
      "QWEN STATISTICS SAVED\n",
      "======================================================================\n",
      "\n",
      "Ready for comparison in 12.3e!\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame (single row)\n",
    "df = pd.DataFrame([qwen_stats])\n",
    "\n",
    "# Reorder columns to match 12.2d\n",
    "column_order = [\n",
    "    'trial_id',\n",
    "    # Basic counts\n",
    "    'n_tokens', 'n_unique', 'n_black_holes', 'n_singletons',\n",
    "    'total_population', 'black_hole_population',\n",
    "    # Per-BH stats\n",
    "    'largest_bh', 'smallest_bh', 'mean_bh_size', 'median_bh_size',\n",
    "    'top2_population', 'gini_coefficient',\n",
    "    # Spatial\n",
    "    'max_l_inf', 'mean_l_inf', 'median_l_inf',\n",
    "    # Topology\n",
    "    'n_components', 'n_isolated', 'largest_component_size',\n",
    "    'largest_component_density', 'global_density',\n",
    "]\n",
    "\n",
    "df = df[column_order]\n",
    "\n",
    "# Save\n",
    "output_path = Path(OUTPUT_CSV)\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved to {output_path}\")\n",
    "print(f\"  Columns: {len(df.columns)}\")\n",
    "print(f\"  File size: {output_path.stat().st_size / 1024:.2f} KB\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"QWEN STATISTICS SAVED\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nReady for comparison in 12.3e!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
