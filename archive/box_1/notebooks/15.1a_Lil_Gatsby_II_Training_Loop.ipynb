{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.1a: Comprehensive Instrumentation\n",
    "\n",
    "**Record everything: embeddings, gradients, optimizer state, logits, loss**\n",
    "\n",
    "## Volume 15: The Everything Dataset\n",
    "\n",
    "Previous instrumented runs recorded deltas (changes). This time we record **absolute state** at each step:\n",
    "\n",
    "1. **Embedding matrix W**: The actual token positions in space\n",
    "2. **Gradients**: The instantaneous forces acting on tokens\n",
    "3. **Adam momentum**: The inertial velocity each token has built up\n",
    "4. **Adam variance**: The adaptive learning rate scaling per token\n",
    "5. **Logits**: Model predictions (one position per step)\n",
    "6. **Loss**: Training loss value\n",
    "\n",
    "This lets us study:\n",
    "- Token trajectories (from W directly, no cumsum needed)\n",
    "- Force decomposition (gradient vs momentum)\n",
    "- Prediction evolution (logits over time)\n",
    "- Optimizer dynamics (how Adam modulates the motion)\n",
    "\n",
    "## File Size\n",
    "\n",
    "~660 MB for 10,001 steps (0-10,000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model architecture\n",
    "VOCAB_SIZE = 128\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYER = 2\n",
    "N_HEAD = 2\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 32\n",
    "GRADIENT_ACCUMULATION = 1\n",
    "NUM_TRAIN_STEPS = 10000\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 0.01\n",
    "\n",
    "# Adam parameters (defaults from torch.optim.AdamW)\n",
    "ADAM_BETA1 = 0.9  # momentum decay\n",
    "ADAM_BETA2 = 0.999  # variance decay\n",
    "ADAM_EPSILON = 1e-8\n",
    "\n",
    "# Initialization\n",
    "INIT_SIGMA = 1e-5  # float32 → bfloat16\n",
    "\n",
    "# Data\n",
    "CORPUS_PATH = \"../data/training_corpus.txt\"\n",
    "OUTPUT_DIR = \"../data/comprehensive_run\"\n",
    "\n",
    "# Instrumentation\n",
    "RECORD_EVERY_N_STEPS = 1  # Record every step\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from safetensors.torch import save_file\n",
    "import time\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Gatsby Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading corpus: ../data/training_corpus.txt\n",
      "  Total bytes: 265,905\n",
      "  Live tokens: 77 / 128\n",
      "  Dead tokens: 51 / 128\n",
      "\n",
      "✓ Corpus on device\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading corpus: {CORPUS_PATH}\")\n",
    "\n",
    "with open(CORPUS_PATH, 'r', encoding='ascii') as f:\n",
    "    corpus_text = f.read()\n",
    "\n",
    "corpus_bytes = [b for b in corpus_text.encode('ascii') if b < VOCAB_SIZE]\n",
    "\n",
    "unique_bytes = set(corpus_bytes)\n",
    "dead_token_ids = sorted(set(range(VOCAB_SIZE)) - unique_bytes)\n",
    "live_token_ids = sorted(unique_bytes)\n",
    "\n",
    "print(f\"  Total bytes: {len(corpus_bytes):,}\")\n",
    "print(f\"  Live tokens: {len(live_token_ids)} / {VOCAB_SIZE}\")\n",
    "print(f\"  Dead tokens: {len(dead_token_ids)} / {VOCAB_SIZE}\")\n",
    "\n",
    "# Pre-load to device\n",
    "corpus_tensor = torch.tensor(corpus_bytes, dtype=torch.long, device=device)\n",
    "print(f\"\\n✓ Corpus on device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset: 265,777 examples\n"
     ]
    }
   ],
   "source": [
    "class ByteDataset(Dataset):\n",
    "    def __init__(self, corpus_tensor, max_seq_len):\n",
    "        self.corpus = corpus_tensor\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(0, len(self.corpus) - self.max_seq_len)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.corpus[idx : idx + self.max_seq_len + 1]\n",
    "        return {\n",
    "            'input_ids': chunk[:-1],\n",
    "            'labels': chunk[1:]\n",
    "        }\n",
    "\n",
    "dataset = ByteDataset(corpus_tensor, MAX_SEQ_LEN)\n",
    "print(f\"✓ Dataset: {len(dataset):,} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model created: 116,480 parameters\n"
     ]
    }
   ],
   "source": [
    "config = GPT2Config(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_positions=MAX_SEQ_LEN,\n",
    "    n_embd=HIDDEN_DIM,\n",
    "    n_layer=N_LAYER,\n",
    "    n_head=N_HEAD,\n",
    "    resid_pdrop=0.0,\n",
    "    embd_pdrop=0.0,\n",
    "    attn_pdrop=0.0,\n",
    "    tie_word_embeddings=True,\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model = model.to(torch.bfloat16).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"✓ Model created: {total_params:,} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Float32 Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Float32 initialization (σ = 1.00e-05)\n",
      "\n",
      "Initialized: 128 tokens at norm ~0.999999\n",
      "\n",
      "✓ Embeddings initialized\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nFloat32 initialization (σ = {INIT_SIGMA:.2e})\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Generate random unit vector in float32\n",
    "    random_vector = torch.randn(HIDDEN_DIM, dtype=torch.float32, device=device)\n",
    "    random_vector = random_vector / random_vector.norm()\n",
    "    \n",
    "    # Add Gaussian noise in float32\n",
    "    noise = torch.randn(VOCAB_SIZE, HIDDEN_DIM, dtype=torch.float32, device=device) * INIT_SIGMA\n",
    "    init_f32 = random_vector + noise\n",
    "    \n",
    "    # Convert to bfloat16 for training\n",
    "    init_bf16 = init_f32.to(torch.bfloat16)\n",
    "    \n",
    "    # Assign to model\n",
    "    model.transformer.wte.weight[:] = init_bf16\n",
    "    \n",
    "    print(f\"Initialized: {VOCAB_SIZE} tokens at norm ~{init_f32.norm(dim=1).mean().item():.6f}\")\n",
    "\n",
    "print(f\"\\n✓ Embeddings initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Recorder class defined\n"
     ]
    }
   ],
   "source": [
    "class ComprehensiveRecorder:\n",
    "    \"\"\"Records everything: embeddings, gradients, Adam state, logits, loss.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_dim, record_every_n):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.record_every_n = record_every_n\n",
    "        \n",
    "        # Storage\n",
    "        self.recorded_steps = []\n",
    "        self.embeddings = []      # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.grads = []           # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.momentum = []        # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.variance = []        # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.logits = []          # [n_recorded, vocab_size]\n",
    "        self.losses = []          # [n_recorded]\n",
    "        \n",
    "        # Temporary storage\n",
    "        self.current_step = 0\n",
    "        self.recorded_initial = False\n",
    "        self.grad_before = None\n",
    "        self.loss_value = None\n",
    "        self.logits_sample = None\n",
    "    \n",
    "    def record_initial_state(self, model, optimizer):\n",
    "        \"\"\"Record step 0: initial state before training.\"\"\"\n",
    "        if not self.recorded_initial:\n",
    "            W = model.transformer.wte.weight.data.clone().cpu().float()\n",
    "            \n",
    "            # Step 0: no gradients, no Adam state yet (zeros)\n",
    "            self.recorded_steps.append(0)\n",
    "            self.embeddings.append(W)\n",
    "            self.grads.append(torch.zeros_like(W))\n",
    "            self.momentum.append(torch.zeros_like(W))\n",
    "            self.variance.append(torch.zeros_like(W))\n",
    "            self.logits.append(torch.zeros(self.vocab_size))\n",
    "            self.losses.append(torch.tensor(float('nan')))  # No loss yet\n",
    "            \n",
    "            self.recorded_initial = True\n",
    "            self.current_step = 1\n",
    "    \n",
    "    def record_before_step(self, model, loss, logits):\n",
    "        \"\"\"Call after forward/backward, before optimizer step.\"\"\"\n",
    "        if self.current_step % self.record_every_n == 0:\n",
    "            # Capture gradients\n",
    "            if model.transformer.wte.weight.grad is not None:\n",
    "                self.grad_before = model.transformer.wte.weight.grad.clone().cpu().float()\n",
    "            else:\n",
    "                self.grad_before = torch.zeros(self.vocab_size, self.hidden_dim)\n",
    "            \n",
    "            # Capture loss\n",
    "            self.loss_value = loss.item()\n",
    "            \n",
    "            # Capture logits from first sequence, last position\n",
    "            # logits shape: [batch_size, seq_len, vocab_size]\n",
    "            self.logits_sample = logits[0, -1, :].detach().cpu().float()\n",
    "    \n",
    "    def record_after_step(self, model, optimizer):\n",
    "        \"\"\"Call after optimizer step.\"\"\"\n",
    "        if self.current_step % self.record_every_n == 0:\n",
    "            # Only record if we have data from before_step\n",
    "            if self.grad_before is not None and self.loss_value is not None:\n",
    "                # Capture embeddings\n",
    "                W = model.transformer.wte.weight.data.clone().cpu().float()\n",
    "\n",
    "                # Capture Adam state\n",
    "                # Adam stores state in optimizer.state[param]\n",
    "                # We need to find which param corresponds to wte.weight\n",
    "                param = model.transformer.wte.weight\n",
    "                if param in optimizer.state:\n",
    "                    state = optimizer.state[param]\n",
    "                    # exp_avg = first moment (momentum)\n",
    "                    # exp_avg_sq = second moment (variance)\n",
    "                    mom = state['exp_avg'].clone().cpu().float()\n",
    "                    var = state['exp_avg_sq'].clone().cpu().float()\n",
    "                else:\n",
    "                    # Optimizer hasn't initialized state yet (shouldn't happen after step 1)\n",
    "                    mom = torch.zeros_like(W)\n",
    "                    var = torch.zeros_like(W)\n",
    "\n",
    "                # Store everything\n",
    "                self.recorded_steps.append(self.current_step)\n",
    "                self.embeddings.append(W)\n",
    "                self.grads.append(self.grad_before)\n",
    "                self.momentum.append(mom)\n",
    "                self.variance.append(var)\n",
    "                self.logits.append(self.logits_sample)\n",
    "                self.losses.append(torch.tensor(self.loss_value))\n",
    "\n",
    "                # Clear temp storage\n",
    "                self.grad_before = None\n",
    "                self.loss_value = None\n",
    "                self.logits_sample = None\n",
    "\n",
    "        self.current_step += 1\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"Return recorded data as tensors.\"\"\"\n",
    "        return {\n",
    "            'recorded_steps': torch.tensor(self.recorded_steps, dtype=torch.long),\n",
    "            'embeddings': torch.stack(self.embeddings) if self.embeddings else torch.tensor([]),\n",
    "            'grads': torch.stack(self.grads) if self.grads else torch.tensor([]),\n",
    "            'momentum': torch.stack(self.momentum) if self.momentum else torch.tensor([]),\n",
    "            'variance': torch.stack(self.variance) if self.variance else torch.tensor([]),\n",
    "            'logits': torch.stack(self.logits) if self.logits else torch.tensor([]),\n",
    "            'losses': torch.stack(self.losses) if self.losses else torch.tensor([]),\n",
    "        }\n",
    "\n",
    "print(\"✓ Recorder class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ InstrumentedTrainer defined\n"
     ]
    }
   ],
   "source": [
    "class InstrumentedTrainer(Trainer):\n",
    "    def __init__(self, recorder, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.recorder = recorder\n",
    "        self.last_logits = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"Override to capture logits.\"\"\"\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Store logits for recorder\n",
    "        self.last_logits = outputs.logits\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
    "        \"\"\"Override to inject recording.\"\"\"\n",
    "        # Standard forward + backward\n",
    "        loss = super().training_step(model, inputs, num_items_in_batch)\n",
    "        \n",
    "        # Record BEFORE optimizer step (gradients + loss + logits)\n",
    "        self.recorder.record_before_step(model, loss, self.last_logits)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time=None, **kwargs):\n",
    "        \"\"\"Override to record AFTER optimizer step.\"\"\"\n",
    "        # Record AFTER optimizer updates parameters\n",
    "        self.recorder.record_after_step(model, self.optimizer)\n",
    "        \n",
    "        # Call parent\n",
    "        super()._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, **kwargs)\n",
    "\n",
    "print(\"✓ InstrumentedTrainer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Trainer ready\n"
     ]
    }
   ],
   "source": [
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "recorder = ComprehensiveRecorder(VOCAB_SIZE, HIDDEN_DIM, RECORD_EVERY_N_STEPS)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_steps=NUM_TRAIN_STEPS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    gradient_accumulation_steps=GRADIENT_ACCUMULATION,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    adam_beta1=ADAM_BETA1,\n",
    "    adam_beta2=ADAM_BETA2,\n",
    "    adam_epsilon=ADAM_EPSILON,\n",
    "    logging_steps=1000,\n",
    "    save_steps=NUM_TRAIN_STEPS + 1,  # Don't save checkpoints\n",
    "    save_total_limit=0,\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=False,\n",
    "    bf16=True,\n",
    "    seed=RANDOM_SEED,\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "trainer = InstrumentedTrainer(\n",
    "    recorder=recorder,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Initial State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording initial state (step 0)...\n",
      "✓ Step 0 recorded\n"
     ]
    }
   ],
   "source": [
    "print(\"Recording initial state (step 0)...\")\n",
    "recorder.record_initial_state(model, trainer.optimizer)\n",
    "print(f\"✓ Step 0 recorded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Starting comprehensive instrumented training\n",
      "  Steps: 10000 (plus initial step 0)\n",
      "  Recording: embeddings, gradients, Adam state, logits, loss\n",
      "  Expected file size: ~660 MB\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10000' max='10000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10000/10000 01:39, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.912000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.528800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.342200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.262200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.218400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.188400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.173900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.163500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.156100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.153800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "✓ Training complete (1.7 min)\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Starting comprehensive instrumented training\")\n",
    "print(f\"  Steps: {NUM_TRAIN_STEPS} (plus initial step 0)\")\n",
    "print(f\"  Recording: embeddings, gradients, Adam state, logits, loss\")\n",
    "print(f\"  Expected file size: ~660 MB\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ Training complete ({elapsed/60:.1f} min)\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Recorded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved to: ../data/comprehensive_run/comprehensive_training_data.safetensors\n",
      "  File size: 1316.1 MB\n",
      "  Recorded steps: 10001\n",
      "  Step range: 0 to 10001\n",
      "\n",
      "Shapes:\n",
      "  embeddings: torch.Size([10001, 128, 64])\n",
      "  grads: torch.Size([10001, 128, 64])\n",
      "  momentum: torch.Size([10001, 128, 64])\n",
      "  variance: torch.Size([10001, 128, 64])\n",
      "  logits: torch.Size([10001, 128])\n",
      "  losses: torch.Size([10001])\n"
     ]
    }
   ],
   "source": [
    "recorded_data = recorder.get_data()\n",
    "\n",
    "save_dict = {\n",
    "    'recorded_steps': recorded_data['recorded_steps'],\n",
    "    'dead_token_ids': torch.tensor(dead_token_ids, dtype=torch.long),\n",
    "    'live_token_ids': torch.tensor(live_token_ids, dtype=torch.long),\n",
    "    'embeddings': recorded_data['embeddings'],\n",
    "    'grads': recorded_data['grads'],\n",
    "    'momentum': recorded_data['momentum'],\n",
    "    'variance': recorded_data['variance'],\n",
    "    'logits': recorded_data['logits'],\n",
    "    'losses': recorded_data['losses'],\n",
    "    'init_sigma': torch.tensor(INIT_SIGMA, dtype=torch.float32),\n",
    "    'learning_rate': torch.tensor(LEARNING_RATE, dtype=torch.float32),\n",
    "    'weight_decay': torch.tensor(WEIGHT_DECAY, dtype=torch.float32),\n",
    "    'adam_beta1': torch.tensor(ADAM_BETA1, dtype=torch.float32),\n",
    "    'adam_beta2': torch.tensor(ADAM_BETA2, dtype=torch.float32),\n",
    "    'init_method_code': torch.tensor(0, dtype=torch.int32),  # 0=f32→bf16, 1=pure_bf16\n",
    "}\n",
    "\n",
    "output_path = Path(OUTPUT_DIR) / \"comprehensive_training_data.safetensors\"\n",
    "save_file(save_dict, output_path)\n",
    "\n",
    "file_size_mb = output_path.stat().st_size / 1e6\n",
    "\n",
    "print(f\"✓ Saved to: {output_path}\")\n",
    "print(f\"  File size: {file_size_mb:.1f} MB\")\n",
    "print(f\"  Recorded steps: {len(recorded_data['recorded_steps'])}\")\n",
    "print(f\"  Step range: {recorded_data['recorded_steps'][0]} to {recorded_data['recorded_steps'][-1]}\")\n",
    "print(f\"\\nShapes:\")\n",
    "print(f\"  embeddings: {recorded_data['embeddings'].shape}\")\n",
    "print(f\"  grads: {recorded_data['grads'].shape}\")\n",
    "print(f\"  momentum: {recorded_data['momentum'].shape}\")\n",
    "print(f\"  variance: {recorded_data['variance'].shape}\")\n",
    "print(f\"  logits: {recorded_data['logits'].shape}\")\n",
    "print(f\"  losses: {recorded_data['losses'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUICK VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "Embeddings evolution:\n",
      "  Step 0 centroid norm: 1.000153\n",
      "  Step 10000 centroid norm: 0.808508\n",
      "\n",
      "Gradient magnitudes:\n",
      "  Step 1 dead token grads (mean): 6.171330e-02\n",
      "\n",
      "Logits at step 1 (should be ~equal for all tokens):\n",
      "  Min: 7.6875\n",
      "  Max: 7.6875\n",
      "  Range: 0.0000\n",
      "  Std: 0.0000\n",
      "\n",
      "Loss evolution:\n",
      "  Step 1: 4.8520\n",
      "  Step 10000: 2.1623\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"QUICK VERIFICATION\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "embeddings = recorded_data['embeddings']\n",
    "grads = recorded_data['grads']\n",
    "logits_vec = recorded_data['logits']\n",
    "losses = recorded_data['losses']\n",
    "\n",
    "if len(embeddings) > 1:\n",
    "    print(f\"Embeddings evolution:\")\n",
    "    print(f\"  Step 0 centroid norm: {embeddings[0].mean(dim=0).norm().item():.6f}\")\n",
    "    print(f\"  Step {NUM_TRAIN_STEPS} centroid norm: {embeddings[-1].mean(dim=0).norm().item():.6f}\")\n",
    "    \n",
    "    print(f\"\\nGradient magnitudes:\")\n",
    "    dead_grads_step1 = grads[1, dead_token_ids, :]\n",
    "    print(f\"  Step 1 dead token grads (mean): {torch.norm(dead_grads_step1, p=2, dim=1).mean().item():.6e}\")\n",
    "    \n",
    "    print(f\"\\nLogits at step 1 (should be ~equal for all tokens):\")\n",
    "    logits_step1 = logits_vec[1]\n",
    "    print(f\"  Min: {logits_step1.min().item():.4f}\")\n",
    "    print(f\"  Max: {logits_step1.max().item():.4f}\")\n",
    "    print(f\"  Range: {(logits_step1.max() - logits_step1.min()).item():.4f}\")\n",
    "    print(f\"  Std: {logits_step1.std().item():.4f}\")\n",
    "    \n",
    "    print(f\"\\nLoss evolution:\")\n",
    "    print(f\"  Step 1: {losses[1].item():.4f}\")\n",
    "    print(f\"  Step {NUM_TRAIN_STEPS}: {losses[-1].item():.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook records the complete training history:\n",
    "\n",
    "- **Embeddings**: Actual token positions (no reconstruction needed)\n",
    "- **Gradients**: Instantaneous forces from loss function\n",
    "- **Adam momentum**: Inertial velocity built up from past gradients\n",
    "- **Adam variance**: Adaptive per-parameter learning rate scaling\n",
    "- **Logits**: Model predictions at one position per step\n",
    "- **Loss**: Training objective value\n",
    "\n",
    "This lets us analyze:\n",
    "1. Token trajectories and velocities\n",
    "2. Force decomposition (gradient vs momentum)\n",
    "3. Prediction evolution (logits over time)\n",
    "4. Whether early logits are uniform (Jeffery's hypothesis)\n",
    "5. How optimizer momentum affects dead token motion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
