{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.20c: Flannel 3 - Ten Big Bangs (Full Dataset)\n",
    "\n",
    "**Experiment:** Exact replica of Flannel 1 (1.20a) run 10 times sequentially with different seeds.\n",
    "\n",
    "## Motivation\n",
    "\n",
    "Test reproducibility of the five epochs observed in Flannel 1:\n",
    "1. **The Inhale** (t=0–6): Slight contraction\n",
    "2. **The Sneeze** (t=6–100): Explosive outward expansion\n",
    "3. **Deceleration** (t=100–300): Rapid slowing\n",
    "4. **Re-expansion** (t=300–400): Linear second growth\n",
    "5. **Fimbulwinter** (t=400+): Quantization freeze\n",
    "\n",
    "## Design\n",
    "\n",
    "**Exact copy of 1.20a, but:**\n",
    "- Run 10 times sequentially\n",
    "- Seeds: 42, 43, 44, ..., 51\n",
    "- Full ComprehensiveRecorder for each run (embeddings, grads, momentum, variance, logits, losses)\n",
    "- Save all runs in one file\n",
    "\n",
    "**Expected output:**\n",
    "- File size: ~12 GB (10 runs × 1.2 GB per run)\n",
    "- Data structure: Separate tensors for each run, combined in one safetensors file\n",
    "- Total runtime: ~5 minutes (10 runs × 30s each)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parameters set\n"
     ]
    }
   ],
   "source": [
    "# Model architecture (identical to Flannel 1)\n",
    "VOCAB_SIZE = 10000\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYER = 2\n",
    "N_HEAD = 2\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# Training (identical to Flannel 1)\n",
    "BATCH_SIZE = 32\n",
    "NUM_TRAIN_STEPS = 1000\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 0.0\n",
    "\n",
    "# Optimizer: Adam\n",
    "ADAM_BETA1 = 0.9\n",
    "ADAM_BETA2 = 0.999\n",
    "ADAM_EPSILON = 1e-8\n",
    "\n",
    "# Initialization\n",
    "INIT_SCALE = 0.02  # N(0, 0.02)\n",
    "\n",
    "# Batch experiment\n",
    "NUM_RUNS = 10\n",
    "BASE_SEED = 42  # Seeds: 42, 43, 44, ..., 51\n",
    "\n",
    "# Data\n",
    "TOKENIZER_PATH = \"../data/flannel_tokenizer_chars.json\"\n",
    "CORPUS_PATH = \"../data/flannel_model_corpus.txt\"\n",
    "TOKEN_MASK_PATH = \"../tensors/Flannel/live_dead_tokens.safetensors\"\n",
    "OUTPUT_DIR = \"../tensors/Flannel\"\n",
    "OUTPUT_FILE = \"1.20c_flannel_3.safetensors\"\n",
    "\n",
    "# Recording\n",
    "RECORD_EVERY_N_STEPS = 1  # Every step\n",
    "\n",
    "print(\"✓ Parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from tokenizers import Tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from safetensors.torch import save_file, load_file\n",
    "import time\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Flannel tokenizer: ../data/flannel_tokenizer_chars.json\n",
      "\n",
      "✓ Loaded Flannel tokenizer\n",
      "  Vocabulary size: 10,000 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading Flannel tokenizer: {TOKENIZER_PATH}\\n\")\n",
    "\n",
    "tokenizer = Tokenizer.from_file(str(TOKENIZER_PATH))\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "print(f\"✓ Loaded Flannel tokenizer\")\n",
    "print(f\"  Vocabulary size: {len(vocab):,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading corpus: ../data/flannel_model_corpus.txt\n",
      "\n",
      "✓ Loaded corpus\n",
      "  Size: 5.01 MB\n",
      "  Characters: 5,225,690\n",
      "\n",
      "Tokenizing corpus...\n",
      "\n",
      "✓ Tokenized\n",
      "  Tokens: 1,371,328\n",
      "\n",
      "✓ Corpus on device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoading corpus: {CORPUS_PATH}\\n\")\n",
    "\n",
    "with open(CORPUS_PATH, 'r', encoding='utf-8') as f:\n",
    "    corpus_text = f.read()\n",
    "\n",
    "corpus_bytes = len(corpus_text.encode('utf-8'))\n",
    "corpus_mb = corpus_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"✓ Loaded corpus\")\n",
    "print(f\"  Size: {corpus_mb:.2f} MB\")\n",
    "print(f\"  Characters: {len(corpus_text):,}\")\n",
    "print()\n",
    "\n",
    "# Tokenize\n",
    "print(\"Tokenizing corpus...\\n\")\n",
    "encoding = tokenizer.encode(corpus_text)\n",
    "tokens = encoding.ids\n",
    "\n",
    "print(f\"✓ Tokenized\")\n",
    "print(f\"  Tokens: {len(tokens):,}\")\n",
    "print()\n",
    "\n",
    "# Pre-load to device\n",
    "corpus_tensor = torch.tensor(tokens, dtype=torch.long, device=device)\n",
    "print(f\"✓ Corpus on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Token Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading token masks: ../tensors/Flannel/live_dead_tokens.safetensors\n",
      "\n",
      "✓ Loaded token masks\n",
      "  Live tokens: 6,301 (63.0%)\n",
      "  Dead tokens: 3,699 (37.0%)\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoading token masks: {TOKEN_MASK_PATH}\\n\")\n",
    "\n",
    "mask_data = load_file(TOKEN_MASK_PATH)\n",
    "live_mask = mask_data['live_mask']\n",
    "dead_mask = mask_data['dead_mask']\n",
    "live_indices = mask_data['live_indices']\n",
    "dead_indices = mask_data['dead_indices']\n",
    "\n",
    "n_live = live_mask.sum().item()\n",
    "n_dead = dead_mask.sum().item()\n",
    "\n",
    "print(f\"✓ Loaded token masks\")\n",
    "print(f\"  Live tokens: {n_live:,} ({100*n_live/VOCAB_SIZE:.1f}%)\")\n",
    "print(f\"  Dead tokens: {n_dead:,} ({100*n_dead/VOCAB_SIZE:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Dataset: 1,371,200 examples\n"
     ]
    }
   ],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, corpus_tensor, max_seq_len):\n",
    "        self.corpus = corpus_tensor\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(0, len(self.corpus) - self.max_seq_len)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.corpus[idx : idx + self.max_seq_len + 1]\n",
    "        return {\n",
    "            'input_ids': chunk[:-1],\n",
    "            'labels': chunk[1:]\n",
    "        }\n",
    "\n",
    "dataset = TokenDataset(corpus_tensor, MAX_SEQ_LEN)\n",
    "print(f\"\\n✓ Dataset: {len(dataset):,} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Recorder (from 1.20a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Recorder class defined\n"
     ]
    }
   ],
   "source": [
    "class ComprehensiveRecorder:\n",
    "    \"\"\"Records embeddings, gradients, optimizer state, logits, loss at every step in bfloat16.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_dim, record_every_n):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.record_every_n = record_every_n\n",
    "        \n",
    "        # Storage (lists of tensors, keep in RAM)\n",
    "        self.recorded_steps = []\n",
    "        self.embeddings = []      # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.grads = []           # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.momentum = []        # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.variance = []        # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.logits = []          # [n_recorded, vocab_size]\n",
    "        self.losses = []          # [n_recorded]\n",
    "        \n",
    "        # Temporary storage\n",
    "        self.current_step = 0\n",
    "        self.recorded_initial = False\n",
    "        self.grad_before = None\n",
    "        self.loss_value = None\n",
    "        self.logits_sample = None\n",
    "    \n",
    "    def record_initial_state(self, model, optimizer):\n",
    "        \"\"\"Record step 0: initial state before training.\"\"\"\n",
    "        if not self.recorded_initial:\n",
    "            W = model.transformer.wte.weight.data.clone().cpu().bfloat16()\n",
    "            \n",
    "            # Step 0: no gradients, no optimizer state yet (zeros)\n",
    "            self.recorded_steps.append(0)\n",
    "            self.embeddings.append(W)\n",
    "            self.grads.append(torch.zeros_like(W))\n",
    "            self.momentum.append(torch.zeros_like(W))\n",
    "            self.variance.append(torch.zeros_like(W))\n",
    "            self.logits.append(torch.zeros(self.vocab_size, dtype=torch.bfloat16))\n",
    "            self.losses.append(torch.tensor(float('nan'), dtype=torch.bfloat16))  # No loss yet\n",
    "            \n",
    "            self.recorded_initial = True\n",
    "            self.current_step = 1\n",
    "            \n",
    "            print(f\"    ✓ Recorded initial state (step 0)\")\n",
    "    \n",
    "    def record_before_step(self, model, loss, logits):\n",
    "        \"\"\"Call after forward/backward, before optimizer step.\"\"\"\n",
    "        if self.current_step % self.record_every_n == 0:\n",
    "            # Capture gradients in bfloat16\n",
    "            if model.transformer.wte.weight.grad is not None:\n",
    "                self.grad_before = model.transformer.wte.weight.grad.clone().cpu().bfloat16()\n",
    "            else:\n",
    "                self.grad_before = torch.zeros(self.vocab_size, self.hidden_dim, dtype=torch.bfloat16)\n",
    "            \n",
    "            # Capture loss\n",
    "            self.loss_value = loss.item()\n",
    "            \n",
    "            # Capture logits from first sequence, last position in bfloat16\n",
    "            self.logits_sample = logits[0, -1, :].detach().cpu().bfloat16()\n",
    "    \n",
    "    def record_after_step(self, model, optimizer):\n",
    "        \"\"\"Call after optimizer step.\"\"\"\n",
    "        if self.current_step % self.record_every_n == 0:\n",
    "            if self.grad_before is not None and self.loss_value is not None:\n",
    "                # Capture embeddings in bfloat16\n",
    "                W = model.transformer.wte.weight.data.clone().cpu().bfloat16()\n",
    "\n",
    "                # Capture optimizer state (Adam momentum and variance)\n",
    "                param = model.transformer.wte.weight\n",
    "                if param in optimizer.state:\n",
    "                    state = optimizer.state[param]\n",
    "                    # Get state tensors if they exist, convert to bfloat16\n",
    "                    mom_src = state.get('exp_avg', None)\n",
    "                    var_src = state.get('exp_avg_sq', None)\n",
    "                    mom = mom_src.clone().cpu().bfloat16() if mom_src is not None else torch.zeros_like(W)\n",
    "                    var = var_src.clone().cpu().bfloat16() if var_src is not None else torch.zeros_like(W)\n",
    "                else:\n",
    "                    mom = torch.zeros_like(W)\n",
    "                    var = torch.zeros_like(W)\n",
    "\n",
    "                # Store everything\n",
    "                self.recorded_steps.append(self.current_step)\n",
    "                self.embeddings.append(W)\n",
    "                self.grads.append(self.grad_before)\n",
    "                self.momentum.append(mom)\n",
    "                self.variance.append(var)\n",
    "                self.logits.append(self.logits_sample)\n",
    "                self.losses.append(torch.tensor(self.loss_value, dtype=torch.bfloat16))\n",
    "\n",
    "                # Clear temp storage\n",
    "                self.grad_before = None\n",
    "                self.loss_value = None\n",
    "                self.logits_sample = None\n",
    "                \n",
    "                # Progress indicator every 100 steps\n",
    "                if self.current_step % 100 == 0:\n",
    "                    print(f\"    Step {self.current_step}\")\n",
    "\n",
    "        self.current_step += 1\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"Return recorded data as stacked tensors.\"\"\"\n",
    "        print(f\"    Stacking {len(self.embeddings)} recorded states...\")\n",
    "        \n",
    "        return {\n",
    "            'recorded_steps': torch.tensor(self.recorded_steps, dtype=torch.long),\n",
    "            'embeddings': torch.stack(self.embeddings) if self.embeddings else torch.tensor([]),\n",
    "            'grads': torch.stack(self.grads) if self.grads else torch.tensor([]),\n",
    "            'momentum': torch.stack(self.momentum) if self.momentum else torch.tensor([]),\n",
    "            'variance': torch.stack(self.variance) if self.variance else torch.tensor([]),\n",
    "            'logits': torch.stack(self.logits) if self.logits else torch.tensor([]),\n",
    "            'losses': torch.stack(self.losses) if self.losses else torch.tensor([]),\n",
    "        }\n",
    "\n",
    "print(\"✓ Recorder class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Trainer with Instrumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ InstrumentedTrainer defined\n"
     ]
    }
   ],
   "source": [
    "class InstrumentedTrainer(Trainer):\n",
    "    def __init__(self, recorder, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.recorder = recorder\n",
    "        self.last_logits = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"Override to capture logits.\"\"\"\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Store logits for recorder\n",
    "        self.last_logits = outputs.logits\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
    "        \"\"\"Override to inject recording.\"\"\"\n",
    "        # Standard forward + backward\n",
    "        loss = super().training_step(model, inputs, num_items_in_batch)\n",
    "        \n",
    "        # Record BEFORE optimizer step\n",
    "        self.recorder.record_before_step(model, loss, self.last_logits)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time=None, **kwargs):\n",
    "        \"\"\"Override to record AFTER optimizer step.\"\"\"\n",
    "        # Record AFTER optimizer updates parameters\n",
    "        self.recorder.record_after_step(model, self.optimizer)\n",
    "        \n",
    "        # Call parent\n",
    "        super()._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, **kwargs)\n",
    "\n",
    "print(\"✓ InstrumentedTrainer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FLANNEL 3: TEN BIG BANGS (FULL DATASET)\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Runs: 10\n",
      "  Steps per run: 1,000\n",
      "  Seeds: 42–51\n",
      "  Recording: full ComprehensiveRecorder (embeddings, grads, momentum, variance, logits, losses)\n",
      "  Expected file size: ~12 GB\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RUN 1/10 (seed=42)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=42)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1299, 'grad_norm': 0.2177734375, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.9053, 'train_samples_per_second': 1235.269, 'train_steps_per_second': 38.602, 'train_loss': 7.12989404296875, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 1 complete (26.0s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "RUN 2/10 (seed=43)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=43)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1002, 'grad_norm': 0.275390625, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.2983, 'train_samples_per_second': 1264.909, 'train_steps_per_second': 39.528, 'train_loss': 7.10022265625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 2 complete (25.4s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "RUN 3/10 (seed=44)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=44)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1005, 'grad_norm': 0.2470703125, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.4104, 'train_samples_per_second': 1259.329, 'train_steps_per_second': 39.354, 'train_loss': 7.10053759765625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 3 complete (25.5s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "RUN 4/10 (seed=45)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=45)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1106, 'grad_norm': 0.26171875, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.5564, 'train_samples_per_second': 1252.132, 'train_steps_per_second': 39.129, 'train_loss': 7.1105634765625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 4 complete (25.6s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "RUN 5/10 (seed=46)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=46)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1435, 'grad_norm': 0.1904296875, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.6968, 'train_samples_per_second': 1245.29, 'train_steps_per_second': 38.915, 'train_loss': 7.14353564453125, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 5 complete (25.8s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "RUN 6/10 (seed=47)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=47)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1018, 'grad_norm': 0.2578125, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.856, 'train_samples_per_second': 1237.625, 'train_steps_per_second': 38.676, 'train_loss': 7.1017978515625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 6 complete (25.9s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "RUN 7/10 (seed=48)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=48)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1179, 'grad_norm': 0.259765625, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.8572, 'train_samples_per_second': 1237.566, 'train_steps_per_second': 38.674, 'train_loss': 7.11792431640625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 7 complete (25.9s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "RUN 8/10 (seed=49)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=49)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1226, 'grad_norm': 0.2333984375, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.4637, 'train_samples_per_second': 1256.691, 'train_steps_per_second': 39.272, 'train_loss': 7.1226103515625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 8 complete (25.5s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "RUN 9/10 (seed=50)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=50)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.0951, 'grad_norm': 0.2734375, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.5888, 'train_samples_per_second': 1250.547, 'train_steps_per_second': 39.08, 'train_loss': 7.09510791015625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 9 complete (25.7s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "RUN 10/10 (seed=51)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=51)\n",
      "    ✓ Recorded initial state (step 0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1065, 'grad_norm': 0.2470703125, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.4483, 'train_samples_per_second': 1257.453, 'train_steps_per_second': 39.295, 'train_loss': 7.10651904296875, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 10 complete (25.5s)\n",
      "    Stacking 1001 recorded states...\n",
      "\n",
      "================================================================================\n",
      "✓ All 10 runs complete\n",
      "  Total time: 273.6s (4.6 minutes)\n",
      "  Average per run: 27.4s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FLANNEL 3: TEN BIG BANGS (FULL DATASET)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Runs: {NUM_RUNS}\")\n",
    "print(f\"  Steps per run: {NUM_TRAIN_STEPS:,}\")\n",
    "print(f\"  Seeds: {BASE_SEED}–{BASE_SEED + NUM_RUNS - 1}\")\n",
    "print(f\"  Recording: full ComprehensiveRecorder (embeddings, grads, momentum, variance, logits, losses)\")\n",
    "print(f\"  Expected file size: ~12 GB\")\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "# Storage for all runs\n",
    "all_runs_data = []\n",
    "\n",
    "experiment_start = time.time()\n",
    "\n",
    "for run_idx in range(NUM_RUNS):\n",
    "    seed = BASE_SEED + run_idx\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RUN {run_idx + 1}/{NUM_RUNS} (seed={seed})\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Set seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create fresh model\n",
    "    config = GPT2Config(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        n_positions=MAX_SEQ_LEN,\n",
    "        n_embd=HIDDEN_DIM,\n",
    "        n_layer=N_LAYER,\n",
    "        n_head=N_HEAD,\n",
    "        resid_pdrop=0.0,\n",
    "        embd_pdrop=0.0,\n",
    "        attn_pdrop=0.0,\n",
    "        tie_word_embeddings=True,\n",
    "    )\n",
    "    \n",
    "    model = GPT2LMHeadModel(config)\n",
    "    model = model.to(torch.bfloat16).to(device)\n",
    "    \n",
    "    # Initialize embeddings\n",
    "    init_f32 = torch.randn(VOCAB_SIZE, HIDDEN_DIM, dtype=torch.float32, device=device) * INIT_SCALE\n",
    "    init_bf16 = init_f32.to(torch.bfloat16)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.transformer.wte.weight[:] = init_bf16\n",
    "    \n",
    "    print(f\"  ✓ Model initialized (seed={seed})\")\n",
    "    \n",
    "    # Create recorder\n",
    "    recorder = ComprehensiveRecorder(VOCAB_SIZE, HIDDEN_DIM, RECORD_EVERY_N_STEPS)\n",
    "    \n",
    "    # Training args\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        max_steps=NUM_TRAIN_STEPS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        adam_beta1=ADAM_BETA1,\n",
    "        adam_beta2=ADAM_BETA2,\n",
    "        adam_epsilon=ADAM_EPSILON,\n",
    "        optim=\"adamw_torch\",\n",
    "        logging_steps=1000,  # Minimal logging\n",
    "        save_steps=NUM_TRAIN_STEPS + 1,\n",
    "        save_total_limit=0,\n",
    "        dataloader_num_workers=0,\n",
    "        dataloader_pin_memory=False,\n",
    "        bf16=True,\n",
    "        seed=seed,\n",
    "        report_to=\"none\",\n",
    "        disable_tqdm=True,  # Quieter output\n",
    "    )\n",
    "    \n",
    "    trainer = InstrumentedTrainer(\n",
    "        recorder=recorder,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "    )\n",
    "    \n",
    "    # Record initial state\n",
    "    recorder.record_initial_state(model, trainer.optimizer)\n",
    "    \n",
    "    # Train\n",
    "    print(f\"  Training...\")\n",
    "    run_start = time.time()\n",
    "    trainer.train()\n",
    "    run_elapsed = time.time() - run_start\n",
    "    \n",
    "    print(f\"\\n  ✓ Run {run_idx + 1} complete ({run_elapsed:.1f}s)\")\n",
    "    \n",
    "    # Collect data\n",
    "    run_data = recorder.get_data()\n",
    "    all_runs_data.append(run_data)\n",
    "    \n",
    "    # Clean up\n",
    "    del model\n",
    "    del trainer\n",
    "    del recorder\n",
    "    \n",
    "    if device == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "    elif device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "experiment_elapsed = time.time() - experiment_start\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ All {NUM_RUNS} runs complete\")\n",
    "print(f\"  Total time: {experiment_elapsed:.1f}s ({experiment_elapsed/60:.1f} minutes)\")\n",
    "print(f\"  Average per run: {experiment_elapsed/NUM_RUNS:.1f}s\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine and Save All Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combining 10 runs into single file...\n",
      "\n",
      "  Run 0: torch.Size([1001, 10000, 64])\n",
      "  Run 1: torch.Size([1001, 10000, 64])\n",
      "  Run 2: torch.Size([1001, 10000, 64])\n",
      "  Run 3: torch.Size([1001, 10000, 64])\n",
      "  Run 4: torch.Size([1001, 10000, 64])\n",
      "  Run 5: torch.Size([1001, 10000, 64])\n",
      "  Run 6: torch.Size([1001, 10000, 64])\n",
      "  Run 7: torch.Size([1001, 10000, 64])\n",
      "  Run 8: torch.Size([1001, 10000, 64])\n",
      "  Run 9: torch.Size([1001, 10000, 64])\n",
      "\n",
      "Saving to: ../tensors/Flannel/1.20c_flannel_3.safetensors\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSaving to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     36\u001b[39m save_start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m \u001b[43msave_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m save_elapsed = time.time() - save_start\n\u001b[32m     40\u001b[39m file_size_mb = output_path.stat().st_size / \u001b[32m1e6\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Azimuth_II/.venv/lib/python3.12/site-packages/safetensors/torch.py:352\u001b[39m, in \u001b[36msave_file\u001b[39m\u001b[34m(tensors, filename, metadata)\u001b[39m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_file\u001b[39m(\n\u001b[32m    322\u001b[39m     tensors: Dict[\u001b[38;5;28mstr\u001b[39m, torch.Tensor],\n\u001b[32m    323\u001b[39m     filename: Union[\u001b[38;5;28mstr\u001b[39m, os.PathLike],\n\u001b[32m    324\u001b[39m     metadata: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    325\u001b[39m ):\n\u001b[32m    326\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    327\u001b[39m \u001b[33;03m    Saves a dictionary of tensors into raw bytes in safetensors format.\u001b[39;00m\n\u001b[32m    328\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    351\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     serialize_file(\u001b[43m_flatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m)\u001b[49m, filename, metadata=metadata)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Azimuth_II/.venv/lib/python3.12/site-packages/safetensors/torch.py:589\u001b[39m, in \u001b[36m_flatten\u001b[39m\u001b[34m(tensors)\u001b[39m\n\u001b[32m    576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m failing:\n\u001b[32m    577\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    578\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    579\u001b[39m \u001b[33m        Some tensors share memory, this will lead to duplicate memory on disk and potential differences when loading them again: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfailing\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    582\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    583\u001b[39m     )\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    586\u001b[39m     k: {\n\u001b[32m    587\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(v.dtype).split(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)[-\u001b[32m1\u001b[39m],\n\u001b[32m    588\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mshape\u001b[39m\u001b[33m\"\u001b[39m: v.shape,\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43m_tobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    590\u001b[39m     }\n\u001b[32m    591\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m tensors.items()\n\u001b[32m    592\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Projects/Azimuth_II/.venv/lib/python3.12/site-packages/safetensors/torch.py:545\u001b[39m, in \u001b[36m_tobytes\u001b[39m\u001b[34m(tensor, name)\u001b[39m\n\u001b[32m    543\u001b[39m     \u001b[38;5;66;03m# Not in place as that would potentially modify a live running model\u001b[39;00m\n\u001b[32m    544\u001b[39m     data = data.view(npdtype).byteswap(inplace=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(f\"\\nCombining {NUM_RUNS} runs into single file...\\n\")\n",
    "\n",
    "# Build save dictionary with run-indexed keys\n",
    "save_dict = {\n",
    "    'n_runs': torch.tensor(NUM_RUNS, dtype=torch.long),\n",
    "    'base_seed': torch.tensor(BASE_SEED, dtype=torch.long),\n",
    "    'n_steps': torch.tensor(NUM_TRAIN_STEPS, dtype=torch.long),\n",
    "    'n_live': torch.tensor(n_live, dtype=torch.long),\n",
    "    'n_dead': torch.tensor(n_dead, dtype=torch.long),\n",
    "    'init_scale': torch.tensor(INIT_SCALE, dtype=torch.float32),\n",
    "    'learning_rate': torch.tensor(LEARNING_RATE, dtype=torch.float32),\n",
    "    'weight_decay': torch.tensor(WEIGHT_DECAY, dtype=torch.float32),\n",
    "    'adam_beta1': torch.tensor(ADAM_BETA1, dtype=torch.float32),\n",
    "    'adam_beta2': torch.tensor(ADAM_BETA2, dtype=torch.float32),\n",
    "}\n",
    "\n",
    "# Add each run's data with indexed keys\n",
    "for run_idx, run_data in enumerate(all_runs_data):\n",
    "    save_dict[f'run_{run_idx}_recorded_steps'] = run_data['recorded_steps']\n",
    "    save_dict[f'run_{run_idx}_embeddings'] = run_data['embeddings']\n",
    "    save_dict[f'run_{run_idx}_grads'] = run_data['grads']\n",
    "    save_dict[f'run_{run_idx}_momentum'] = run_data['momentum']\n",
    "    save_dict[f'run_{run_idx}_variance'] = run_data['variance']\n",
    "    save_dict[f'run_{run_idx}_logits'] = run_data['logits']\n",
    "    save_dict[f'run_{run_idx}_losses'] = run_data['losses']\n",
    "    print(f\"  Run {run_idx}: {run_data['embeddings'].shape}\")\n",
    "\n",
    "print()\n",
    "\n",
    "# Save\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "output_path = Path(OUTPUT_DIR) / OUTPUT_FILE\n",
    "\n",
    "print(f\"Saving to: {output_path}\\n\")\n",
    "\n",
    "save_start = time.time()\n",
    "save_file(save_dict, str(output_path))\n",
    "save_elapsed = time.time() - save_start\n",
    "\n",
    "file_size_mb = output_path.stat().st_size / 1e6\n",
    "file_size_gb = file_size_mb / 1000\n",
    "\n",
    "print(f\"✓ Saved successfully\")\n",
    "print(f\"  File: {output_path}\")\n",
    "print(f\"  Size: {file_size_mb:.1f} MB ({file_size_gb:.2f} GB)\")\n",
    "print(f\"  Save time: {save_elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FLANNEL 3 COMPLETE\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Experiment: Ten independent training runs (full dataset)\")\n",
    "print(f\"  Runs: {NUM_RUNS}\")\n",
    "print(f\"  Steps per run: {NUM_TRAIN_STEPS:,}\")\n",
    "print(f\"  Seeds: {BASE_SEED}–{BASE_SEED + NUM_RUNS - 1}\")\n",
    "print()\n",
    "print(f\"Data saved: {output_path}\")\n",
    "print(f\"  Size: {file_size_gb:.2f} GB\")\n",
    "print(f\"  Total experiment time: {experiment_elapsed/60:.1f} minutes\")\n",
    "print()\n",
    "print(f\"Next steps:\")\n",
    "print(f\"  1. Run 1.22d_flannel_3_prelim (updated to load this new format)\")\n",
    "print(f\"  2. Verify run 0 (seed=42) matches Flannel 1 exactly\")\n",
    "print(f\"  3. Analyze epoch reproducibility across runs\")\n",
    "print(f\"  4. Deeper statistical mechanics analysis\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
