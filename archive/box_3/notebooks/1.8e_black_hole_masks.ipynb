{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 1.8e: Black Hole Masks\n",
    "\n",
    "We discovered 4 black holes in the core (2,179 tokens sitting at r = 0.00007553):\n",
    "1. BH1: 866 tokens at (x=-ε, y=0, z=0)\n",
    "2. BH2: 734 tokens at (x=+ε, y=+ε, z=0)\n",
    "3. BH3: 329 tokens at (x=+ε, y=0, z=0)\n",
    "4. BH4: 249 tokens at (x=-ε, y=+ε, z=0)\n",
    "\n",
    "Where ε ≈ 1.526e-5 (1 ULP in bfloat16).\n",
    "\n",
    "**Goal:** Create reusable masks and metadata for the black hole tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to analyze\n",
    "MODEL_NAME = \"Qwen3-4B-Instruct-2507\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ml_dtypes\n",
    "import numpy as np\n",
    "from safetensors.torch import load_file, save_file\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_bf16_to_numpy_bf16(tensor):\n",
    "    \"\"\"Convert PyTorch bfloat16 tensor to numpy array with ml_dtypes.bfloat16 dtype.\"\"\"\n",
    "    return tensor.cpu().view(torch.uint16).numpy().view(ml_dtypes.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded core: 2,179 tokens\n",
      "Basis dimensions: x=322, y=1564, z=163\n"
     ]
    }
   ],
   "source": [
    "# Load W in bfloat16\n",
    "W_path = Path(f\"../tensors/{MODEL_NAME}/W.safetensors\")\n",
    "W_bf16 = load_file(W_path)[\"W\"]\n",
    "\n",
    "# Load core data\n",
    "core_path = Path(f\"../tensors/{MODEL_NAME}/1.8a_core.safetensors\")\n",
    "core_data = load_file(core_path)\n",
    "\n",
    "core_mask = core_data[\"core_mask\"].to(torch.bool)\n",
    "core_token_ids = core_data[\"core_token_ids\"].to(torch.int64)\n",
    "n_core = core_data[\"n_core\"].item()\n",
    "\n",
    "# Basis indices\n",
    "north_idx = core_data[\"north_idx\"].item()\n",
    "meridian_idx = core_data[\"meridian_idx\"].item()\n",
    "equinox_idx = core_data[\"equinox_idx\"].item()\n",
    "\n",
    "print(f\"Loaded core: {n_core:,} tokens\")\n",
    "print(f\"Basis dimensions: x={meridian_idx}, y={equinox_idx}, z={north_idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Compute Centered Coordinates (bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing centered coordinates...\n",
      "\n",
      "✓ Computed centered coordinates in bfloat16\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing centered coordinates...\\n\")\n",
    "\n",
    "# Extract core and center\n",
    "W_core_bf16 = W_bf16[core_mask]\n",
    "core_centroid_bf16 = W_core_bf16.mean(dim=0)\n",
    "W_core_centered_bf16 = W_core_bf16 - core_centroid_bf16\n",
    "\n",
    "# Extract coordinates for basis dimensions\n",
    "x_bf16 = W_core_centered_bf16[:, meridian_idx]\n",
    "y_bf16 = W_core_centered_bf16[:, equinox_idx]\n",
    "z_bf16 = W_core_centered_bf16[:, north_idx]\n",
    "r_squared_bf16 = x_bf16**2 + y_bf16**2 + z_bf16**2\n",
    "\n",
    "print(\"✓ Computed centered coordinates in bfloat16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Group by Coordinates to Find Black Holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouping tokens by coordinates...\n",
      "\n",
      "Found 4 black holes\n",
      "  BH1:  866 tokens at (x=-1.525879e-05, y=0.000000e+00, z=0.000000e+00)\n",
      "  BH2:  734 tokens at (x=1.525879e-05, y=1.525879e-05, z=0.000000e+00)\n",
      "  BH3:  329 tokens at (x=1.525879e-05, y=0.000000e+00, z=0.000000e+00)\n",
      "  BH4:  249 tokens at (x=-1.525879e-05, y=1.525879e-05, z=0.000000e+00)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGrouping tokens by coordinates...\\n\")\n",
    "\n",
    "# Create coordinate tuples\n",
    "coords_bf16 = torch.stack([r_squared_bf16, x_bf16, y_bf16, z_bf16], dim=1)\n",
    "coords_np_bf16 = torch_bf16_to_numpy_bf16(coords_bf16)\n",
    "\n",
    "# Group tokens\n",
    "coord_groups = defaultdict(list)\n",
    "for i in range(n_core):\n",
    "    coord_tuple = tuple(coords_np_bf16[i])\n",
    "    coord_groups[coord_tuple].append(i)\n",
    "\n",
    "# Get black holes (groups with >1 token)\n",
    "black_holes = [(coord, indices) for coord, indices in coord_groups.items() if len(indices) > 1]\n",
    "black_holes.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "n_black_holes = len(black_holes)\n",
    "print(f\"Found {n_black_holes} black holes\")\n",
    "for i, (coord, indices) in enumerate(black_holes, 1):\n",
    "    r2, x, y, z = coord\n",
    "    print(f\"  BH{i}: {len(indices):4,} tokens at (x={float(x):.6e}, y={float(y):.6e}, z={float(z):.6e})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Create Masks and Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating masks and metadata...\n",
      "\n",
      "BH1:  866 tokens (IDs 80091-149445)\n",
      "BH2:  734 tokens (IDs 125-151934)\n",
      "BH3:  329 tokens (IDs 124-151919)\n",
      "BH4:  249 tokens (IDs 123939-151935)\n",
      "\n",
      "Total black hole tokens: 2,178 (1.433% of vocab)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating masks and metadata...\\n\")\n",
    "\n",
    "# Get vocab size from W\n",
    "vocab_size = W_bf16.shape[0]\n",
    "\n",
    "# Initialize masks\n",
    "black_hole_mask = torch.zeros(vocab_size, dtype=torch.bool)\n",
    "black_hole_labels = torch.full((vocab_size,), -1, dtype=torch.int32)  # -1 = not a BH\n",
    "\n",
    "# Black hole sizes\n",
    "black_hole_sizes = torch.tensor([len(indices) for _, indices in black_holes], dtype=torch.int32)\n",
    "\n",
    "# Token IDs for each black hole (we'll store these separately)\n",
    "bh_token_ids = {}\n",
    "\n",
    "# Fill in the masks\n",
    "for bh_idx, (coord, core_indices) in enumerate(black_holes, 1):\n",
    "    # core_indices are indices into the core (2,179 tokens)\n",
    "    # We need to map them back to full vocab indices\n",
    "    \n",
    "    # Get the full vocab token IDs for this black hole\n",
    "    token_ids = core_token_ids[core_indices]\n",
    "    \n",
    "    # Mark them in the masks\n",
    "    black_hole_mask[token_ids] = True\n",
    "    black_hole_labels[token_ids] = bh_idx\n",
    "    \n",
    "    # Store token IDs\n",
    "    bh_token_ids[f\"bh{bh_idx}_token_ids\"] = token_ids\n",
    "    \n",
    "    print(f\"BH{bh_idx}: {len(token_ids):4,} tokens (IDs {token_ids.min().item()}-{token_ids.max().item()})\")\n",
    "\n",
    "n_bh_tokens = black_hole_mask.sum().item()\n",
    "print(f\"\\nTotal black hole tokens: {n_bh_tokens:,} ({n_bh_tokens/vocab_size*100:.3f}% of vocab)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Save to Safetensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving masks and metadata...\n",
      "\n",
      "✓ Saved to ../tensors/Qwen3-4B-Instruct-2507/1.8e_black_hole_masks.safetensors\n",
      "\n",
      "Contents:\n",
      "  black_hole_mask: torch.Size([151936]) (boolean mask for all BH tokens)\n",
      "  black_hole_labels: torch.Size([151936]) (BH number 1-4, or -1 for non-BH)\n",
      "  n_black_holes: scalar (4)\n",
      "  black_hole_sizes: torch.Size([4]) (sizes: [866, 734, 329, 249])\n",
      "  bh1_token_ids: torch.Size([866]) (token IDs for BH1)\n",
      "  bh2_token_ids: torch.Size([734]) (token IDs for BH2)\n",
      "  bh3_token_ids: torch.Size([329]) (token IDs for BH3)\n",
      "  bh4_token_ids: torch.Size([249]) (token IDs for BH4)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving masks and metadata...\\n\")\n",
    "\n",
    "output_path = Path(f\"../tensors/{MODEL_NAME}/1.8e_black_hole_masks.safetensors\")\n",
    "\n",
    "# Prepare data dict\n",
    "save_dict = {\n",
    "    'black_hole_mask': black_hole_mask,\n",
    "    'black_hole_labels': black_hole_labels,\n",
    "    'n_black_holes': torch.tensor(n_black_holes, dtype=torch.int32),\n",
    "    'black_hole_sizes': black_hole_sizes,\n",
    "}\n",
    "\n",
    "# Add individual BH token IDs\n",
    "save_dict.update(bh_token_ids)\n",
    "\n",
    "# Save\n",
    "save_file(save_dict, str(output_path))\n",
    "\n",
    "print(f\"✓ Saved to {output_path}\")\n",
    "print(f\"\\nContents:\")\n",
    "print(f\"  black_hole_mask: {black_hole_mask.shape} (boolean mask for all BH tokens)\")\n",
    "print(f\"  black_hole_labels: {black_hole_labels.shape} (BH number 1-4, or -1 for non-BH)\")\n",
    "print(f\"  n_black_holes: scalar ({n_black_holes})\")\n",
    "print(f\"  black_hole_sizes: {black_hole_sizes.shape} (sizes: {black_hole_sizes.tolist()})\")\n",
    "for i in range(1, n_black_holes + 1):\n",
    "    key = f\"bh{i}_token_ids\"\n",
    "    print(f\"  {key}: {save_dict[key].shape} (token IDs for BH{i})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUMMARY: BLACK HOLE MASKS\n",
      "============================================================\n",
      "\n",
      "Created masks for 4 black holes\n",
      "Total tokens in black holes: 2,178\n",
      "\n",
      "Black hole sizes:\n",
      "  BH1: 866 tokens\n",
      "  BH2: 734 tokens\n",
      "  BH3: 329 tokens\n",
      "  BH4: 249 tokens\n",
      "\n",
      "Saved to: ../tensors/Qwen3-4B-Instruct-2507/1.8e_black_hole_masks.safetensors\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY: BLACK HOLE MASKS\")\n",
    "print(\"=\"*60)\n",
    "print()\n",
    "print(f\"Created masks for {n_black_holes} black holes\")\n",
    "print(f\"Total tokens in black holes: {n_bh_tokens:,}\")\n",
    "print()\n",
    "print(f\"Black hole sizes:\")\n",
    "for i, size in enumerate(black_hole_sizes, 1):\n",
    "    print(f\"  BH{i}: {size.item():,} tokens\")\n",
    "print()\n",
    "print(f\"Saved to: {output_path}\")\n",
    "print()\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
