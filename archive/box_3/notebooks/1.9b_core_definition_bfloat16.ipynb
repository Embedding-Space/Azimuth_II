{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.9b: Core Definition (bfloat16 corrected)\n",
    "\n",
    "**The Error:** In 1.8a, we loaded W and immediately converted to float32. This merged the 13 real black holes into 4 apparent ones.\n",
    "\n",
    "**The Fix:** Keep W in **native bfloat16** throughout. Only convert to float32 for operations that need precision (like centering), but do all equality/grouping in bfloat16.\n",
    "\n",
    "**Expected Results:**\n",
    "- 13 unique vectors (not 5)\n",
    "- Populations matching 1.9a: 814, 704, 306, 228, 11, 10, 6, 5, 4, 4, 3, 3, 2\n",
    "- Total: 2,100 degenerate tokens\n",
    "\n",
    "This is the **corrected** version of 1.8a."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to analyze\n",
    "MODEL_NAME = \"Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "# Magic radius that defines the core (from 1.8a)\n",
    "MAGIC_RADIUS = 0.00007553\n",
    "RADIUS_TOLERANCE = 1e-7\n",
    "\n",
    "# Visualization\n",
    "DPI = 200\n",
    "N_BINS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import ml_dtypes\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from safetensors.torch import load_file, save_file\n",
    "from pathlib import Path\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_bf16_to_numpy_bf16(tensor):\n",
    "    \"\"\"Convert PyTorch bfloat16 tensor to numpy array with ml_dtypes.bfloat16 dtype.\"\"\"\n",
    "    return tensor.cpu().view(torch.uint16).numpy().view(ml_dtypes.bfloat16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded W from ../tensors/Qwen3-4B-Instruct-2507/W.safetensors\n",
      "  Shape: torch.Size([151936, 2560])\n",
      "  Dtype: torch.bfloat16 ← NATIVE bfloat16 (not converted!)\n",
      "\n",
      "Loaded cluster from ../tensors/Qwen3-4B-Instruct-2507/1.6a_cluster_mask.safetensors\n",
      "  Cluster size: 2,248 tokens\n",
      "\n",
      "Loaded cluster spherical coords from ../tensors/Qwen3-4B-Instruct-2507/1.7c_cluster_spherical.safetensors\n"
     ]
    }
   ],
   "source": [
    "# Load W in NATIVE bfloat16 (DO NOT CONVERT!)\n",
    "W_path = Path(f\"../tensors/{MODEL_NAME}/W.safetensors\")\n",
    "W_bf16 = load_file(W_path)[\"W\"]\n",
    "\n",
    "print(f\"Loaded W from {W_path}\")\n",
    "print(f\"  Shape: {W_bf16.shape}\")\n",
    "print(f\"  Dtype: {W_bf16.dtype} ← NATIVE bfloat16 (not converted!)\")\n",
    "\n",
    "# Load cluster data\n",
    "cluster_path = Path(f\"../tensors/{MODEL_NAME}/1.6a_cluster_mask.safetensors\")\n",
    "cluster_data = load_file(cluster_path)\n",
    "cluster_mask = cluster_data[\"cluster_mask\"].to(torch.bool)\n",
    "cluster_token_ids = cluster_data[\"cluster_token_ids\"].to(torch.int64)\n",
    "\n",
    "print(f\"\\nLoaded cluster from {cluster_path}\")\n",
    "print(f\"  Cluster size: {cluster_mask.sum().item():,} tokens\")\n",
    "\n",
    "# Load cluster spherical coords\n",
    "spherical_path = Path(f\"../tensors/{MODEL_NAME}/1.7c_cluster_spherical.safetensors\")\n",
    "spherical_data = load_file(spherical_path)\n",
    "r_cluster = spherical_data[\"r\"]\n",
    "\n",
    "print(f\"\\nLoaded cluster spherical coords from {spherical_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Defining the core...\n",
      "\n",
      "Core definition:\n",
      "  Radius: 7.553e-05 ± 1e-07\n",
      "  Core size: 2,179 tokens\n",
      "  Percentage of cluster: 96.9%\n",
      "\n",
      "Core token ID range:\n",
      "  Min: 124\n",
      "  Max: 151,935\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDefining the core...\\n\")\n",
    "\n",
    "# Core = tokens at magic radius within cluster\n",
    "core_mask_within_cluster = torch.abs(r_cluster - MAGIC_RADIUS) < RADIUS_TOLERANCE\n",
    "n_core = core_mask_within_cluster.sum().item()\n",
    "\n",
    "# Get core token IDs\n",
    "core_token_ids = cluster_token_ids[core_mask_within_cluster]\n",
    "\n",
    "print(f\"Core definition:\")\n",
    "print(f\"  Radius: {MAGIC_RADIUS} ± {RADIUS_TOLERANCE}\")\n",
    "print(f\"  Core size: {n_core:,} tokens\")\n",
    "print(f\"  Percentage of cluster: {n_core/len(cluster_token_ids)*100:.1f}%\")\n",
    "print(f\"\\nCore token ID range:\")\n",
    "print(f\"  Min: {core_token_ids.min().item():,}\")\n",
    "print(f\"  Max: {core_token_ids.max().item():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Core Embeddings (bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting core embeddings in bfloat16...\n",
      "\n",
      "✓ Extracted 2,179 core embeddings\n",
      "  Dimensionality: 2,560\n",
      "  Dtype: torch.bfloat16 ← Still bfloat16!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nExtracting core embeddings in bfloat16...\\n\")\n",
    "\n",
    "# Create global mask (in full vocabulary space)\n",
    "core_mask_global = torch.zeros(W_bf16.shape[0], dtype=torch.bool)\n",
    "core_mask_global[core_token_ids] = True\n",
    "\n",
    "# Extract embeddings IN BFLOAT16\n",
    "W_core_bf16 = W_bf16[core_mask_global]\n",
    "\n",
    "print(f\"✓ Extracted {W_core_bf16.shape[0]:,} core embeddings\")\n",
    "print(f\"  Dimensionality: {W_core_bf16.shape[1]:,}\")\n",
    "print(f\"  Dtype: {W_core_bf16.dtype} ← Still bfloat16!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Black Holes via Exact Equality (bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Grouping core tokens by exact vector equality (bfloat16)...\n",
      "\n",
      "Unique vectors in core: 92\n",
      "Total core tokens: 2179\n",
      "Degenerate tokens: 2087\n",
      "\n",
      "Black holes found: 13\n",
      "\n",
      "Top 20 black holes:\n",
      "Rank  Population  Sample Local Indices\n",
      "------------------------------------------------------------\n",
      "   1         814  14, 16, 18, 20, 21, ...\n",
      "   2         704  1, 2, 3, 4, 6, ...\n",
      "   3         306  0, 24, 26, 33, 38, ...\n",
      "   4         228  51, 85, 136, 160, 264, ...\n",
      "   5          11  25, 668, 670, 885, 886, ...\n",
      "   6          10  19, 127, 276, 1121, 1147, ...\n",
      "   7           6  244, 724, 1134, 1695, 1742, ...\n",
      "   8           5  698, 700, 1234, 1545, 1546\n",
      "   9           4  940, 1188, 1385, 1627\n",
      "  10           4  1037, 1141, 1142, 1256\n",
      "  11           3  5, 1224, 1448\n",
      "  12           3  295, 1340, 1710\n",
      "  13           2  300, 1739\n",
      "\n",
      "✓ Black hole grouping complete\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGrouping core tokens by exact vector equality (bfloat16)...\\n\")\n",
    "\n",
    "# Convert to numpy bfloat16 for hashing\n",
    "W_core_np_bf16 = torch_bf16_to_numpy_bf16(W_core_bf16)\n",
    "\n",
    "# Group by vector\n",
    "vector_groups = defaultdict(list)\n",
    "for i in range(len(W_core_np_bf16)):\n",
    "    vector = W_core_np_bf16[i]\n",
    "    vector_key = tuple(vector)  # Hashable\n",
    "    vector_groups[vector_key].append(i)  # Local index within core\n",
    "\n",
    "n_unique = len(vector_groups)\n",
    "\n",
    "print(f\"Unique vectors in core: {n_unique}\")\n",
    "print(f\"Total core tokens: {n_core}\")\n",
    "print(f\"Degenerate tokens: {n_core - n_unique}\")\n",
    "\n",
    "# Find black holes (groups with >1 token)\n",
    "black_holes = [(vector_key, indices) for vector_key, indices in vector_groups.items() \n",
    "               if len(indices) > 1]\n",
    "black_holes.sort(key=lambda x: len(x[1]), reverse=True)\n",
    "\n",
    "print(f\"\\nBlack holes found: {len(black_holes)}\")\n",
    "print(f\"\\nTop 20 black holes:\")\n",
    "print(\"Rank  Population  Sample Local Indices\")\n",
    "print(\"-\" * 60)\n",
    "for i, (vector_key, indices) in enumerate(black_holes[:20], 1):\n",
    "    sample = indices[:5]\n",
    "    sample_str = \", \".join(str(idx) for idx in sample)\n",
    "    if len(indices) > 5:\n",
    "        sample_str += \", ...\"\n",
    "    print(f\"{i:4d}  {len(indices):10,}  {sample_str}\")\n",
    "\n",
    "print(f\"\\n✓ Black hole grouping complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification Against 1.9a Global Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "VERIFICATION: COMPARING TO 1.9a GLOBAL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Expected (from 1.9a global check):\n",
      "  Black holes: 13\n",
      "  Populations: [814, 704, 306, 228, 11, 10, 6, 5, 4, 4, 3, 3, 2]\n",
      "  Total degenerate: 2,100\n",
      "\n",
      "Actual (from bfloat16 core analysis):\n",
      "  Black holes: 13\n",
      "  Populations: [814, 704, 306, 228, 11, 10, 6, 5, 4, 4, 3, 3, 2]\n",
      "  Total degenerate: 2,100\n",
      "\n",
      "✓ Number of black holes MATCHES (13)\n",
      "✓ Populations EXACTLY MATCH\n",
      "✓ Total degenerate MATCHES (2,100)\n",
      "\n",
      "================================================================================\n",
      "VERDICT: ✓✓✓ CORRECTION SUCCESSFUL ✓✓✓\n",
      "================================================================================\n",
      "\n",
      "The bfloat16-native analysis correctly identifies all 13 black holes.\n",
      "The 1.8a error has been corrected.\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VERIFICATION: COMPARING TO 1.9a GLOBAL RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Expected from 1.9a\n",
    "expected_n_bh = 13\n",
    "expected_populations = [814, 704, 306, 228, 11, 10, 6, 5, 4, 4, 3, 3, 2]\n",
    "expected_total = 2100\n",
    "\n",
    "print(\"Expected (from 1.9a global check):\")\n",
    "print(f\"  Black holes: {expected_n_bh}\")\n",
    "print(f\"  Populations: {expected_populations}\")\n",
    "print(f\"  Total degenerate: {expected_total:,}\")\n",
    "print()\n",
    "\n",
    "# Actual from this notebook\n",
    "actual_n_bh = len(black_holes)\n",
    "actual_populations = [len(indices) for _, indices in black_holes]\n",
    "actual_total = sum(actual_populations)\n",
    "\n",
    "print(\"Actual (from bfloat16 core analysis):\")\n",
    "print(f\"  Black holes: {actual_n_bh}\")\n",
    "print(f\"  Populations: {actual_populations}\")\n",
    "print(f\"  Total degenerate: {actual_total:,}\")\n",
    "print()\n",
    "\n",
    "# Check\n",
    "if actual_n_bh == expected_n_bh:\n",
    "    print(f\"✓ Number of black holes MATCHES ({actual_n_bh})\")\n",
    "else:\n",
    "    print(f\"✗ Number MISMATCH (expected {expected_n_bh}, found {actual_n_bh})\")\n",
    "\n",
    "if actual_populations == expected_populations:\n",
    "    print(f\"✓ Populations EXACTLY MATCH\")\n",
    "else:\n",
    "    print(f\"⚠ Populations differ (might be ordering or subset)\")\n",
    "\n",
    "if actual_total == expected_total:\n",
    "    print(f\"✓ Total degenerate MATCHES ({actual_total:,})\")\n",
    "else:\n",
    "    print(f\"✗ Total MISMATCH (expected {expected_total:,}, found {actual_total:,})\")\n",
    "\n",
    "print()\n",
    "if actual_n_bh == expected_n_bh and actual_total == expected_total:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"VERDICT: ✓✓✓ CORRECTION SUCCESSFUL ✓✓✓\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    print(\"The bfloat16-native analysis correctly identifies all 13 black holes.\")\n",
    "    print(\"The 1.8a error has been corrected.\")\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"VERDICT: ⚠ STILL DISCREPANCY ⚠\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Centered Coordinates (for geometry, not grouping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing centered coordinates for geometric analysis...\n",
      "\n",
      "✓ Computed centered coordinates in float32 (for geometry)\n",
      "  Mean of centered core: 9.86e-10 (should be ~0)\n",
      "\n",
      "NOTE: Centering is ONLY for geometric analysis (PCA, spherical coords).\n",
      "      Black hole grouping was done in native bfloat16 before centering.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing centered coordinates for geometric analysis...\\n\")\n",
    "\n",
    "# NOW we can convert to float32 for centering (for geometry only, not grouping!)\n",
    "W_core_f32 = W_core_bf16.to(torch.float32)\n",
    "core_centroid_f32 = W_core_f32.mean(dim=0)\n",
    "W_core_centered_f32 = W_core_f32 - core_centroid_f32\n",
    "\n",
    "# Verify centering\n",
    "mean_norm = W_core_centered_f32.mean(dim=0).norm().item()\n",
    "\n",
    "print(f\"✓ Computed centered coordinates in float32 (for geometry)\")\n",
    "print(f\"  Mean of centered core: {mean_norm:.2e} (should be ~0)\")\n",
    "print()\n",
    "print(\"NOTE: Centering is ONLY for geometric analysis (PCA, spherical coords).\")\n",
    "print(\"      Black hole grouping was done in native bfloat16 before centering.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find High-Variance Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding high-variance dimensions...\n",
      "\n",
      "Top 3 dimensions by variance (in core):\n",
      "  Meridian (1st): dimension 322, variance = 2.33e-10\n",
      "  North (2nd):    dimension 163, variance = 1.09e-10\n",
      "  Equinox (3rd):  dimension 1564, variance = 5.77e-11\n",
      "\n",
      "✓ Identified basis dimensions\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinding high-variance dimensions...\\n\")\n",
    "\n",
    "# Compute variance per dimension\n",
    "variances = W_core_centered_f32.var(dim=0)\n",
    "\n",
    "# Find top 3 dimensions\n",
    "top_indices = variances.argsort(descending=True)[:3]\n",
    "\n",
    "# Assign to spherical basis\n",
    "north_idx = top_indices[1].item()\n",
    "meridian_idx = top_indices[0].item()\n",
    "equinox_idx = top_indices[2].item()\n",
    "\n",
    "print(f\"Top 3 dimensions by variance (in core):\")\n",
    "print(f\"  Meridian (1st): dimension {meridian_idx}, variance = {variances[meridian_idx].item():.2e}\")\n",
    "print(f\"  North (2nd):    dimension {north_idx}, variance = {variances[north_idx].item():.2e}\")\n",
    "print(f\"  Equinox (3rd):  dimension {equinox_idx}, variance = {variances[equinox_idx].item():.2e}\")\n",
    "\n",
    "print(f\"\\n✓ Identified basis dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project to Spherical Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Projecting to spherical coordinates...\n",
      "\n",
      "✓ Computed spherical coordinates\n",
      "\n",
      "Radius statistics:\n",
      "  Min: 1.64e-05\n",
      "  Max: 4.88e-04\n",
      "  Median: 1.71e-05\n",
      "  Mean: 1.72e-05\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nProjecting to spherical coordinates...\\n\")\n",
    "\n",
    "# Extract Cartesian coordinates\n",
    "x = W_core_centered_f32[:, meridian_idx]\n",
    "y = W_core_centered_f32[:, equinox_idx]\n",
    "z = W_core_centered_f32[:, north_idx]\n",
    "\n",
    "# Compute radius\n",
    "r_core = torch.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "# Latitude\n",
    "lat_rad = torch.asin(torch.clamp(z / (r_core + 1e-10), -1, 1))\n",
    "lat_deg = torch.rad2deg(lat_rad)\n",
    "\n",
    "# Longitude\n",
    "lon_rad = torch.atan2(y, x)\n",
    "lon_deg = torch.rad2deg(lon_rad)\n",
    "\n",
    "print(f\"✓ Computed spherical coordinates\")\n",
    "print(f\"\\nRadius statistics:\")\n",
    "print(f\"  Min: {r_core.min().item():.2e}\")\n",
    "print(f\"  Max: {r_core.max().item():.2e}\")\n",
    "print(f\"  Median: {r_core.median().item():.2e}\")\n",
    "print(f\"  Mean: {r_core.mean().item():.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Corrected Core Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving corrected core data...\n",
      "\n",
      "✓ Saved to ../tensors/Qwen3-4B-Instruct-2507/1.9b_core_bfloat16.safetensors\n",
      "\n",
      "Saved tensors:\n",
      "  core_mask, core_token_ids, n_core\n",
      "  bh_labels: (2179,) - which black hole each token belongs to\n",
      "  n_black_holes: 13\n",
      "  core_centroid, r, lat_deg, lon_deg (for geometry)\n",
      "  basis indices: 322, 163, 1564\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving corrected core data...\\n\")\n",
    "\n",
    "output_path = Path(f\"../tensors/{MODEL_NAME}/1.9b_core_bfloat16.safetensors\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create black hole labels (which BH does each token belong to?)\n",
    "bh_labels = torch.full((n_core,), -1, dtype=torch.int64)  # -1 = unique\n",
    "for bh_id, (vector_key, indices) in enumerate(black_holes):\n",
    "    for local_idx in indices:\n",
    "        bh_labels[local_idx] = bh_id\n",
    "\n",
    "save_file({\n",
    "    # Core definition\n",
    "    \"core_mask\": core_mask_global.to(torch.uint8),\n",
    "    \"core_token_ids\": core_token_ids.to(torch.int32),\n",
    "    \"n_core\": torch.tensor([n_core], dtype=torch.int32),\n",
    "    \n",
    "    # Black hole assignments\n",
    "    \"bh_labels\": bh_labels.to(torch.int16),  # Which BH each token belongs to\n",
    "    \"n_black_holes\": torch.tensor([len(black_holes)], dtype=torch.int32),\n",
    "    \n",
    "    # Core centroid (float32, for geometry)\n",
    "    \"core_centroid\": core_centroid_f32,\n",
    "    \n",
    "    # Spherical coordinates (centered at core centroid, float32)\n",
    "    \"r\": r_core,\n",
    "    \"lat_deg\": lat_deg,\n",
    "    \"lon_deg\": lon_deg,\n",
    "    \n",
    "    # Basis indices\n",
    "    \"north_idx\": torch.tensor([north_idx], dtype=torch.int32),\n",
    "    \"meridian_idx\": torch.tensor([meridian_idx], dtype=torch.int32),\n",
    "    \"equinox_idx\": torch.tensor([equinox_idx], dtype=torch.int32),\n",
    "}, str(output_path))\n",
    "\n",
    "print(f\"✓ Saved to {output_path}\")\n",
    "print()\n",
    "print(\"Saved tensors:\")\n",
    "print(f\"  core_mask, core_token_ids, n_core\")\n",
    "print(f\"  bh_labels: ({n_core},) - which black hole each token belongs to\")\n",
    "print(f\"  n_black_holes: {len(black_holes)}\")\n",
    "print(f\"  core_centroid, r, lat_deg, lon_deg (for geometry)\")\n",
    "print(f\"  basis indices: {meridian_idx}, {north_idx}, {equinox_idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
