{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.18b: Data Rate Calculator\n",
    "\n",
    "**Goal:** Calculate storage requirements for training experiments given hyperparameters.\n",
    "\n",
    "## Why This Matters\n",
    "\n",
    "We want to record the full W matrix (unembedding) at every training step to watch token dynamics. But how much disk space will this require?\n",
    "\n",
    "**Answer depends on:**\n",
    "- Vocabulary size (number of tokens)\n",
    "- Hidden dimension size\n",
    "- Number of training steps\n",
    "- Data type (float32, bfloat16, float16)\n",
    "\n",
    "This notebook lets us **tune hyperparameters** before training to ensure we don't run out of disk space mid-run.\n",
    "\n",
    "## What We Calculate\n",
    "\n",
    "For a given set of hyperparameters:\n",
    "1. **Single snapshot size:** How big is one W matrix?\n",
    "2. **Per-1000-steps:** How much data per 1,000 training steps?\n",
    "3. **Total run size:** How much for a full training run (N steps)?\n",
    "4. **RAM requirements:** How much memory needed to hold snapshots before saving?\n",
    "\n",
    "## Storage Format\n",
    "\n",
    "We save W matrices using **safetensors** format:\n",
    "- Minimal overhead (~100 bytes per file)\n",
    "- Compressed if possible\n",
    "- But essentially: `file_size ≈ vocab_size × hidden_dim × bytes_per_float`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters\n",
    "\n",
    "Edit these to match your planned training run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parameters set\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "VOCAB_SIZE = 10000        # Flannel tokenizer siz\n",
    "HIDDEN_DIM = 64          # Same as Lil Gatsby / Wordybird\n",
    "NUM_LAYERS = 2           # Number of transformer layers\n",
    "NUM_HEADS = 2            # Number of attention heads\n",
    "\n",
    "# Training parameters\n",
    "TRAINING_STEPS = 10000   # Total number of training steps\n",
    "SAVE_EVERY_N_STEPS = 1   # How often to save W matrix (1 = every step)\n",
    "\n",
    "# Data type\n",
    "DTYPE = \"bfloat16\"       # Options: \"float32\" (4 bytes), \"bfloat16\" (2 bytes), \"float16\" (2 bytes)\n",
    "\n",
    "# Bytes per data type\n",
    "BYTES_PER_DTYPE = {\n",
    "    \"float32\": 4,\n",
    "    \"bfloat16\": 2,\n",
    "    \"float16\": 2\n",
    "}\n",
    "\n",
    "print(\"✓ Parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate W Matrix Size\n",
    "\n",
    "The W matrix (unembedding) is what we're tracking. It's a 2D matrix:\n",
    "- Shape: `(vocab_size, hidden_dim)`\n",
    "- Size in bytes: `vocab_size × hidden_dim × bytes_per_float`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W Matrix (Unembedding):\n",
      "  Shape: (10,000 tokens, 64 dims)\n",
      "  Elements: 640,000\n",
      "  Data type: bfloat16 (2 bytes per element)\n",
      "  Size per snapshot: 1.22 MB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate W matrix size\n",
    "bytes_per_float = BYTES_PER_DTYPE[DTYPE]\n",
    "w_matrix_elements = VOCAB_SIZE * HIDDEN_DIM\n",
    "w_matrix_bytes = w_matrix_elements * bytes_per_float\n",
    "\n",
    "# Convert to human-readable units\n",
    "def format_bytes(b):\n",
    "    \"\"\"Format bytes as human-readable string\"\"\"\n",
    "    if b < 1024:\n",
    "        return f\"{b} B\"\n",
    "    elif b < 1024**2:\n",
    "        return f\"{b/1024:.2f} KB\"\n",
    "    elif b < 1024**3:\n",
    "        return f\"{b/1024**2:.2f} MB\"\n",
    "    else:\n",
    "        return f\"{b/1024**3:.2f} GB\"\n",
    "\n",
    "print(f\"W Matrix (Unembedding):\")\n",
    "print(f\"  Shape: ({VOCAB_SIZE:,} tokens, {HIDDEN_DIM} dims)\")\n",
    "print(f\"  Elements: {w_matrix_elements:,}\")\n",
    "print(f\"  Data type: {DTYPE} ({bytes_per_float} bytes per element)\")\n",
    "print(f\"  Size per snapshot: {format_bytes(w_matrix_bytes)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Storage Requirements per Interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage Requirements:\n",
      "  Training steps: 10,000\n",
      "  Save frequency: every 1 step(s)\n",
      "  Total snapshots: 10,000\n",
      "\n",
      "  Per snapshot: 1.22 MB\n",
      "  Per 1,000 steps: 1.19 GB\n",
      "  Total for 10,000 steps: 11.92 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# How many snapshots will we save?\n",
    "num_snapshots = TRAINING_STEPS // SAVE_EVERY_N_STEPS\n",
    "\n",
    "# Total storage for W matrices\n",
    "total_w_storage = w_matrix_bytes * num_snapshots\n",
    "\n",
    "# Per-1000-steps\n",
    "snapshots_per_1000 = 1000 // SAVE_EVERY_N_STEPS\n",
    "storage_per_1000 = w_matrix_bytes * snapshots_per_1000\n",
    "\n",
    "print(f\"Storage Requirements:\")\n",
    "print(f\"  Training steps: {TRAINING_STEPS:,}\")\n",
    "print(f\"  Save frequency: every {SAVE_EVERY_N_STEPS} step(s)\")\n",
    "print(f\"  Total snapshots: {num_snapshots:,}\")\n",
    "print()\n",
    "\n",
    "print(f\"  Per snapshot: {format_bytes(w_matrix_bytes)}\")\n",
    "print(f\"  Per 1,000 steps: {format_bytes(storage_per_1000)}\")\n",
    "print(f\"  Total for {TRAINING_STEPS:,} steps: {format_bytes(total_w_storage)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Data\n",
    "\n",
    "Besides W matrices, we might also save:\n",
    "- E matrix (embedding) - same size as W\n",
    "- Optimizer state (Adam: 2× model parameters for momentum/variance)\n",
    "- Loss values (negligible)\n",
    "- Checkpoints (full model state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Additional Data (optional):\n",
      "  E matrix per snapshot: 1.22 MB\n",
      "  Both E + W per snapshot: 2.44 MB\n",
      "  Both E + W per 1,000 steps: 2.38 GB\n",
      "  Both E + W total: 23.84 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# E matrix (embedding) - same size as W\n",
    "e_matrix_bytes = w_matrix_bytes\n",
    "\n",
    "# If we save both E and W\n",
    "total_embeddings = (w_matrix_bytes + e_matrix_bytes) * num_snapshots\n",
    "\n",
    "print(f\"Additional Data (optional):\")\n",
    "print(f\"  E matrix per snapshot: {format_bytes(e_matrix_bytes)}\")\n",
    "print(f\"  Both E + W per snapshot: {format_bytes(w_matrix_bytes + e_matrix_bytes)}\")\n",
    "print(f\"  Both E + W per 1,000 steps: {format_bytes((w_matrix_bytes + e_matrix_bytes) * snapshots_per_1000)}\")\n",
    "print(f\"  Both E + W total: {format_bytes(total_embeddings)}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAM Requirements\n",
    "\n",
    "During training, we need to hold:\n",
    "1. Current model parameters\n",
    "2. Optimizer state (2× parameters for Adam)\n",
    "3. Batch activations\n",
    "4. Gradient tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAM Requirements (approximate):\n",
      "  Total parameters: 1,378,304\n",
      "  Model memory: 2.63 MB\n",
      "  Optimizer state (Adam): 5.26 MB\n",
      "  Minimum RAM needed: 7.89 MB\n",
      "  Recommended RAM: 11.83 MB (with 50% buffer)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estimate model parameter count\n",
    "# E + W matrices\n",
    "embedding_params = 2 * VOCAB_SIZE * HIDDEN_DIM\n",
    "\n",
    "# Transformer layers (rough estimate)\n",
    "# Per layer: attention (4 × hidden²) + FFN (2 × 4 × hidden²)\n",
    "params_per_layer = 4 * HIDDEN_DIM**2 + 8 * HIDDEN_DIM**2\n",
    "transformer_params = NUM_LAYERS * params_per_layer\n",
    "\n",
    "total_params = embedding_params + transformer_params\n",
    "\n",
    "# Memory usage\n",
    "model_memory = total_params * bytes_per_float\n",
    "optimizer_memory = 2 * model_memory  # Adam keeps momentum + variance\n",
    "total_ram = model_memory + optimizer_memory\n",
    "\n",
    "print(f\"RAM Requirements (approximate):\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Model memory: {format_bytes(model_memory)}\")\n",
    "print(f\"  Optimizer state (Adam): {format_bytes(optimizer_memory)}\")\n",
    "print(f\"  Minimum RAM needed: {format_bytes(total_ram)}\")\n",
    "print(f\"  Recommended RAM: {format_bytes(int(total_ram * 1.5))} (with 50% buffer)\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling Analysis\n",
    "\n",
    "How does storage scale with different vocab sizes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaling Analysis (for 10,000 steps, bfloat16):\n",
      "\n",
      "Vocab Size W per snapshot Per 1,000 steps Total (10,000 steps)\n",
      "       128       16.00 KB        15.62 MB            156.25 MB\n",
      "       256       32.00 KB        31.25 MB            312.50 MB\n",
      "     1,000      125.00 KB       122.07 MB              1.19 GB\n",
      "     5,000      625.00 KB       610.35 MB              5.96 GB\n",
      "    10,000        1.22 MB         1.19 GB             11.92 GB\n",
      "    50,000        6.10 MB         5.96 GB             59.60 GB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(f\"Scaling Analysis (for {TRAINING_STEPS:,} steps, {DTYPE}):\")\n",
    "print()\n",
    "\n",
    "vocab_sizes = [128, 256, 1000, 5000, 10000, 50000]\n",
    "scaling_data = []\n",
    "\n",
    "for vocab in vocab_sizes:\n",
    "    w_bytes = vocab * HIDDEN_DIM * bytes_per_float\n",
    "    total = w_bytes * num_snapshots\n",
    "    per_1000 = w_bytes * snapshots_per_1000\n",
    "    \n",
    "    scaling_data.append({\n",
    "        'Vocab Size': f\"{vocab:,}\",\n",
    "        'W per snapshot': format_bytes(w_bytes),\n",
    "        'Per 1,000 steps': format_bytes(per_1000),\n",
    "        f'Total ({TRAINING_STEPS:,} steps)': format_bytes(total)\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(scaling_data)\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA RATE SUMMARY\n",
      "======================================================================\n",
      "\n",
      "Model Configuration:\n",
      "  Vocabulary: 10,000 tokens\n",
      "  Hidden dimension: 64\n",
      "  Layers: 2\n",
      "  Attention heads: 2\n",
      "  Data type: bfloat16\n",
      "\n",
      "Training Plan:\n",
      "  Total steps: 10,000\n",
      "  Save frequency: every 1 step(s)\n",
      "  Total snapshots: 10,000\n",
      "\n",
      "Storage Requirements (W matrix only):\n",
      "  Per snapshot: 1.22 MB\n",
      "  Per 1,000 steps: 1.19 GB\n",
      "  Total: 11.92 GB\n",
      "\n",
      "RAM Requirements:\n",
      "  Model + optimizer: 7.89 MB\n",
      "  Recommended: 11.83 MB\n",
      "\n",
      "Next steps:\n",
      "  → If storage is acceptable, proceed with training (1.20a+)\n",
      "  → If too large, adjust VOCAB_SIZE or TRAINING_STEPS above\n",
      "  → Consider using bfloat16 instead of float32 (halves storage)\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"DATA RATE SUMMARY\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "print(f\"Model Configuration:\")\n",
    "print(f\"  Vocabulary: {VOCAB_SIZE:,} tokens\")\n",
    "print(f\"  Hidden dimension: {HIDDEN_DIM}\")\n",
    "print(f\"  Layers: {NUM_LAYERS}\")\n",
    "print(f\"  Attention heads: {NUM_HEADS}\")\n",
    "print(f\"  Data type: {DTYPE}\")\n",
    "print()\n",
    "\n",
    "print(f\"Training Plan:\")\n",
    "print(f\"  Total steps: {TRAINING_STEPS:,}\")\n",
    "print(f\"  Save frequency: every {SAVE_EVERY_N_STEPS} step(s)\")\n",
    "print(f\"  Total snapshots: {num_snapshots:,}\")\n",
    "print()\n",
    "\n",
    "print(f\"Storage Requirements (W matrix only):\")\n",
    "print(f\"  Per snapshot: {format_bytes(w_matrix_bytes)}\")\n",
    "print(f\"  Per 1,000 steps: {format_bytes(storage_per_1000)}\")\n",
    "print(f\"  Total: {format_bytes(total_w_storage)}\")\n",
    "print()\n",
    "\n",
    "print(f\"RAM Requirements:\")\n",
    "print(f\"  Model + optimizer: {format_bytes(total_ram)}\")\n",
    "print(f\"  Recommended: {format_bytes(int(total_ram * 1.5))}\")\n",
    "print()\n",
    "\n",
    "# Sanity checks\n",
    "if total_w_storage > 100 * 1024**3:  # > 100 GB\n",
    "    print(f\"⚠️  WARNING: Total storage exceeds 100 GB!\")\n",
    "    print(f\"   Consider reducing vocab size or training steps.\")\n",
    "    print()\n",
    "\n",
    "if total_ram > 16 * 1024**3:  # > 16 GB\n",
    "    print(f\"⚠️  WARNING: RAM requirements exceed 16 GB!\")\n",
    "    print(f\"   Consider reducing model size or using bfloat16.\")\n",
    "    print()\n",
    "\n",
    "print(f\"Next steps:\")\n",
    "print(f\"  → If storage is acceptable, proceed with training (1.20a+)\")\n",
    "print(f\"  → If too large, adjust VOCAB_SIZE or TRAINING_STEPS above\")\n",
    "print(f\"  → Consider using bfloat16 instead of float32 (halves storage)\")\n",
    "print()\n",
    "print(f\"{'='*70}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
