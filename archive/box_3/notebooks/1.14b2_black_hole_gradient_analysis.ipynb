{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 1.14b2: Black Hole Gradient Analysis\n",
    "\n",
    "**Goal:** Why does the black hole move? Check if untrained tokens receive identical gradients.\n",
    "\n",
    "## Hypothesis\n",
    "\n",
    "The black hole (49 untrained tokens) moves because:\n",
    "\n",
    "1. All tokens start at the same point (supermassive BH)\n",
    "2. Forward pass: `logit[i] = h • W[i]` → identical logits for identical W[i]\n",
    "3. Backward pass: gradient depends on logit\n",
    "4. **Identical logits → identical gradients**\n",
    "5. Identical gradients → tokens move together\n",
    "6. Still coincident → cycle repeats\n",
    "\n",
    "## Test\n",
    "\n",
    "For untrained tokens at each timestep:\n",
    "- Are the logits identical?\n",
    "- Are the gradients identical?\n",
    "- Does gradient equality → position equality?\n",
    "\n",
    "## Expected Result\n",
    "\n",
    "✓ Untrained tokens have identical (or near-identical) logits\n",
    "✓ Untrained tokens have identical (or near-identical) gradients\n",
    "✓ This explains why the black hole moves as a rigid body"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data to analyze\n",
    "TRAINING_DATA_PATH = \"../tensors/Lil_Gatsby/1.12b_training_data_sigma0e+00.safetensors\"\n",
    "\n",
    "# Corpus path (to identify untrained tokens)\n",
    "CORPUS_PATH = \"../data/gatsby_clean.txt\"\n",
    "\n",
    "# Analysis\n",
    "STEPS_TO_CHECK = [0, 1, 2, 10, 100, 1000, 10000]  # Sample timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from safetensors.torch import load_file\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading training data: ../tensors/Lil_Gatsby/1.12b_training_data_sigma0e+00.safetensors\n",
      "\n",
      "✓ Loaded training data\n",
      "  Embeddings: torch.Size([10001, 128, 64])\n",
      "  Gradients: torch.Size([10001, 128, 64])\n",
      "  Logits: torch.Size([10001, 128])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading training data: {TRAINING_DATA_PATH}\\n\")\n",
    "\n",
    "data = load_file(TRAINING_DATA_PATH)\n",
    "embeddings = data['embeddings'].float()  # (n_steps, vocab_size, hidden_dim)\n",
    "gradients = data['grads'].float()        # (n_steps, vocab_size, hidden_dim)\n",
    "logits = data['logits'].float()          # (n_steps, vocab_size)\n",
    "\n",
    "n_steps, vocab_size, hidden_dim = embeddings.shape\n",
    "\n",
    "print(f\"✓ Loaded training data\")\n",
    "print(f\"  Embeddings: {embeddings.shape}\")\n",
    "print(f\"  Gradients: {gradients.shape}\")\n",
    "print(f\"  Logits: {logits.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Identify Untrained Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing corpus: ../data/gatsby_clean.txt\n",
      "\n",
      "✓ Identified token usage\n",
      "  Trained: 79 tokens\n",
      "  Untrained (black hole): 49 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAnalyzing corpus: {CORPUS_PATH}\\n\")\n",
    "\n",
    "with open(CORPUS_PATH, 'r', encoding='ascii') as f:\n",
    "    corpus_text = f.read()\n",
    "\n",
    "corpus_bytes = corpus_text.encode('ascii')\n",
    "trained_tokens = sorted(set(corpus_bytes))\n",
    "untrained_tokens = sorted(set(range(vocab_size)) - set(trained_tokens))\n",
    "\n",
    "print(f\"✓ Identified token usage\")\n",
    "print(f\"  Trained: {len(trained_tokens)} tokens\")\n",
    "print(f\"  Untrained (black hole): {len(untrained_tokens)} tokens\")\n",
    "\n",
    "untrained_indices = torch.tensor(untrained_tokens, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Check Logit Equality for Untrained Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "LOGIT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Step     0:\n",
      "  Untrained logits: mean=+0.000000, std=0.000000e+00, range=0.000000e+00\n",
      "  → Logits are IDENTICAL (std < 1e-6)\n",
      "\n",
      "Step     1:\n",
      "  Untrained logits: mean=+0.632812, std=0.000000e+00, range=0.000000e+00\n",
      "  → Logits are IDENTICAL (std < 1e-6)\n",
      "\n",
      "Step     2:\n",
      "  Untrained logits: mean=+1.039062, std=0.000000e+00, range=0.000000e+00\n",
      "  → Logits are IDENTICAL (std < 1e-6)\n",
      "\n",
      "Step    10:\n",
      "  Untrained logits: mean=+0.457031, std=0.000000e+00, range=0.000000e+00\n",
      "  → Logits are IDENTICAL (std < 1e-6)\n",
      "\n",
      "Step   100:\n",
      "  Untrained logits: mean=-2.609375, std=0.000000e+00, range=0.000000e+00\n",
      "  → Logits are IDENTICAL (std < 1e-6)\n",
      "\n",
      "Step  1000:\n",
      "  Untrained logits: mean=-3.421875, std=0.000000e+00, range=0.000000e+00\n",
      "  → Logits are IDENTICAL (std < 1e-6)\n",
      "\n",
      "Step 10000:\n",
      "  Untrained logits: mean=-2.921875, std=0.000000e+00, range=0.000000e+00\n",
      "  → Logits are IDENTICAL (std < 1e-6)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"LOGIT ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for step in STEPS_TO_CHECK:\n",
    "    if step >= n_steps:\n",
    "        continue\n",
    "    \n",
    "    # Get logits for untrained tokens at this step\n",
    "    untrained_logits = logits[step, untrained_indices]\n",
    "    \n",
    "    # Compute statistics\n",
    "    logit_mean = untrained_logits.mean().item()\n",
    "    logit_std = untrained_logits.std().item()\n",
    "    logit_range = (untrained_logits.max() - untrained_logits.min()).item()\n",
    "    \n",
    "    print(f\"Step {step:5d}:\")\n",
    "    print(f\"  Untrained logits: mean={logit_mean:+.6f}, std={logit_std:.6e}, range={logit_range:.6e}\")\n",
    "    \n",
    "    if logit_std < 1e-6:\n",
    "        print(f\"  → Logits are IDENTICAL (std < 1e-6)\")\n",
    "    elif logit_std < 1e-3:\n",
    "        print(f\"  → Logits are nearly identical (std < 1e-3)\")\n",
    "    else:\n",
    "        print(f\"  → Logits vary\")\n",
    "    print()\n",
    "\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Check Gradient Equality for Untrained Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "GRADIENT ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Step     1:\n",
      "  Gradient norms: mean=4.576357e-02, std=0.000000e+00\n",
      "  Pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Gradients are IDENTICAL (max dist < 1e-6)\n",
      "\n",
      "Step     2:\n",
      "  Gradient norms: mean=5.894304e-02, std=0.000000e+00\n",
      "  Pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Gradients are IDENTICAL (max dist < 1e-6)\n",
      "\n",
      "Step    10:\n",
      "  Gradient norms: mean=5.045750e-02, std=0.000000e+00\n",
      "  Pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Gradients are IDENTICAL (max dist < 1e-6)\n",
      "\n",
      "Step   100:\n",
      "  Gradient norms: mean=1.788655e-03, std=2.352435e-10\n",
      "  Pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Gradients are IDENTICAL (max dist < 1e-6)\n",
      "\n",
      "Step  1000:\n",
      "  Gradient norms: mean=4.876784e-04, std=0.000000e+00\n",
      "  Pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Gradients are IDENTICAL (max dist < 1e-6)\n",
      "\n",
      "Step 10000:\n",
      "  Gradient norms: mean=4.253804e-04, std=2.940543e-11\n",
      "  Pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Gradients are IDENTICAL (max dist < 1e-6)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"GRADIENT ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for step in STEPS_TO_CHECK:\n",
    "    if step >= n_steps or step == 0:  # No gradients at step 0\n",
    "        continue\n",
    "    \n",
    "    # Get gradients for untrained tokens at this step\n",
    "    untrained_grads = gradients[step, untrained_indices, :]  # (n_untrained, hidden_dim)\n",
    "    \n",
    "    # Check if all gradients are identical by comparing pairwise distances\n",
    "    # If identical, all pairwise distances should be 0\n",
    "    pairwise_dists = torch.cdist(untrained_grads, untrained_grads, p=2)\n",
    "    max_pairwise_dist = pairwise_dists.max().item()\n",
    "    mean_pairwise_dist = pairwise_dists.mean().item()\n",
    "    \n",
    "    # Also check gradient magnitudes\n",
    "    grad_norms = torch.norm(untrained_grads, p=2, dim=1)\n",
    "    grad_norm_mean = grad_norms.mean().item()\n",
    "    grad_norm_std = grad_norms.std().item()\n",
    "    \n",
    "    print(f\"Step {step:5d}:\")\n",
    "    print(f\"  Gradient norms: mean={grad_norm_mean:.6e}, std={grad_norm_std:.6e}\")\n",
    "    print(f\"  Pairwise distances: max={max_pairwise_dist:.6e}, mean={mean_pairwise_dist:.6e}\")\n",
    "    \n",
    "    if max_pairwise_dist < 1e-6:\n",
    "        print(f\"  → Gradients are IDENTICAL (max dist < 1e-6)\")\n",
    "    elif max_pairwise_dist < 1e-3:\n",
    "        print(f\"  → Gradients are nearly identical (max dist < 1e-3)\")\n",
    "    else:\n",
    "        print(f\"  → Gradients vary\")\n",
    "    print()\n",
    "\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Check Position Equality for Untrained Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "POSITION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Step     0:\n",
      "  Position pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Positions are IDENTICAL (all tokens at same point)\n",
      "\n",
      "Step     1:\n",
      "  Position pairwise distances: max=6.103516e-05, mean=6.103516e-05\n",
      "  → Positions are nearly identical (tight cluster)\n",
      "\n",
      "Step     2:\n",
      "  Position pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Positions are IDENTICAL (all tokens at same point)\n",
      "\n",
      "Step    10:\n",
      "  Position pairwise distances: max=4.315837e-05, mean=4.315836e-05\n",
      "  → Positions are nearly identical (tight cluster)\n",
      "\n",
      "Step   100:\n",
      "  Position pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Positions are IDENTICAL (all tokens at same point)\n",
      "\n",
      "Step  1000:\n",
      "  Position pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Positions are IDENTICAL (all tokens at same point)\n",
      "\n",
      "Step 10000:\n",
      "  Position pairwise distances: max=0.000000e+00, mean=0.000000e+00\n",
      "  → Positions are IDENTICAL (all tokens at same point)\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"POSITION ANALYSIS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "for step in STEPS_TO_CHECK:\n",
    "    if step >= n_steps:\n",
    "        continue\n",
    "    \n",
    "    # Get positions for untrained tokens at this step\n",
    "    untrained_positions = embeddings[step, untrained_indices, :]  # (n_untrained, hidden_dim)\n",
    "    \n",
    "    # Check if all positions are identical\n",
    "    pairwise_dists = torch.cdist(untrained_positions, untrained_positions, p=2)\n",
    "    max_pairwise_dist = pairwise_dists.max().item()\n",
    "    mean_pairwise_dist = pairwise_dists.mean().item()\n",
    "    \n",
    "    print(f\"Step {step:5d}:\")\n",
    "    print(f\"  Position pairwise distances: max={max_pairwise_dist:.6e}, mean={mean_pairwise_dist:.6e}\")\n",
    "    \n",
    "    if max_pairwise_dist < 1e-6:\n",
    "        print(f\"  → Positions are IDENTICAL (all tokens at same point)\")\n",
    "    elif max_pairwise_dist < 1e-3:\n",
    "        print(f\"  → Positions are nearly identical (tight cluster)\")\n",
    "    else:\n",
    "        print(f\"  → Positions vary (tokens spread out)\")\n",
    "    print()\n",
    "\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Hypothesis: Black hole moves because untrained tokens receive identical gradients.\n",
      "\n",
      "Causal chain:\n",
      "  1. Tokens at same position → identical when dotted with hidden state\n",
      "  2. Identical dot products → identical logits\n",
      "  3. Identical logits → identical gradients (after loss backward)\n",
      "  4. Identical gradients → tokens move together (stay coincident)\n",
      "  5. Still coincident → cycle repeats\n",
      "\n",
      "Result: Black hole moves as a RIGID BODY through embedding space.\n",
      "\n",
      "Check the analysis above to verify:\n",
      "  ✓ Positions identical? (supermassive BH = all at one point)\n",
      "  ✓ Logits identical? (same position → same score)\n",
      "  ✓ Gradients identical? (same score → same update)\n",
      "\n",
      "Implication for thermodynamics:\n",
      "  The black hole HAS NO INTERNAL MOTION.\n",
      "  It moves as a single object, not a gas of particles.\n",
      "  Temperature of black hole = 0 (no relative motion).\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"SUMMARY\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "print(f\"Hypothesis: Black hole moves because untrained tokens receive identical gradients.\")\n",
    "print()\n",
    "print(f\"Causal chain:\")\n",
    "print(f\"  1. Tokens at same position → identical when dotted with hidden state\")\n",
    "print(f\"  2. Identical dot products → identical logits\")\n",
    "print(f\"  3. Identical logits → identical gradients (after loss backward)\")\n",
    "print(f\"  4. Identical gradients → tokens move together (stay coincident)\")\n",
    "print(f\"  5. Still coincident → cycle repeats\")\n",
    "print()\n",
    "print(f\"Result: Black hole moves as a RIGID BODY through embedding space.\")\n",
    "print()\n",
    "print(f\"Check the analysis above to verify:\")\n",
    "print(f\"  ✓ Positions identical? (supermassive BH = all at one point)\")\n",
    "print(f\"  ✓ Logits identical? (same position → same score)\")\n",
    "print(f\"  ✓ Gradients identical? (same score → same update)\")\n",
    "print()\n",
    "print(f\"Implication for thermodynamics:\")\n",
    "print(f\"  The black hole HAS NO INTERNAL MOTION.\")\n",
    "print(f\"  It moves as a single object, not a gas of particles.\")\n",
    "print(f\"  Temperature of black hole = 0 (no relative motion).\")\n",
    "print()\n",
    "print(f\"{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
