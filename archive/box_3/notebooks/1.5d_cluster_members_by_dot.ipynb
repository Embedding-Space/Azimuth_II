{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5d: Cluster Members by Dot Product\n",
    "\n",
    "This notebook identifies cluster membership using a simple criterion:\n",
    "\n",
    "1. Pick an arbitrary token `h` from the cluster region\n",
    "2. Compute `W @ h` in bfloat16 (all dot products)\n",
    "3. Find all tokens `t` where `t @ h == h @ h` in bfloat16\n",
    "\n",
    "These are the tokens indistinguishable from `h` when the hidden state points at `h`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model to analyze\n",
    "MODEL_NAME = \"Qwen3-4B-Instruct-2507\"\n",
    "\n",
    "# PCA basis selection (from 1.3c)\n",
    "NORTH_PC = 2      # North pole (+90° latitude)\n",
    "MERIDIAN_PC = 1   # Prime meridian (0° longitude)\n",
    "EQUINOX_PC = 3    # Equinox (+90° longitude)\n",
    "\n",
    "# Telescope pointing (from 1.3c)\n",
    "CENTER_LAT = -7.2888       # Latitude of center (degrees)\n",
    "CENTER_LON = 6.9400        # Longitude of center (degrees)\n",
    "ANGULAR_DIAMETER = 0.0010  # Field of view (degrees)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors.torch import load_file, save_file\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# Detect available device\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded W from ../tensors/Qwen3-4B-Instruct-2507/W.safetensors\n",
      "  Shape: torch.Size([151936, 2560])\n",
      "  Dtype: torch.bfloat16\n",
      "\n",
      "Token space: 151,936 tokens in 2,560 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Load W in bfloat16\n",
    "tensor_path = Path(f\"../tensors/{MODEL_NAME}/W.safetensors\")\n",
    "W_bf16 = load_file(tensor_path)[\"W\"]\n",
    "\n",
    "print(f\"Loaded W from {tensor_path}\")\n",
    "print(f\"  Shape: {W_bf16.shape}\")\n",
    "print(f\"  Dtype: {W_bf16.dtype}\")\n",
    "\n",
    "# Also keep float32 version for PCA/spherical coords\n",
    "W_f32 = W_bf16.to(torch.float32)\n",
    "\n",
    "N, d = W_bf16.shape\n",
    "print(f\"\\nToken space: {N:,} tokens in {d:,} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PCA...\n",
      "\n",
      "✓ PCA computed\n"
     ]
    }
   ],
   "source": [
    "print(\"Computing PCA...\\n\")\n",
    "\n",
    "# Center the data\n",
    "W_centered = W_f32 - W_f32.mean(dim=0)\n",
    "\n",
    "# Compute covariance matrix\n",
    "cov = (W_centered.T @ W_centered) / N\n",
    "\n",
    "# Eigendecomposition\n",
    "eigenvalues, eigenvectors = torch.linalg.eigh(cov)\n",
    "\n",
    "# Sort by descending eigenvalue\n",
    "idx = torch.argsort(eigenvalues, descending=True)\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx]\n",
    "\n",
    "print(\"✓ PCA computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Spherical Basis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pc_vector(pcs, index):\n",
    "    \"\"\"Get PC vector by index (1-indexed), with sign flip for negative indices.\"\"\"\n",
    "    pc_num = abs(index) - 1\n",
    "    vector = pcs[:, pc_num].clone()\n",
    "    if index < 0:\n",
    "        vector = -vector\n",
    "    return vector\n",
    "\n",
    "\n",
    "# Extract basis vectors\n",
    "north = get_pc_vector(eigenvectors, NORTH_PC)\n",
    "meridian = get_pc_vector(eigenvectors, MERIDIAN_PC)\n",
    "equinox = get_pc_vector(eigenvectors, EQUINOX_PC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project to Spherical Coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting to spherical coordinates...\n",
      "\n",
      "✓ Spherical coordinates computed\n"
     ]
    }
   ],
   "source": [
    "print(\"Projecting to spherical coordinates...\\n\")\n",
    "\n",
    "# Project onto basis vectors\n",
    "x = W_f32 @ meridian\n",
    "y = W_f32 @ equinox\n",
    "z = W_f32 @ north\n",
    "\n",
    "# Compute radius\n",
    "r = torch.sqrt(x**2 + y**2 + z**2)\n",
    "\n",
    "# Spherical coordinates\n",
    "lat_rad = torch.asin(torch.clamp(z / r, -1, 1))\n",
    "lat_deg = torch.rad2deg(lat_rad)\n",
    "\n",
    "lon_rad = torch.atan2(y, x)\n",
    "lon_deg = torch.rad2deg(lon_rad)\n",
    "\n",
    "print(\"✓ Spherical coordinates computed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Filter: Find Reference Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Applying spatial filter...\n",
      "  Center: (-7.2888°, 6.9400°)\n",
      "  Angular diameter: 0.0010°\n",
      "\n",
      "✓ Found 2,176 tokens in spatial region\n",
      "\n",
      "✓ Selected token 124 as reference h\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nApplying spatial filter...\")\n",
    "print(f\"  Center: ({CENTER_LAT:.4f}°, {CENTER_LON:.4f}°)\")\n",
    "print(f\"  Angular diameter: {ANGULAR_DIAMETER:.4f}°\")\n",
    "print()\n",
    "\n",
    "# Define region bounds\n",
    "half_width = ANGULAR_DIAMETER / 2\n",
    "lat_min = CENTER_LAT - half_width\n",
    "lat_max = CENTER_LAT + half_width\n",
    "lon_min = CENTER_LON - half_width\n",
    "lon_max = CENTER_LON + half_width\n",
    "\n",
    "# Filter tokens\n",
    "spatial_mask = (\n",
    "    (lat_deg >= lat_min) & (lat_deg <= lat_max) &\n",
    "    (lon_deg >= lon_min) & (lon_deg <= lon_max)\n",
    ")\n",
    "\n",
    "n_spatial = spatial_mask.sum().item()\n",
    "spatial_token_ids = spatial_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "print(f\"✓ Found {n_spatial:,} tokens in spatial region\")\n",
    "\n",
    "# Pick arbitrary token as reference\n",
    "ref_token_id = spatial_token_ids[0].item()\n",
    "print(f\"\\n✓ Selected token {ref_token_id} as reference h\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute W @ h in bfloat16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing W @ h in bfloat16...\n",
      "\n",
      "✓ Computed all dot products\n",
      "  h @ h = 0.13769531\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nComputing W @ h in bfloat16...\\n\")\n",
    "\n",
    "# Move to device\n",
    "W_bf16_device = W_bf16.to(device)\n",
    "\n",
    "# Get reference vector\n",
    "h = W_bf16_device[ref_token_id]\n",
    "\n",
    "# Compute all dot products in bfloat16\n",
    "with torch.no_grad():\n",
    "    dots = W_bf16_device @ h\n",
    "\n",
    "# Move to CPU\n",
    "dots_cpu = dots.cpu()\n",
    "\n",
    "# Get h @ h (squared norm of h)\n",
    "h_dot_h = dots_cpu[ref_token_id].item()\n",
    "\n",
    "print(f\"✓ Computed all dot products\")\n",
    "print(f\"  h @ h = {h_dot_h:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Cluster: t @ h == h @ h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding cluster members...\n",
      "\n",
      "✓ Found 3,245 cluster members\n",
      "  (2.136% of vocabulary)\n",
      "\n",
      "First 10 cluster token IDs: [124, 125, 141, 177, 178, 179, 180, 181, 182, 183]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinding cluster members...\\n\")\n",
    "\n",
    "# Find all tokens where t @ h == h @ h in bfloat16\n",
    "cluster_mask = (dots_cpu == h_dot_h)\n",
    "\n",
    "n_cluster = cluster_mask.sum().item()\n",
    "cluster_token_ids = cluster_mask.nonzero(as_tuple=True)[0]\n",
    "\n",
    "print(f\"✓ Found {n_cluster:,} cluster members\")\n",
    "print(f\"  ({n_cluster/N*100:.3f}% of vocabulary)\")\n",
    "print()\n",
    "print(f\"First 10 cluster token IDs: {cluster_token_ids[:10].tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results...\n",
      "\n",
      "✓ Saved to ../tensors/Qwen3-4B-Instruct-2507/1.5d_cluster_mask.safetensors\n",
      "\n",
      "Saved tensors:\n",
      "  cluster_mask: (151936,) - binary mask\n",
      "  cluster_token_ids: (3245,) - token IDs\n",
      "  ref_token_id: scalar - 124\n",
      "  n_cluster: scalar - 3,245\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSaving results...\\n\")\n",
    "\n",
    "# Convert mask to uint8 for storage\n",
    "cluster_mask_uint8 = cluster_mask.to(torch.uint8)\n",
    "\n",
    "# Save to safetensors\n",
    "output_path = Path(f\"../tensors/{MODEL_NAME}/1.5d_cluster_mask.safetensors\")\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_file({\n",
    "    \"cluster_mask\": cluster_mask_uint8,\n",
    "    \"cluster_token_ids\": cluster_token_ids.to(torch.int32),\n",
    "    \"ref_token_id\": torch.tensor([ref_token_id], dtype=torch.int32),\n",
    "    \"n_cluster\": torch.tensor([n_cluster], dtype=torch.int32),\n",
    "}, str(output_path))\n",
    "\n",
    "print(f\"✓ Saved to {output_path}\")\n",
    "print()\n",
    "print(\"Saved tensors:\")\n",
    "print(f\"  cluster_mask: ({N},) - binary mask\")\n",
    "print(f\"  cluster_token_ids: ({n_cluster},) - token IDs\")\n",
    "print(f\"  ref_token_id: scalar - {ref_token_id}\")\n",
    "print(f\"  n_cluster: scalar - {n_cluster:,}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
