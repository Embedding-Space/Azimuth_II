# 2025-11-23

EXPERIMENT SERIES: THIMBLE
LAST COMPLETED EXPERIMENT: THIMBLE 6

# 2025-11-23 09:48:36

Major methodological (dare I use the word) breakthrough this morning. When we're doing our experiments in which we really usually want to load whole tensors at a time (W[6001, 10000, 64] e.g.) it's better to write to HDF5 files in ~2GB chunks. Alph settled on [1500, 10000, 64] as the chunk shape for the four important tensors. This lets an analysis notebook load the whole tensor in four big bites. Or I guess five. Maybe we should revisit our chunk shapes if we're going to have 6,001 layers in the tensor.

OH. Why not [6001, 10000, 64]? Because chunks have to be smaller than 4 GB.

# 2025-11-23 10:09:15

Alph has converted the Thimble 6 HDF5 file to a new `thimble_6_chunky.h5` that's consistent with what I wrote above. Performs very well. We'll use this from now on.

# 2025-11-23 10:25:29

Have discovered that bfloat16 data in Thimble 6 was stored as float16. Odds of this being a problem are very low, but have decided to proceed with Thimble 7 anyway. Nice clean data saved efficiently and faithfully.

# 2025-11-23 10:49:57

Thimble 7 bombed out during training in a way that irritates me. Alph had inserted a print statement â€” no reason, just for show â€” that tried to print the value of a recorded parameter that had already been deallocated when the data file was closed, so the notebook bombed. However, the data file had already been closed, so we got the data. It's just the experiment technically crashed at the end. We can avoid this in the future by isolating long-running compute tasks in their own cells.

# 2025-11-23 11:36:57

Starting to think about Thimble 7 analysis possibilities. Interested in phase transitions. Imagining early, hot phase (Î”W >> ULP), cold phase (Î”W = k ULP for medium k), solid phase (Î”W = k ULP for k â‰¤ 8), frozen phase (Î”W = 0). Possible analysis: Compute Î”W in lattice coordinates, plot Î”W magnitude in ULP as a function of time for all tokens, superimposed, plus the mean and 1 std?

# 2025-11-23 12:23:16

Confusion has arisen about our Î”Wâ€² coordinate system. The idea is that for each coordinate, we calculate the size of the lattice at that value (lattice spacing is constant within the same exponent), then we compute the displacement to the next timestep, then we divide that by the lattice scale. Answer should be an integer. Literally an integer, not approximately. Say to within machine epsilon if not literally 1.000000 integers. My suggestion is if our algorithm produces any non-integers, it's flawed. Trying to settle this now. (See 1.31c.)

# 2025-11-23 12:30:25

Settled. We now have a 31c_delta_W_prime_dead tensor that contains displacement vectors in lattice cells. This tensor is 100% bitwise perfect integers. ðŸŽ‰

Now what to do with it? We can start classifing displacements as classical, quantum, or â€¦ what. Oscillatory?

# 2025-11-23 16:45:14

Alpha has provided me with a new metaphor that I'm trying to accept: particles moving under thrust. They're not reacting to external forces, well they are, but the forces are unique to each particle. I'm now trying to imagine each one as having a little rocket engine.

Which natural makes me think of modeling the dynamics of the cloud as flocking behavior in many dimensions.

# 2025-11-23 16:58:20

We have run into a very frustrating problem. Notebook 1.31j is unable to make predicted Î”W[t] match observed Î”W[t]. This is very basic arithmetic and I am irritated that we don't have this down. We have SOLVED this problem already in 1.25a, b, c.

# 2025-11-23 17:33:05

Alph has solved this problem with alacrity and aplomb. See 1.31j for the algorithm.

# 2025-11-23 18:05:20

Oh, see 1.13k for such sights. I understand now that it's really the variance term in the AdamW algorithm that drives the onset of fimbulwinter. It shoots up, overcorrects, then just grows inexorably, linearly, until even sizable gradient updates just can't move a token on the coarse bfloat16 lattice.