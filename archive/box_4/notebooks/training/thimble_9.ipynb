{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Thimble 9: Long-Haul Fimbulwinter Hunt\n",
    "\n",
    "Train for 10,000 steps to definitively capture the onset of Fimbulwinter.\n",
    "\n",
    "**Stripped-down data capture:**\n",
    "- W only (dead tokens, bfloat16 as uint16)\n",
    "- Loss per step\n",
    "- Sparse checkpoints\n",
    "\n",
    "**Verification mode:** First run with 1,000 steps to confirm bitwise equality with Thimble 8.\n",
    "\n",
    "**Expected output:** ~4.7 GB for full 10k run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODE: PRODUCTION (10000 steps)\n",
      "Total steps: 10000\n"
     ]
    }
   ],
   "source": [
    "# === VERIFICATION MODE ===\n",
    "# Set to True for 1000-step verification run against Thimble 8\n",
    "# Set to False for full 10,000-step production run\n",
    "VERIFICATION_MODE = False\n",
    "\n",
    "# Training parameters (MUST match Thimble 8 exactly)\n",
    "TOTAL_STEPS = 1000 if VERIFICATION_MODE else 10000\n",
    "BATCH_SIZE = 128\n",
    "SEQ_LEN = 128\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 0.1\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "# Model parameters (MUST match Thimble 8 exactly)\n",
    "VOCAB_SIZE = 10000\n",
    "HIDDEN_DIM = 64\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 2\n",
    "\n",
    "# Reproducibility (MUST match Thimble 8 exactly)\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Checkpointing (sparse for long run)\n",
    "if VERIFICATION_MODE:\n",
    "    CHECKPOINT_STEPS = [0, 100, 500, 1000]\n",
    "else:\n",
    "    CHECKPOINT_STEPS = [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n",
    "\n",
    "# Paths\n",
    "CORPUS_PATH = '../../data/flannel_model_corpus.txt'\n",
    "TOKENIZER_PATH = '../../data/flannel_tokenizer_chars.json'\n",
    "DEAD_MASK_PATH = '../../tensors/Flannel/live_dead_tokens.safetensors'\n",
    "OUTPUT_DIR = '../../tensors/Thimble-9'\n",
    "\n",
    "# For verification comparison\n",
    "THIMBLE_8_PATH = '../../tensors/Thimble-8/thimble_8_trajectory.safetensors'\n",
    "\n",
    "print(f\"MODE: {'VERIFICATION (1000 steps)' if VERIFICATION_MODE else 'PRODUCTION (10000 steps)'}\")\n",
    "print(f\"Total steps: {TOTAL_STEPS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "from safetensors.torch import save_file, load_file\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Device Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Set Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(f\"Random seed set to {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Load Tokenizer and Dead Token Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer with vocab size 10000\n",
      "Dead tokens: 3699\n",
      "Live tokens: 6301\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_file(TOKENIZER_PATH)\n",
    "print(f\"Loaded tokenizer with vocab size {tokenizer.get_vocab_size()}\")\n",
    "\n",
    "masks = load_file(DEAD_MASK_PATH)\n",
    "dead_mask = masks['dead_mask'].bool()\n",
    "dead_indices = masks['dead_indices'].long()\n",
    "n_dead = dead_mask.sum().item()\n",
    "\n",
    "print(f\"Dead tokens: {n_dead}\")\n",
    "print(f\"Live tokens: {VOCAB_SIZE - n_dead}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 10713 sequences of length 128\n",
      "Total tokens: 1,371,264\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"Simple dataset that returns chunks of tokenized text.\"\"\"\n",
    "    \n",
    "    def __init__(self, corpus_path, tokenizer, seq_len):\n",
    "        with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        \n",
    "        encoding = tokenizer.encode(text)\n",
    "        self.tokens = encoding.ids\n",
    "        self.seq_len = seq_len\n",
    "        self.n_sequences = len(self.tokens) // seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_sequences\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.seq_len\n",
    "        chunk = self.tokens[start:start + self.seq_len]\n",
    "        return torch.tensor(chunk, dtype=torch.long)\n",
    "\n",
    "\n",
    "dataset = TextDataset(CORPUS_PATH, tokenizer, SEQ_LEN)\n",
    "print(f\"Dataset: {len(dataset)} sequences of length {SEQ_LEN}\")\n",
    "print(f\"Total tokens: {len(dataset) * SEQ_LEN:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 748,288\n",
      "Embedding shape: torch.Size([10000, 64])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jefferyharrell/Projects/Azimuth_II/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class TinyLM(nn.Module):\n",
    "    \"\"\"Minimal language model with tied embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_dim, num_layers, num_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(SEQ_LEN, hidden_dim)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim * 4,\n",
    "            dropout=0.0,\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.ln_f = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.pos_embedding.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, input_ids):\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        \n",
    "        tok_emb = self.embedding(input_ids)\n",
    "        pos_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        pos_emb = self.pos_embedding(pos_ids)\n",
    "        \n",
    "        hidden = tok_emb + pos_emb\n",
    "        \n",
    "        causal_mask = nn.Transformer.generate_square_subsequent_mask(seq_len, device=input_ids.device)\n",
    "        \n",
    "        hidden = self.transformer(hidden, mask=causal_mask, is_causal=True)\n",
    "        hidden = self.ln_f(hidden)\n",
    "        \n",
    "        logits = hidden @ self.embedding.weight.T\n",
    "        \n",
    "        return logits\n",
    "\n",
    "\n",
    "model = TinyLM(VOCAB_SIZE, HIDDEN_DIM, NUM_LAYERS, NUM_HEADS)\n",
    "model = model.to(device).to(torch.bfloat16)\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params:,}\")\n",
    "print(f\"Embedding shape: {model.embedding.weight.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: AdamW\n",
      "  lr=0.0003, weight_decay=0.1\n",
      "  betas=(0.9, 0.999), eps=1e-08\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(BETA1, BETA2),\n",
    "    eps=EPSILON,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: AdamW\")\n",
    "print(f\"  lr={LEARNING_RATE}, weight_decay={WEIGHT_DECAY}\")\n",
    "print(f\"  betas=({BETA1}, {BETA2}), eps={EPSILON}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Data Collection Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-allocated 4.74 GB for data collection\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(OUTPUT_DIR)\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "checkpoint_path = output_path / 'checkpoints'\n",
    "checkpoint_path.mkdir(exist_ok=True)\n",
    "\n",
    "# Stripped down: W only (as bfloat16/uint16) + loss\n",
    "W_history = torch.zeros(TOTAL_STEPS + 1, n_dead, HIDDEN_DIM, dtype=torch.bfloat16)\n",
    "loss_history = torch.zeros(TOTAL_STEPS + 1, dtype=torch.float32)\n",
    "\n",
    "total_bytes = W_history.numel() * 2 + loss_history.numel() * 4\n",
    "print(f\"Pre-allocated {total_bytes / 1e9:.2f} GB for data collection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_state(model, step, dead_mask, loss_val=0.0):\n",
    "    \"\"\"Capture W for dead tokens only.\"\"\"\n",
    "    W = model.embedding.weight.detach().cpu()[dead_mask]\n",
    "    W_history[step] = W.to(torch.bfloat16)\n",
    "    loss_history[step] = loss_val\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, step, path):\n",
    "    \"\"\"Save full model and optimizer checkpoint.\"\"\"\n",
    "    checkpoint = {\n",
    "        'step': step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'rng_state': torch.get_rng_state(),\n",
    "    }\n",
    "    if device == 'cuda':\n",
    "        checkpoint['cuda_rng_state'] = torch.cuda.get_rng_state_all()\n",
    "    \n",
    "    torch.save(checkpoint, path / f'checkpoint_step_{step:05d}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cell-22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 0\n",
      "\n",
      "Starting training for 10000 steps...\n",
      "Checkpoints at: [0, 1000, 2000, 3000, 4000, 5000, 6000, 7000, 8000, 9000, 10000]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  10%|█         | 1002/10000 [01:00<09:21, 16.04it/s, loss=6.6562, epoch=13]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20%|██        | 2002/10000 [02:00<08:16, 16.10it/s, loss=6.3750, epoch=25]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  30%|███       | 3002/10000 [03:02<07:15, 16.09it/s, loss=6.3438, epoch=37]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40%|████      | 4002/10000 [04:03<06:20, 15.76it/s, loss=6.2500, epoch=49]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  50%|█████     | 5002/10000 [05:06<05:29, 15.19it/s, loss=6.2188, epoch=61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60%|██████    | 6002/10000 [06:09<04:21, 15.30it/s, loss=6.2812, epoch=73]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  70%|███████   | 7002/10000 [07:12<03:25, 14.59it/s, loss=6.2188, epoch=85]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 7000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80%|████████  | 8002/10000 [08:15<02:06, 15.75it/s, loss=6.2188, epoch=97]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  90%|█████████ | 9002/10000 [09:15<01:03, 15.74it/s, loss=6.2500, epoch=109]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 9000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10000/10000 [10:17<00:00, 16.21it/s, loss=6.2188, epoch=121]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoint at step 10000\n",
      "\n",
      "Training complete. Final loss: 6.2188\n",
      "Completed 121 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Capture initial state\n",
    "capture_state(model, step=0, dead_mask=dead_mask, loss_val=0.0)\n",
    "if 0 in CHECKPOINT_STEPS:\n",
    "    save_checkpoint(model, optimizer, 0, checkpoint_path)\n",
    "    print(\"Saved checkpoint at step 0\")\n",
    "\n",
    "print(f\"\\nStarting training for {TOTAL_STEPS} steps...\")\n",
    "print(f\"Checkpoints at: {CHECKPOINT_STEPS}\")\n",
    "\n",
    "model.train()\n",
    "step = 0\n",
    "epoch = 0\n",
    "\n",
    "pbar = tqdm(total=TOTAL_STEPS, desc=\"Training\")\n",
    "\n",
    "while step < TOTAL_STEPS:\n",
    "    epoch += 1\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        if step >= TOTAL_STEPS:\n",
    "            break\n",
    "            \n",
    "        input_ids = batch.to(device)\n",
    "        \n",
    "        with torch.autocast(device_type=device if device != 'mps' else 'cpu', dtype=torch.bfloat16):\n",
    "            logits = model(input_ids)\n",
    "            \n",
    "            shift_logits = logits[:, :-1, :].contiguous()\n",
    "            shift_labels = input_ids[:, 1:].contiguous()\n",
    "            \n",
    "            loss = loss_fn(\n",
    "                shift_logits.view(-1, VOCAB_SIZE),\n",
    "                shift_labels.view(-1)\n",
    "            )\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        capture_state(model, step=step, dead_mask=dead_mask, loss_val=loss.item())\n",
    "        \n",
    "        if step in CHECKPOINT_STEPS:\n",
    "            save_checkpoint(model, optimizer, step, checkpoint_path)\n",
    "            tqdm.write(f\"Saved checkpoint at step {step}\")\n",
    "        \n",
    "        pbar.set_postfix({'loss': f'{loss.item():.4f}', 'epoch': epoch})\n",
    "        pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\nTraining complete. Final loss: {loss.item():.4f}\")\n",
    "print(f\"Completed {epoch} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Verification: Compare to Thimble 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cell-24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping verification (production mode)\n"
     ]
    }
   ],
   "source": [
    "if VERIFICATION_MODE:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"VERIFICATION: Comparing to Thimble 8\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Load Thimble 8 data\n",
    "    thimble_8_data = load_file(THIMBLE_8_PATH)\n",
    "    W_thimble_8 = thimble_8_data['W'].view(torch.bfloat16)  # (4001, 3699, 64)\n",
    "    \n",
    "    # Compare first 1001 steps (0 through 1000)\n",
    "    W_thimble_9 = W_history  # (1001, 3699, 64)\n",
    "    W_thimble_8_subset = W_thimble_8[:1001]  # (1001, 3699, 64)\n",
    "    \n",
    "    print(f\"Thimble 9 W shape: {W_thimble_9.shape}\")\n",
    "    print(f\"Thimble 8 W subset shape: {W_thimble_8_subset.shape}\")\n",
    "    \n",
    "    # Bitwise comparison (view as uint16 for exact bit comparison)\n",
    "    W9_bits = W_thimble_9.view(torch.uint16)\n",
    "    W8_bits = W_thimble_8_subset.view(torch.uint16)\n",
    "    \n",
    "    exact_match = (W9_bits == W8_bits).all().item()\n",
    "    \n",
    "    if exact_match:\n",
    "        print(\"\\n✓ BITWISE IDENTICAL: Thimble 9 matches Thimble 8 exactly!\")\n",
    "    else:\n",
    "        # Find where they differ\n",
    "        diff_mask = W9_bits != W8_bits\n",
    "        n_diff = diff_mask.sum().item()\n",
    "        total_elements = W9_bits.numel()\n",
    "        \n",
    "        print(f\"\\n✗ MISMATCH: {n_diff:,} / {total_elements:,} elements differ ({n_diff/total_elements:.4%})\")\n",
    "        \n",
    "        # Find first differing timestep\n",
    "        diff_per_step = diff_mask.any(dim=(1, 2))\n",
    "        first_diff_step = torch.where(diff_per_step)[0]\n",
    "        if len(first_diff_step) > 0:\n",
    "            print(f\"First difference at step: {first_diff_step[0].item()}\")\n",
    "        \n",
    "        # Check step 0 specifically (initialization)\n",
    "        step0_match = (W9_bits[0] == W8_bits[0]).all().item()\n",
    "        print(f\"Step 0 (initialization) matches: {step0_match}\")\n",
    "        \n",
    "        # Check loss values\n",
    "        loss_8 = thimble_8_data['loss'][:1001]\n",
    "        loss_9 = loss_history\n",
    "        loss_match = torch.allclose(loss_8, loss_9, rtol=1e-5, atol=1e-5)\n",
    "        print(f\"Loss values match (within tolerance): {loss_match}\")\n",
    "        \n",
    "        if not loss_match:\n",
    "            # Find first loss divergence\n",
    "            loss_diff = (loss_8 - loss_9).abs()\n",
    "            max_diff_idx = loss_diff.argmax().item()\n",
    "            print(f\"Max loss difference at step {max_diff_idx}: {loss_diff[max_diff_idx]:.6f}\")\n",
    "else:\n",
    "    print(\"Skipping verification (production mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Save Data (if not verification mode, or if verification passed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cell-26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved trajectory data to ../../tensors/Thimble-9/thimble_9_trajectory.safetensors\n",
      "File size: 4.74 GB\n",
      "Saved metadata.json\n"
     ]
    }
   ],
   "source": [
    "if VERIFICATION_MODE:\n",
    "    print(\"\\nVerification mode: Not saving trajectory data.\")\n",
    "    print(\"If verification passed, set VERIFICATION_MODE = False and rerun.\")\n",
    "else:\n",
    "    data_to_save = {\n",
    "        'W': W_history.view(torch.uint16),  # Store as uint16 to preserve bfloat16 bits\n",
    "        'loss': loss_history,\n",
    "        'dead_mask': dead_mask,\n",
    "        'dead_indices': dead_indices,\n",
    "    }\n",
    "    \n",
    "    save_path = output_path / 'thimble_9_trajectory.safetensors'\n",
    "    save_file(data_to_save, str(save_path))\n",
    "    \n",
    "    print(f\"Saved trajectory data to {save_path}\")\n",
    "    print(f\"File size: {save_path.stat().st_size / 1e9:.2f} GB\")\n",
    "    \n",
    "    # Save metadata\n",
    "    metadata = {\n",
    "        'experiment': 'Thimble 9',\n",
    "        'date': '2025-11-25',\n",
    "        'total_steps': TOTAL_STEPS,\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'seq_len': SEQ_LEN,\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'weight_decay': WEIGHT_DECAY,\n",
    "        'beta1': BETA1,\n",
    "        'beta2': BETA2,\n",
    "        'epsilon': EPSILON,\n",
    "        'vocab_size': VOCAB_SIZE,\n",
    "        'hidden_dim': HIDDEN_DIM,\n",
    "        'num_layers': NUM_LAYERS,\n",
    "        'num_heads': NUM_HEADS,\n",
    "        'random_seed': RANDOM_SEED,\n",
    "        'n_dead_tokens': n_dead,\n",
    "        'checkpoint_steps': CHECKPOINT_STEPS,\n",
    "        'final_loss': loss_history[-1].item(),\n",
    "        'total_epochs': epoch,\n",
    "        'device': device,\n",
    "        'data_shapes': {\n",
    "            'W': list(W_history.shape),\n",
    "            'loss': list(loss_history.shape),\n",
    "        },\n",
    "        'notes': 'Dead tokens only. W stored as uint16 (bfloat16 bit pattern). Stripped-down for long run.'\n",
    "    }\n",
    "    \n",
    "    with open(output_path / 'metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(\"Saved metadata.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
