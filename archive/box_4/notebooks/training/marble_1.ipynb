{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Marble 1: Does Size Matter?\n",
    "\n",
    "**Series:** Marble (hyperparameter exploration for minimal viable LM)\n",
    "\n",
    "**Goal:** Find the smallest model that learns *beyond unigram distribution* while training fast enough to iterate on a MacBook.\n",
    "\n",
    "**This run:**\n",
    "- Model: 4L, 128D, 4H (~3-4M params)\n",
    "- Training: 5000 steps, lr=3e-4, wd=0.01\n",
    "- Target: ~100 steps/minute\n",
    "\n",
    "**Success criteria:**\n",
    "1. Loss drops below 5.0 (better than Flannel's 5.25)\n",
    "2. Top predictions include context-dependent tokens (not just comma/period)\n",
    "3. h_mean shows direction changes (not converging to static point)\n",
    "4. Dead tokens show motion → slowing pattern (approaching freeze)\n",
    "\n",
    "**Data storage:**\n",
    "- Live metrics logged to CSV every epoch\n",
    "- Checkpoints saved every 500 steps (W as bfloat16, h_mean as float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Marble 1: 4L, 128D, 4H\n",
      "Training: 5000 steps, lr=0.0003, wd=0.01\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "TOTAL_STEPS = 5000\n",
    "BATCH_SIZE = 128\n",
    "SEQ_LEN = 128\n",
    "LEARNING_RATE = 3e-4      # Standard LM lr\n",
    "WEIGHT_DECAY = 0.01       # Gentle regularization\n",
    "BETA1 = 0.9\n",
    "BETA2 = 0.999\n",
    "EPSILON = 1e-8\n",
    "\n",
    "# Model architecture\n",
    "VOCAB_SIZE = 10000\n",
    "HIDDEN_DIM = 128          # 2× Flannel\n",
    "NUM_LAYERS = 4            # 2× Flannel\n",
    "NUM_HEADS = 4\n",
    "\n",
    "# Checkpointing\n",
    "CHECKPOINT_INTERVAL = 500  # Save W and h_mean every N steps\n",
    "\n",
    "# Reproducibility\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# Paths\n",
    "CORPUS_PATH = '../../data/flannel_model_corpus.txt'\n",
    "TOKENIZER_PATH = '../../data/flannel_tokenizer_chars.json'\n",
    "DEAD_MASK_PATH = '../../tensors/Flannel/live_dead_tokens.safetensors'\n",
    "OUTPUT_DIR = '../../tensors/Marble-1'\n",
    "\n",
    "print(f\"Marble 1: {NUM_LAYERS}L, {HIDDEN_DIM}D, {NUM_HEADS}H\")\n",
    "print(f\"Training: {TOTAL_STEPS} steps, lr={LEARNING_RATE}, wd={WEIGHT_DECAY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tokenizers import Tokenizer\n",
    "from safetensors.torch import save_file, load_file\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Random Seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 42\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "\n",
    "print(f\"Random seed set to {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer and Dead Token Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer with vocab size 10000\n",
      "Dead tokens: 3699\n",
      "Live tokens: 6301\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer.from_file(TOKENIZER_PATH)\n",
    "print(f\"Loaded tokenizer with vocab size {tokenizer.get_vocab_size()}\")\n",
    "\n",
    "masks = load_file(DEAD_MASK_PATH)\n",
    "dead_mask = masks['dead_mask'].bool()\n",
    "dead_indices = masks['dead_indices'].long()\n",
    "live_mask = ~dead_mask\n",
    "n_dead = dead_mask.sum().item()\n",
    "n_live = live_mask.sum().item()\n",
    "\n",
    "print(f\"Dead tokens: {n_dead}\")\n",
    "print(f\"Live tokens: {n_live}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: 10713 sequences of length 128\n",
      "Epoch length: ~83 steps\n"
     ]
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, corpus_path, tokenizer, seq_len):\n",
    "        with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        encoding = tokenizer.encode(text)\n",
    "        self.tokens = encoding.ids\n",
    "        self.seq_len = seq_len\n",
    "        self.n_sequences = len(self.tokens) // seq_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.n_sequences\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        start = idx * self.seq_len\n",
    "        chunk = self.tokens[start:start + self.seq_len]\n",
    "        return torch.tensor(chunk, dtype=torch.long)\n",
    "\n",
    "dataset = TextDataset(CORPUS_PATH, tokenizer, SEQ_LEN)\n",
    "EPOCH_LENGTH = len(dataset) // BATCH_SIZE\n",
    "\n",
    "print(f\"Dataset: {len(dataset)} sequences of length {SEQ_LEN}\")\n",
    "print(f\"Epoch length: ~{EPOCH_LENGTH} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "**Architecture:** 4L, 128D, 4H  \n",
    "**Compute dtype:** bfloat16 (like Qwen)  \n",
    "**Storage dtype:** bfloat16 for W checkpoints, float32 for metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 2,089,728 (2.09M)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jefferyharrell/Projects/Azimuth_II/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class TinyLM(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, num_layers, num_heads, seq_len):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_dim)\n",
    "        self.pos_embedding = nn.Embedding(seq_len, hidden_dim)\n",
    "        \n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=hidden_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=hidden_dim * 4,\n",
    "            dropout=0.0,\n",
    "            activation='gelu',\n",
    "            batch_first=True,\n",
    "            norm_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.ln_f = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        # Xavier init for embeddings\n",
    "        nn.init.normal_(self.embedding.weight, mean=0.0, std=0.02)\n",
    "        nn.init.normal_(self.pos_embedding.weight, mean=0.0, std=0.02)\n",
    "        \n",
    "    def forward(self, input_ids, return_hidden=False):\n",
    "        \"\"\"Forward pass. Returns logits, or (logits, h) if return_hidden=True.\"\"\"\n",
    "        batch_size, seq_len = input_ids.shape\n",
    "        \n",
    "        tok_emb = self.embedding(input_ids)\n",
    "        pos_ids = torch.arange(seq_len, device=input_ids.device).unsqueeze(0)\n",
    "        pos_emb = self.pos_embedding(pos_ids)\n",
    "        \n",
    "        hidden = tok_emb + pos_emb\n",
    "        causal_mask = nn.Transformer.generate_square_subsequent_mask(seq_len, device=input_ids.device)\n",
    "        hidden = self.transformer(hidden, mask=causal_mask, is_causal=True)\n",
    "        hidden = self.ln_f(hidden)  # This is h\n",
    "        \n",
    "        logits = hidden @ self.embedding.weight.T\n",
    "        \n",
    "        if return_hidden:\n",
    "            return logits, hidden\n",
    "        return logits\n",
    "\n",
    "model = TinyLM(VOCAB_SIZE, HIDDEN_DIM, NUM_LAYERS, NUM_HEADS, SEQ_LEN)\n",
    "model = model.to(device).to(torch.bfloat16)  # Train in bfloat16 like Qwen\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Model parameters: {n_params:,} ({n_params/1e6:.2f}M)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "AdamW with float32 states (optimizer requires full precision)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizer: AdamW (lr=0.0003, wd=0.01)\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE,\n",
    "    betas=(BETA1, BETA2),\n",
    "    eps=EPSILON,\n",
    "    weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "print(f\"Optimizer: AdamW (lr={LEARNING_RATE}, wd={WEIGHT_DECAY})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and Checkpointing Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: ../../tensors/Marble-1\n",
      "Checkpoints every 500 steps\n"
     ]
    }
   ],
   "source": [
    "output_path = Path(OUTPUT_DIR)\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Metrics log (lightweight, written every epoch)\n",
    "metrics_log = []\n",
    "\n",
    "# Checkpoint storage (every CHECKPOINT_INTERVAL steps)\n",
    "checkpoints = {\n",
    "    'steps': [],      # Which steps we saved\n",
    "    'W': [],          # bfloat16\n",
    "    'h_mean': [],     # float32\n",
    "}\n",
    "\n",
    "print(f\"Output directory: {output_path}\")\n",
    "print(f\"Checkpoints every {CHECKPOINT_INTERVAL} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "### Lattice Displacement (for dead token motion detection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Lattice displacement functions defined\n"
     ]
    }
   ],
   "source": [
    "def compute_ulp_bf16(tensor_bf16):\n",
    "    \"\"\"Compute ULP (Unit in Last Place) for bfloat16 tensor.\n",
    "    \n",
    "    Formula: ULP = 2^(E - 134) where E is the exponent.\n",
    "    Returns float32 tensor of ULP values.\n",
    "    \"\"\"\n",
    "    bits = tensor_bf16.view(torch.uint16).to(torch.int32)\n",
    "    exponent = ((bits >> 7) & 0xFF).to(torch.int32)\n",
    "    \n",
    "    # Subnormals: treat E=0 as E=1\n",
    "    effective_exp = torch.where(exponent == 0, torch.ones_like(exponent), exponent)\n",
    "    \n",
    "    ulp = torch.pow(2.0, (effective_exp - 134).float())\n",
    "    return ulp\n",
    "\n",
    "def compute_lattice_displacement(W_before, W_after):\n",
    "    \"\"\"Compute lattice displacement ΔW′ = ΔW / ULP.\n",
    "    \n",
    "    Args:\n",
    "        W_before: bfloat16 weights at time t-1\n",
    "        W_after: bfloat16 weights at time t\n",
    "    \n",
    "    Returns:\n",
    "        float32 tensor of lattice displacements (per dimension)\n",
    "    \"\"\"\n",
    "    delta_W = W_after.float() - W_before.float()\n",
    "    ulp = compute_ulp_bf16(W_before)\n",
    "    return delta_W / ulp\n",
    "\n",
    "def fraction_moving(W_before, W_after, mask):\n",
    "    \"\"\"Fraction of tokens (selected by mask) with L1 > 0 (any dimension moved).\n",
    "    \n",
    "    Args:\n",
    "        W_before, W_after: bfloat16 weight matrices\n",
    "        mask: boolean mask selecting tokens to measure\n",
    "    \n",
    "    Returns:\n",
    "        float: fraction of masked tokens that moved\n",
    "    \"\"\"\n",
    "    delta_W_prime = compute_lattice_displacement(W_before[mask], W_after[mask])\n",
    "    L1 = delta_W_prime.abs().sum(dim=1)  # Sum across dimensions\n",
    "    moving = (L1 > 0).float().mean().item()\n",
    "    return moving\n",
    "\n",
    "print(\"✓ Lattice displacement functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "**Live metrics computed every epoch:**\n",
    "1. Loss\n",
    "2. Top-3 predicted tokens (from h_mean)\n",
    "3. h_mean autocorrelation (vs previous step)\n",
    "4. Fraction of dead tokens moving (L1 > 0)\n",
    "\n",
    "**Checkpoints saved every 500 steps:**\n",
    "- W (bfloat16)\n",
    "- h_mean (float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training for 5000 steps...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 5000/5000 [09:15<00:00,  8.99it/s, loss=5.4688, dead_moving=0.075, epoch=61]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete. Final loss: 5.4688\n",
      "Completed 61 epochs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "step = 0\n",
    "epoch = 0\n",
    "\n",
    "# Previous step's data for metrics\n",
    "h_mean_prev = None\n",
    "W_prev = None\n",
    "\n",
    "# Initial checkpoint (t=0)\n",
    "W_init = model.embedding.weight.detach().cpu().to(torch.bfloat16)\n",
    "checkpoints['steps'].append(0)\n",
    "checkpoints['W'].append(W_init)\n",
    "checkpoints['h_mean'].append(torch.zeros(HIDDEN_DIM))  # Placeholder for t=0\n",
    "\n",
    "print(f\"Starting training for {TOTAL_STEPS} steps...\")\n",
    "pbar = tqdm(total=TOTAL_STEPS, desc=\"Training\")\n",
    "\n",
    "while step < TOTAL_STEPS:\n",
    "    epoch += 1\n",
    "    \n",
    "    for batch in dataloader:\n",
    "        if step >= TOTAL_STEPS:\n",
    "            break\n",
    "        \n",
    "        input_ids = batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.autocast(device_type=device if device != 'mps' else 'cpu', dtype=torch.bfloat16):\n",
    "            logits, h = model(input_ids, return_hidden=True)\n",
    "            shift_logits = logits[:, :-1, :].contiguous()\n",
    "            shift_labels = input_ids[:, 1:].contiguous()\n",
    "            loss = loss_fn(shift_logits.view(-1, VOCAB_SIZE), shift_labels.view(-1))\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        step += 1\n",
    "        \n",
    "        # === Compute metrics ===\n",
    "        \n",
    "        # Get current state (float32 for metrics, bfloat16 for storage)\n",
    "        W_current_bf16 = model.embedding.weight.detach().cpu().to(torch.bfloat16)\n",
    "        W_current_f32 = W_current_bf16.float()\n",
    "        h_mean_current = h.mean(dim=(0, 1)).cpu().float()  # (D,)\n",
    "        \n",
    "        # Top-3 tokens (unembedding logits from h_mean)\n",
    "        logits_from_h = h_mean_current @ W_current_f32.T\n",
    "        top3_tokens = torch.topk(logits_from_h, k=3).indices.tolist()\n",
    "        \n",
    "        # h_mean autocorrelation\n",
    "        if h_mean_prev is not None:\n",
    "            h_autocorr = torch.dot(h_mean_current, h_mean_prev) / \\\n",
    "                        (torch.norm(h_mean_current) * torch.norm(h_mean_prev))\n",
    "            h_autocorr = h_autocorr.item()\n",
    "        else:\n",
    "            h_autocorr = float('nan')\n",
    "        \n",
    "        # Dead token motion\n",
    "        if W_prev is not None:\n",
    "            dead_moving = fraction_moving(W_prev, W_current_bf16, dead_mask)\n",
    "        else:\n",
    "            dead_moving = float('nan')\n",
    "        \n",
    "        # Log metrics\n",
    "        metrics_log.append({\n",
    "            'step': step,\n",
    "            'epoch': epoch,\n",
    "            'loss': loss.item(),\n",
    "            'top1': top3_tokens[0],\n",
    "            'top2': top3_tokens[1],\n",
    "            'top3': top3_tokens[2],\n",
    "            'h_autocorr': h_autocorr,\n",
    "            'dead_moving': dead_moving,\n",
    "        })\n",
    "        \n",
    "        # Checkpoint if needed\n",
    "        if step % CHECKPOINT_INTERVAL == 0:\n",
    "            checkpoints['steps'].append(step)\n",
    "            checkpoints['W'].append(W_current_bf16.clone())\n",
    "            checkpoints['h_mean'].append(h_mean_current.clone())\n",
    "        \n",
    "        # Update previous state\n",
    "        h_mean_prev = h_mean_current\n",
    "        W_prev = W_current_bf16\n",
    "        \n",
    "        # Progress bar\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'dead_moving': f'{dead_moving:.3f}' if not np.isnan(dead_moving) else 'N/A',\n",
    "            'epoch': epoch\n",
    "        })\n",
    "        pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "print(f\"\\nTraining complete. Final loss: {loss.item():.4f}\")\n",
    "print(f\"Completed {epoch} epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Metrics CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metrics to ../../tensors/Marble-1/metrics.csv\n",
      "  Rows: 5000\n",
      "  Columns: ['step', 'epoch', 'loss', 'top1', 'top2', 'top3', 'h_autocorr', 'dead_moving']\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(metrics_log)\n",
    "csv_path = output_path / 'metrics.csv'\n",
    "df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Saved metrics to {csv_path}\")\n",
    "print(f\"  Rows: {len(df)}\")\n",
    "print(f\"  Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved checkpoints to ../../tensors/Marble-1/checkpoints.safetensors\n",
      "  11 checkpoints\n",
      "  File size: 28.21 MB\n"
     ]
    }
   ],
   "source": [
    "# Stack checkpoints into tensors\n",
    "checkpoint_steps = torch.tensor(checkpoints['steps'], dtype=torch.int64)\n",
    "checkpoint_W = torch.stack(checkpoints['W'])  # (n_checkpoints, vocab, dim) bfloat16\n",
    "checkpoint_h_mean = torch.stack(checkpoints['h_mean'])  # (n_checkpoints, dim) float32\n",
    "\n",
    "checkpoint_data = {\n",
    "    'steps': checkpoint_steps,\n",
    "    'W': checkpoint_W.view(torch.uint16),  # Store bfloat16 as uint16\n",
    "    'h_mean': checkpoint_h_mean,\n",
    "    'dead_mask': dead_mask,\n",
    "    'dead_indices': dead_indices,\n",
    "}\n",
    "\n",
    "checkpoint_path = output_path / 'checkpoints.safetensors'\n",
    "save_file(checkpoint_data, str(checkpoint_path))\n",
    "\n",
    "print(f\"Saved checkpoints to {checkpoint_path}\")\n",
    "print(f\"  {len(checkpoints['steps'])} checkpoints\")\n",
    "print(f\"  File size: {checkpoint_path.stat().st_size / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved metadata.json\n",
      "\n",
      "============================================================\n",
      "MARBLE 1 COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "metadata = {\n",
    "    'experiment': 'Marble 1',\n",
    "    'series': 'Marble',\n",
    "    'date': datetime.now().strftime('%Y-%m-%d'),\n",
    "    'total_steps': TOTAL_STEPS,\n",
    "    'batch_size': BATCH_SIZE,\n",
    "    'seq_len': SEQ_LEN,\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'weight_decay': WEIGHT_DECAY,\n",
    "    'beta1': BETA1,\n",
    "    'beta2': BETA2,\n",
    "    'epsilon': EPSILON,\n",
    "    'vocab_size': VOCAB_SIZE,\n",
    "    'hidden_dim': HIDDEN_DIM,\n",
    "    'num_layers': NUM_LAYERS,\n",
    "    'num_heads': NUM_HEADS,\n",
    "    'n_params': n_params,\n",
    "    'random_seed': RANDOM_SEED,\n",
    "    'n_dead_tokens': n_dead,\n",
    "    'n_live_tokens': n_live,\n",
    "    'final_loss': metrics_log[-1]['loss'],\n",
    "    'total_epochs': epoch,\n",
    "    'epoch_length': EPOCH_LENGTH,\n",
    "    'device': device,\n",
    "    'checkpoint_interval': CHECKPOINT_INTERVAL,\n",
    "    'n_checkpoints': len(checkpoints['steps']),\n",
    "    'notes': '4L, 128D, 4H model. Testing if larger architecture learns beyond unigram.'\n",
    "}\n",
    "\n",
    "with open(output_path / 'metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"Saved metadata.json\")\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"MARBLE 1 COMPLETE\")\n",
    "print(f\"{'='*60}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
