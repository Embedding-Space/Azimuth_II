{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08.4c: Pairwise Distance Matrices (Parallel Runs)\n",
    "\n",
    "**Compute pairwise distance matrices for all 16 parallel training runs**\n",
    "\n",
    "This notebook processes all 16 training runs and computes Chebyshev distance matrices for each step. These matrices are essential for adjacency graph analysis and black hole fission detection.\n",
    "\n",
    "## Distance Metric\n",
    "\n",
    "**Chebyshev (L∞)**: Maximum absolute difference across dimensions\n",
    "$$d_\\infty(u, v) = \\max_i |u_i - v_i|$$\n",
    "\n",
    "Chebyshev is ideal for detecting quantization neighbors—tokens differing by less than the bfloat16 quantization threshold in every dimension.\n",
    "\n",
    "## Output\n",
    "\n",
    "For each run, saves:\n",
    "- `chebyshev_distances`: (10001, 128, 128) float32\n",
    "- Total per run: ~655 MB\n",
    "- Total for 16 runs: ~10.5 GB\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data directories\n",
    "DATA_DIR = \"../data\"\n",
    "RUN_PATTERN = \"embeddings_128vocab_qweninit_run_*\"\n",
    "EMBEDDING_FILE = \"embedding_evolution.safetensors\"\n",
    "EMBEDDING_KEY = \"embedding_history\"\n",
    "OUTPUT_FILE = \"pairwise_distances.safetensors\"\n",
    "\n",
    "# Expected dimensions\n",
    "EXPECTED_RUNS = 16\n",
    "EXPECTED_STEPS = 10001\n",
    "VOCAB_SIZE = 128\n",
    "HIDDEN_DIM = 64\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from safetensors.torch import load_file, save_file\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps (Apple Silicon (MPS))\n"
     ]
    }
   ],
   "source": [
    "# Auto-detect best available device\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    device_name = \"Apple Silicon (MPS)\"\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device_name = \"CPU\"\n",
    "\n",
    "print(f\"Using device: {device} ({device_name})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find All Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 runs:\n",
      "  embeddings_128vocab_qweninit_run_001\n",
      "  embeddings_128vocab_qweninit_run_002\n",
      "  embeddings_128vocab_qweninit_run_003\n",
      "  embeddings_128vocab_qweninit_run_004\n",
      "  embeddings_128vocab_qweninit_run_005\n",
      "  embeddings_128vocab_qweninit_run_006\n",
      "  embeddings_128vocab_qweninit_run_007\n",
      "  embeddings_128vocab_qweninit_run_008\n",
      "  embeddings_128vocab_qweninit_run_009\n",
      "  embeddings_128vocab_qweninit_run_010\n",
      "  embeddings_128vocab_qweninit_run_011\n",
      "  embeddings_128vocab_qweninit_run_012\n",
      "  embeddings_128vocab_qweninit_run_013\n",
      "  embeddings_128vocab_qweninit_run_014\n",
      "  embeddings_128vocab_qweninit_run_015\n",
      "  embeddings_128vocab_qweninit_run_016\n",
      "\n",
      "✓ Found all 16 runs\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(DATA_DIR)\n",
    "run_dirs = sorted(data_dir.glob(RUN_PATTERN))\n",
    "\n",
    "print(f\"Found {len(run_dirs)} runs:\")\n",
    "for run_dir in run_dirs:\n",
    "    print(f\"  {run_dir.name}\")\n",
    "\n",
    "if len(run_dirs) != EXPECTED_RUNS:\n",
    "    print(f\"\\n⚠ WARNING: Expected {EXPECTED_RUNS} runs, found {len(run_dirs)}\")\n",
    "else:\n",
    "    print(f\"\\n✓ Found all {EXPECTED_RUNS} runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Each Run\n",
    "\n",
    "For each run:\n",
    "1. Load embedding history\n",
    "2. Compute Chebyshev distance matrices (GPU-accelerated)\n",
    "3. Save to run directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing runs...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0f4df31e5654ce89f304887c438df3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Runs:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c17c72db6ef4119bac409fa35cb4365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  001:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  001: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5fa8987fa644a258527c7b7b8cb2b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  002:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  002: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd8d13ef61347869e35a246fa09a366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  003:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  003: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e59752515342308499f7a815e61b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  004:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  004: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e41fb3edc0bd4f11a186729025c9174a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  005:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  005: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0793457fe4a046aebb712c9d7d1202b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  006:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  006: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6a753abcfb4d589b3f515d9f40127b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  007:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  007: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3886af0ae874f489b0abbc0abe34dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  008:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  008: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa8e5902440c46f88bb750ba0c65c63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  009:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  009: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a99818bebf469fa1b07e8afe9f82d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  010:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  010: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c5278248cc6490ea00aac3454382c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  011:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  011: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7586a830a44fc2a8ff69700dc3481e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  012:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  012: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c910aba843341a689f2a3e8cf18106b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  013:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  013: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afc3aabda6614d6491f1a85a741fbedf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  014:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  014: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96ba0b96e8654b3b84e7f951ebe9221f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  015:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  015: saved 655.4 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df3fb68bf554a64959531593a66be36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  016:   0%|          | 0/10001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  016: saved 655.4 MB\n",
      "\n",
      "✓ All runs processed\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nProcessing runs...\\n\")\n",
    "\n",
    "for run_dir in tqdm(run_dirs, desc=\"Runs\"):\n",
    "    run_name = run_dir.name.split('_')[-1]\n",
    "    embedding_path = run_dir / EMBEDDING_FILE\n",
    "    output_path = run_dir / OUTPUT_FILE\n",
    "    \n",
    "    # Skip if already computed\n",
    "    if output_path.exists():\n",
    "        print(f\"  {run_name}: already exists, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Load embedding history\n",
    "    data = load_file(embedding_path)\n",
    "    embedding_history = data[EMBEDDING_KEY]\n",
    "    n_snapshots, vocab_size, hidden_dim = embedding_history.shape\n",
    "    \n",
    "    # Validate dimensions\n",
    "    if (n_snapshots, vocab_size, hidden_dim) != (EXPECTED_STEPS, VOCAB_SIZE, HIDDEN_DIM):\n",
    "        print(f\"  {run_name}: unexpected shape {embedding_history.shape}, skipping\")\n",
    "        continue\n",
    "    \n",
    "    # Allocate distance matrix\n",
    "    chebyshev_distances = torch.zeros((n_snapshots, vocab_size, vocab_size), dtype=torch.float32)\n",
    "    \n",
    "    # Move to GPU and compute distances\n",
    "    embedding_history_gpu = embedding_history.float().to(device)\n",
    "    \n",
    "    for i in tqdm(range(n_snapshots), desc=f\"  {run_name}\", leave=False):\n",
    "        gamma = embedding_history_gpu[i]  # (128, 64) on GPU\n",
    "        \n",
    "        # Compute pairwise differences using broadcasting\n",
    "        # gamma.unsqueeze(0): (1, 128, 64)\n",
    "        # gamma.unsqueeze(1): (128, 1, 64)\n",
    "        # diff: (128, 128, 64)\n",
    "        diff = gamma.unsqueeze(0) - gamma.unsqueeze(1)\n",
    "        \n",
    "        # Chebyshev distance: max absolute difference across dimensions\n",
    "        # chebyshev: (128, 128)\n",
    "        chebyshev = torch.abs(diff).max(dim=2)[0]\n",
    "        \n",
    "        # Move to CPU and store\n",
    "        chebyshev_distances[i] = chebyshev.cpu()\n",
    "    \n",
    "    # Free GPU memory\n",
    "    del embedding_history_gpu\n",
    "    if device.type == \"cuda\":\n",
    "        torch.cuda.empty_cache()\n",
    "    elif device.type == \"mps\":\n",
    "        torch.mps.empty_cache()\n",
    "    \n",
    "    # Save\n",
    "    save_file({'chebyshev_distances': chebyshev_distances}, output_path)\n",
    "    \n",
    "    file_size_mb = output_path.stat().st_size / 1e6\n",
    "    print(f\"  {run_name}: saved {file_size_mb:.1f} MB\")\n",
    "\n",
    "print(f\"\\n✓ All runs processed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY\n",
      "================================================================================\n",
      "\n",
      "  001: 655.4 MB\n",
      "  002: 655.4 MB\n",
      "  003: 655.4 MB\n",
      "  004: 655.4 MB\n",
      "  005: 655.4 MB\n",
      "  006: 655.4 MB\n",
      "  007: 655.4 MB\n",
      "  008: 655.4 MB\n",
      "  009: 655.4 MB\n",
      "  010: 655.4 MB\n",
      "  011: 655.4 MB\n",
      "  012: 655.4 MB\n",
      "  013: 655.4 MB\n",
      "  014: 655.4 MB\n",
      "  015: 655.4 MB\n",
      "  016: 655.4 MB\n",
      "\n",
      "Total storage: 10.49 GB\n",
      "\n",
      "Each file contains:\n",
      "  chebyshev_distances: (10001, 128, 128) float32\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Check what we created\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SUMMARY\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "total_size = 0\n",
    "for run_dir in sorted(run_dirs):\n",
    "    output_path = run_dir / OUTPUT_FILE\n",
    "    if output_path.exists():\n",
    "        size_mb = output_path.stat().st_size / 1e6\n",
    "        total_size += size_mb\n",
    "        run_name = run_dir.name.split('_')[-1]\n",
    "        print(f\"  {run_name}: {size_mb:.1f} MB\")\n",
    "\n",
    "print(f\"\\nTotal storage: {total_size / 1e3:.2f} GB\")\n",
    "print(f\"\\nEach file contains:\")\n",
    "print(f\"  chebyshev_distances: (10001, 128, 128) float32\")\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
