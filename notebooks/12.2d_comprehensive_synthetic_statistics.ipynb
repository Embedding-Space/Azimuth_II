{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 12.2d: Comprehensive Synthetic Statistics\n",
    "\n",
    "**Goal:** Stream through all 10,000 synthetic snowball trials and collect EVERY statistic we care about. Save to One CSV To Rule Them All.\n",
    "\n",
    "## What We Compute (Per Trial)\n",
    "\n",
    "### Basic Counts\n",
    "- `n_tokens` - Total tokens (should always be 2,100)\n",
    "- `n_unique` - Number of unique vectors\n",
    "- `n_black_holes` - Vectors with count ≥ 2\n",
    "- `n_singletons` - Vectors with count = 1\n",
    "- `total_population` - Sum of all counts (= n_tokens)\n",
    "- `black_hole_population` - Sum of counts where count ≥ 2\n",
    "\n",
    "### Per-Black-Hole Statistics\n",
    "- `largest_bh` - Max population among black holes\n",
    "- `smallest_bh` - Min population among black holes\n",
    "- `mean_bh_size` - Mean population per black hole\n",
    "- `median_bh_size` - Median population per black hole\n",
    "- `top2_population` - Sum of two largest black holes (concentration metric)\n",
    "- `gini_coefficient` - Inequality measure of population distribution\n",
    "\n",
    "### Spatial Extent (L∞ Distances)\n",
    "- `max_l_inf` - Maximum pairwise Chebyshev distance (in units of ε)\n",
    "- `mean_l_inf` - Mean pairwise Chebyshev distance\n",
    "- `median_l_inf` - Median pairwise Chebyshev distance\n",
    "\n",
    "### Topology (Graph Structure)\n",
    "- `n_components` - Number of connected components in adjacency graph\n",
    "- `n_isolated` - Number of nodes with degree = 0\n",
    "- `largest_component_size` - Size of largest connected component\n",
    "- `largest_component_density` - Edge density of largest component (0-1)\n",
    "- `global_density` - Edge density of full graph (0-1)\n",
    "\n",
    "## Approach\n",
    "\n",
    "- Stream HDF5 in 100-trial batches (~2 GB RAM per batch)\n",
    "- For each trial: run `torch.unique()` to get vectors + counts\n",
    "- Compute all statistics using vectorized operations where possible\n",
    "- Use NetworkX only for graph topology (unavoidable, but fast for ~12 nodes)\n",
    "- Save results to CSV: one row per trial, 20+ columns\n",
    "\n",
    "## Output\n",
    "\n",
    "`../data/analysis/synthetic_comprehensive_n10000.csv`\n",
    "\n",
    "**Runtime:** ~2-3 minutes (bottleneck: torch.unique() runs on CPU)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
