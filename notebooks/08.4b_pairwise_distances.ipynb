{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 08.4b: Pairwise Distance Matrices\n",
    "\n",
    "**Compute pairwise distance matrices across all training snapshots**\n",
    "\n",
    "With only 128 tokens, pairwise distances are computationally cheap. We compute distance matrices for all 5,001 snapshots and save them for reuse in multiple analysis notebooks.\n",
    "\n",
    "## Distance Metrics\n",
    "\n",
    "For each snapshot, we compute two distance metrics:\n",
    "\n",
    "1. **Euclidean (L2)**: Standard geometric distance\n",
    "   $$d_2(u, v) = \\sqrt{\\sum_i (u_i - v_i)^2}$$\n",
    "\n",
    "2. **Chebyshev (L∞)**: Maximum absolute difference across dimensions\n",
    "   $$d_\\infty(u, v) = \\max_i |u_i - v_i|$$\n",
    "\n",
    "Chebyshev is particularly useful for detecting quantization neighbors—tokens that differ by less than the bfloat16 quantization threshold in every dimension are distinguishable in Chebyshev space.\n",
    "\n",
    "## Output\n",
    "\n",
    "Saves two tensors:\n",
    "- `euclidean_distances`: (5001, 128, 128) float16\n",
    "- `chebyshev_distances`: (5001, 128, 128) float16\n",
    "\n",
    "Total storage: ~328 MB\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: consolidated embedding history tensor\n",
    "EMBEDDING_DIR = \"../data/embeddings_128vocab_qweninit\"  # or embeddings_128vocab_qweninit\n",
    "EMBEDDING_FILE = \"embedding_evolution.safetensors\"\n",
    "EMBEDDING_KEY = \"embedding_history\"\n",
    "\n",
    "# Output: distance matrices\n",
    "OUTPUT_FILE = \"pairwise_distances.safetensors\"\n",
    "\n",
    "# Training run parameters (for validation)\n",
    "EXPECTED_STEPS = 5001\n",
    "VOCAB_SIZE = 128\n",
    "HIDDEN_DIM = 64\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from safetensors.torch import load_file, save_file\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## Load Embedding History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding history from: ../data/embeddings_128vocab_qweninit/embedding_evolution.safetensors\n",
      "\n",
      "✓ Embedding history loaded\n",
      "Shape: torch.Size([5001, 128, 64])\n",
      "Snapshots: 5,001\n",
      "Vocabulary size: 128\n",
      "Hidden dimension: 64\n",
      "Memory footprint: 81.94 MB\n",
      "\n",
      "✓ Snapshot count matches expectation\n"
     ]
    }
   ],
   "source": [
    "embedding_dir = Path(EMBEDDING_DIR)\n",
    "embedding_path = embedding_dir / EMBEDDING_FILE\n",
    "\n",
    "print(f\"Loading embedding history from: {embedding_path}\")\n",
    "\n",
    "data = load_file(embedding_path)\n",
    "embedding_history = data[EMBEDDING_KEY]\n",
    "n_snapshots, vocab_size, hidden_dim = embedding_history.shape\n",
    "\n",
    "print(f\"\\n✓ Embedding history loaded\")\n",
    "print(f\"Shape: {embedding_history.shape}\")\n",
    "print(f\"Snapshots: {n_snapshots:,}\")\n",
    "print(f\"Vocabulary size: {vocab_size:,}\")\n",
    "print(f\"Hidden dimension: {hidden_dim:,}\")\n",
    "print(f\"Memory footprint: {embedding_history.element_size() * embedding_history.numel() / 1e6:.2f} MB\")\n",
    "\n",
    "# Validate dimensions\n",
    "if n_snapshots != EXPECTED_STEPS:\n",
    "    print(f\"\\n⚠ WARNING: Snapshot count mismatch! Expected {EXPECTED_STEPS:,}, got {n_snapshots:,}\")\n",
    "else:\n",
    "    print(f\"\\n✓ Snapshot count matches expectation\")\n",
    "\n",
    "if (vocab_size, hidden_dim) != (VOCAB_SIZE, HIDDEN_DIM):\n",
    "    raise ValueError(f\"Unexpected dimensions: expected ({VOCAB_SIZE}, {HIDDEN_DIM}), got ({vocab_size}, {hidden_dim})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## Allocate Distance Matrices\n",
    "\n",
    "Pre-allocate tensors for both distance metrics. We use float16 to save space—distance precision doesn't need float32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Allocated distance matrices:\n",
      "  Euclidean: torch.Size([5001, 128, 128]) (327.75 MB)\n",
      "  Chebyshev: torch.Size([5001, 128, 128]) (327.75 MB)\n",
      "  Total: 327.75 MB\n"
     ]
    }
   ],
   "source": [
    "# Allocate distance matrices (float16 for storage efficiency)\n",
    "euclidean_distances = torch.zeros((n_snapshots, vocab_size, vocab_size), dtype=torch.float32)\n",
    "chebyshev_distances = torch.zeros((n_snapshots, vocab_size, vocab_size), dtype=torch.float32)\n",
    "\n",
    "print(f\"Allocated distance matrices:\")\n",
    "print(f\"  Euclidean: {euclidean_distances.shape} ({euclidean_distances.element_size() * euclidean_distances.numel() / 1e6:.2f} MB)\")\n",
    "print(f\"  Chebyshev: {chebyshev_distances.shape} ({chebyshev_distances.element_size() * chebyshev_distances.numel() / 1e6:.2f} MB)\")\n",
    "print(f\"  Total: {(euclidean_distances.numel() + chebyshev_distances.numel()) * 2 / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Compute Distance Matrices\n",
    "\n",
    "For each snapshot, compute pairwise distances using PyTorch's efficient broadcasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing pairwise distances...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fba6c6cf05c4e6f93b86d1d5fd1854a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing snapshots:   0%|          | 0/5001 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Computed distance matrices for 5,001 snapshots\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nComputing pairwise distances...\\n\")\n",
    "\n",
    "for i in tqdm(range(n_snapshots), desc=\"Processing snapshots\"):\n",
    "    # Extract embedding matrix for this step\n",
    "    gamma = embedding_history[i].float()  # Convert to float32 for computation\n",
    "    \n",
    "    # Compute pairwise differences using broadcasting\n",
    "    # gamma: (vocab_size, hidden_dim)\n",
    "    # gamma.unsqueeze(0): (1, vocab_size, hidden_dim)\n",
    "    # gamma.unsqueeze(1): (vocab_size, 1, hidden_dim)\n",
    "    # diff: (vocab_size, vocab_size, hidden_dim)\n",
    "    diff = gamma.unsqueeze(0) - gamma.unsqueeze(1)\n",
    "    \n",
    "    # Euclidean distance: L2 norm across dimension axis\n",
    "    # sqrt(sum(diff^2, dim=2))\n",
    "    euclidean = torch.norm(diff, p=2, dim=2)\n",
    "    euclidean_distances[i] = euclidean\n",
    "    \n",
    "    # Chebyshev distance: max absolute difference across dimensions\n",
    "    # max(|diff|, dim=2)\n",
    "    chebyshev = torch.abs(diff).max(dim=2)[0]\n",
    "    chebyshev_distances[i] = chebyshev\n",
    "\n",
    "print(f\"\\n✓ Computed distance matrices for {n_snapshots:,} snapshots\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "DISTANCE MATRIX SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Snapshots: 5,001\n",
      "Tokens: 128\n",
      "Distance pairs per snapshot: 8,128 (excluding diagonal)\n",
      "\n",
      "Initial distances (step 0):\n",
      "  Euclidean: min=0.000000, max=0.000000, mean=0.000000\n",
      "  Chebyshev: min=0.000000, max=0.000000, mean=0.000000\n",
      "\n",
      "Final distances (step 5000):\n",
      "  Euclidean: min=0.000000, max=1.593674, mean=0.672264\n",
      "  Chebyshev: min=0.000000, max=0.597656, mean=0.204198\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"DISTANCE MATRIX SUMMARY\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Snapshots: {n_snapshots:,}\")\n",
    "print(f\"Tokens: {vocab_size:,}\")\n",
    "print(f\"Distance pairs per snapshot: {vocab_size * (vocab_size - 1) // 2:,} (excluding diagonal)\")\n",
    "\n",
    "# Analyze initial distances (step 0)\n",
    "print(f\"\\nInitial distances (step 0):\")\n",
    "# Mask out diagonal (self-distances = 0)\n",
    "mask = ~torch.eye(vocab_size, dtype=torch.bool)\n",
    "euclidean_init = euclidean_distances[0][mask].float()\n",
    "chebyshev_init = chebyshev_distances[0][mask].float()\n",
    "\n",
    "print(f\"  Euclidean: min={euclidean_init.min().item():.6f}, max={euclidean_init.max().item():.6f}, mean={euclidean_init.mean().item():.6f}\")\n",
    "print(f\"  Chebyshev: min={chebyshev_init.min().item():.6f}, max={chebyshev_init.max().item():.6f}, mean={chebyshev_init.mean().item():.6f}\")\n",
    "\n",
    "# Analyze final distances (step 5000)\n",
    "print(f\"\\nFinal distances (step {n_snapshots - 1}):\")\n",
    "euclidean_final = euclidean_distances[-1][mask].float()\n",
    "chebyshev_final = chebyshev_distances[-1][mask].float()\n",
    "\n",
    "print(f\"  Euclidean: min={euclidean_final.min().item():.6f}, max={euclidean_final.max().item():.6f}, mean={euclidean_final.mean().item():.6f}\")\n",
    "print(f\"  Chebyshev: min={chebyshev_final.min().item():.6f}, max={chebyshev_final.max().item():.6f}, mean={chebyshev_final.mean().item():.6f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Save Distance Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved distance matrices to: ../data/embeddings_128vocab_qweninit/pairwise_distances.safetensors\n",
      "\n",
      "File size: 655.49 MB\n",
      "\n",
      "Saved tensors:\n",
      "  euclidean_distances: torch.Size([5001, 128, 128]) (torch.float32)\n",
      "  chebyshev_distances: torch.Size([5001, 128, 128]) (torch.float32)\n"
     ]
    }
   ],
   "source": [
    "# Build save dictionary\n",
    "save_dict = {\n",
    "    'euclidean_distances': euclidean_distances,\n",
    "    'chebyshev_distances': chebyshev_distances,\n",
    "}\n",
    "\n",
    "# Save\n",
    "output_path = embedding_dir / OUTPUT_FILE\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "save_file(save_dict, output_path)\n",
    "\n",
    "print(f\"✓ Saved distance matrices to: {output_path}\")\n",
    "print(f\"\\nFile size: {output_path.stat().st_size / 1e6:.2f} MB\")\n",
    "print(f\"\\nSaved tensors:\")\n",
    "for key, tensor in save_dict.items():\n",
    "    print(f\"  {key}: {tensor.shape} ({tensor.dtype})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
