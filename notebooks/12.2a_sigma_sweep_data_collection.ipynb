{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12.2a: Sigma Sweep Data Collection\n",
    "\n",
    "**Goal:** Generate synthetic snowballs at Qwen-scale and measure their structure.\n",
    "\n",
    "## Experiment\n",
    "\n",
    "For σ ∈ [1×10⁻⁶, 1×10⁻⁴]:\n",
    "1. Initialize 2,100 tokens: `qwen_centroid + Gaussian(0, σ)`\n",
    "2. Quantize to bfloat16\n",
    "3. Measure black hole structure\n",
    "4. Save results to CSV\n",
    "\n",
    "No analysis, no plots—pure data collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "N_TOKENS = 2100        # Match Qwen's dead token count\n",
    "HIDDEN_DIM = 2560      # Qwen's embedding dimension\n",
    "\n",
    "# Sweep range\n",
    "SIGMA_MIN = 1.5e-9\n",
    "SIGMA_MAX = 5e-9\n",
    "N_SAMPLES = 1000\n",
    "\n",
    "# Reference scale\n",
    "EPSILON = 6e-5  # bfloat16 ULP at Qwen black hole magnitude\n",
    "\n",
    "# Output\n",
    "OUTPUT_FILE = \"../data/analysis/sigma_sweep_qwen_scale.csv\"\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from safetensors.torch import load_file\n",
    "from tqdm.auto import tqdm\n",
    "from pathlib import Path\n",
    "import gc\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Qwen Centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Qwen black hole centroid...\n",
      "\n",
      "✓ Centroid loaded\n",
      "  Shape: torch.Size([2560])\n",
      "  Norm: 0.166061\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Qwen black hole centroid...\\n\")\n",
    "\n",
    "centroid_data = load_file(\"../data/tensors/black_hole_centroid_qwen3_4b.safetensors\")\n",
    "qwen_centroid = centroid_data['centroid'].to(torch.float32)\n",
    "\n",
    "print(f\"✓ Centroid loaded\")\n",
    "print(f\"  Shape: {qwen_centroid.shape}\")\n",
    "print(f\"  Norm: {qwen_centroid.norm().item():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Measurement Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Measurement function defined\n"
     ]
    }
   ],
   "source": [
    "def measure_snowball(centroid, n_tokens, sigma):\n",
    "    \"\"\"\n",
    "    Generate synthetic snowball and measure structure.\n",
    "    \n",
    "    Returns dict with measurements.\n",
    "    \"\"\"\n",
    "    hidden_dim = len(centroid)\n",
    "    \n",
    "    # Generate embeddings\n",
    "    noise = torch.randn(n_tokens, hidden_dim, dtype=torch.float32) * sigma\n",
    "    embeddings = centroid.unsqueeze(0) + noise\n",
    "    \n",
    "    # Quantize to bfloat16\n",
    "    embeddings = embeddings.to(torch.bfloat16).to(torch.float32)\n",
    "    \n",
    "    # Find unique vectors\n",
    "    unique_vectors, inverse_indices, counts = torch.unique(\n",
    "        embeddings,\n",
    "        dim=0,\n",
    "        return_inverse=True,\n",
    "        return_counts=True\n",
    "    )\n",
    "    \n",
    "    # Black holes (count ≥ 2)\n",
    "    black_hole_mask = counts >= 2\n",
    "    n_black_holes = black_hole_mask.sum().item()\n",
    "    black_hole_population = counts[black_hole_mask].sum().item() if n_black_holes > 0 else 0\n",
    "    largest_bh = counts.max().item()\n",
    "    n_singletons = len(unique_vectors) - n_black_holes\n",
    "    \n",
    "    # Pairwise L∞ distances (only if we have multiple black holes)\n",
    "    if n_black_holes > 1:\n",
    "        black_hole_vectors = unique_vectors[black_hole_mask]\n",
    "        v1 = black_hole_vectors.unsqueeze(1)\n",
    "        v2 = black_hole_vectors.unsqueeze(0)\n",
    "        diffs = v1 - v2\n",
    "        l_inf_distances = torch.abs(diffs).max(dim=2)[0]\n",
    "        \n",
    "        mask = ~torch.eye(n_black_holes, dtype=torch.bool)\n",
    "        l_inf_nondiag = l_inf_distances[mask]\n",
    "        \n",
    "        max_l_inf = l_inf_nondiag.max().item()\n",
    "        mean_l_inf = l_inf_nondiag.mean().item()\n",
    "        median_l_inf = l_inf_nondiag.median().item()\n",
    "    else:\n",
    "        max_l_inf = 0.0\n",
    "        mean_l_inf = 0.0\n",
    "        median_l_inf = 0.0\n",
    "    \n",
    "    return {\n",
    "        'sigma': sigma,\n",
    "        'unique_vectors': len(unique_vectors),\n",
    "        'n_black_holes': n_black_holes,\n",
    "        'black_hole_population': black_hole_population,\n",
    "        'n_singletons': n_singletons,\n",
    "        'largest_bh': largest_bh,\n",
    "        'max_l_inf': max_l_inf,\n",
    "        'mean_l_inf': mean_l_inf,\n",
    "        'median_l_inf': median_l_inf,\n",
    "    }\n",
    "\n",
    "print(\"✓ Measurement function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running sigma sweep...\n",
      "  Range: σ ∈ [1.50e-09, 5.00e-09]\n",
      "  Samples: 1000\n",
      "  Tokens: 2,100\n",
      "  Dimension: 2,560\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2ce0d7521249b2946949eb4064aa86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sweeping σ:   0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Sweep complete: 1000 measurements\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nRunning sigma sweep...\")\n",
    "print(f\"  Range: σ ∈ [{SIGMA_MIN:.2e}, {SIGMA_MAX:.2e}]\")\n",
    "print(f\"  Samples: {N_SAMPLES}\")\n",
    "print(f\"  Tokens: {N_TOKENS:,}\")\n",
    "print(f\"  Dimension: {HIDDEN_DIM:,}\\n\")\n",
    "\n",
    "sigmas = np.linspace(SIGMA_MIN, SIGMA_MAX, N_SAMPLES)\n",
    "results = []\n",
    "\n",
    "for sigma in tqdm(sigmas, desc=\"Sweeping σ\"):\n",
    "    measurements = measure_snowball(qwen_centroid, N_TOKENS, sigma)\n",
    "    results.append(measurements)\n",
    "    \n",
    "    # Periodic garbage collection\n",
    "    if len(results) % 20 == 0:\n",
    "        gc.collect()\n",
    "\n",
    "print(f\"\\n✓ Sweep complete: {len(results)} measurements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Results saved to ../data/analysis/sigma_sweep_qwen_scale.csv\n",
      "  Rows: 1,000\n",
      "  Columns: ['sigma', 'unique_vectors', 'n_black_holes', 'black_hole_population', 'n_singletons', 'largest_bh', 'max_l_inf', 'mean_l_inf', 'median_l_inf', 'n_tokens', 'hidden_dim', 'epsilon', 'sigma_over_epsilon', 'max_l_inf_over_epsilon']\n",
      "  File size: 154.0 KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Add metadata columns\n",
    "df['n_tokens'] = N_TOKENS\n",
    "df['hidden_dim'] = HIDDEN_DIM\n",
    "df['epsilon'] = EPSILON\n",
    "df['sigma_over_epsilon'] = df['sigma'] / EPSILON\n",
    "df['max_l_inf_over_epsilon'] = df['max_l_inf'] / EPSILON\n",
    "\n",
    "# Save\n",
    "output_path = Path(OUTPUT_FILE)\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n✓ Results saved to {output_path}\")\n",
    "print(f\"  Rows: {len(df):,}\")\n",
    "print(f\"  Columns: {list(df.columns)}\")\n",
    "print(f\"  File size: {output_path.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "DATA COLLECTION COMPLETE\n",
      "============================================================\n",
      "Samples: 1,000\n",
      "\n",
      "Black hole count range: [12, 240]\n",
      "Max L∞ / ε range: [0.01, 0.25]\n",
      "\n",
      "Data saved: ../data/analysis/sigma_sweep_qwen_scale.csv\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DATA COLLECTION COMPLETE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Samples: {len(df):,}\")\n",
    "print(f\"\\nBlack hole count range: [{df['n_black_holes'].min()}, {df['n_black_holes'].max()}]\")\n",
    "print(f\"Max L∞ / ε range: [{df['max_l_inf_over_epsilon'].min():.2f}, {df['max_l_inf_over_epsilon'].max():.2f}]\")\n",
    "print(f\"\\nData saved: {output_path}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "esu66x3hnqg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 1000\n",
      "Samples with black holes: 1000\n",
      "\n",
      "Black hole detections:\n",
      "\n",
      "            sigma  n_black_holes  black_hole_population  max_l_inf  \\\n",
      "0    1.500000e-09             14                   2099   0.000015   \n",
      "1    1.503504e-09             14                   2098   0.000015   \n",
      "2    1.507007e-09             14                   2098   0.000015   \n",
      "3    1.510511e-09             13                   2097   0.000015   \n",
      "4    1.514014e-09             13                   2099   0.000015   \n",
      "..            ...            ...                    ...        ...   \n",
      "995  4.985986e-09            230                   1698   0.000015   \n",
      "996  4.989489e-09            222                   1703   0.000015   \n",
      "997  4.992993e-09            235                   1720   0.000015   \n",
      "998  4.996496e-09            227                   1696   0.000015   \n",
      "999  5.000000e-09            232                   1690   0.000015   \n",
      "\n",
      "     sigma_over_epsilon  max_l_inf_over_epsilon  \n",
      "0              0.000025                0.254313  \n",
      "1              0.000025                0.254313  \n",
      "2              0.000025                0.254313  \n",
      "3              0.000025                0.254313  \n",
      "4              0.000025                0.254313  \n",
      "..                  ...                     ...  \n",
      "995            0.000083                0.254313  \n",
      "996            0.000083                0.254313  \n",
      "997            0.000083                0.254313  \n",
      "998            0.000083                0.254313  \n",
      "999            0.000083                0.254313  \n",
      "\n",
      "[1000 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../data/analysis/sigma_sweep_qwen_scale.csv')\n",
    "\n",
    "# Show rows where we got black holes\n",
    "black_hole_rows = df[df['n_black_holes'] > 0]\n",
    "\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Samples with black holes: {len(black_hole_rows)}\")\n",
    "print(f\"\\nBlack hole detections:\\n\")\n",
    "print(black_hole_rows[['sigma', 'n_black_holes', 'black_hole_population', 'max_l_inf', 'sigma_over_epsilon', 'max_l_inf_over_epsilon']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
