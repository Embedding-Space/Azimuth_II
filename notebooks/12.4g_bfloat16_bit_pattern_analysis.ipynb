{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 12.4g: bfloat16 Bit Pattern Analysis\n",
    "\n",
    "**Goal:** Analyze the raw bfloat16 bit patterns of Qwen's 13 black holes to understand how they actually differ.\n",
    "\n",
    "## The Question\n",
    "\n",
    "We've been doing float32 math on bfloat16 data, which obscures the actual bit-level structure.\n",
    "\n",
    "By looking at the **raw 16-bit representations**, we can see:\n",
    "1. Which dimensions are **identical** across all 13 black holes (same bit pattern)\n",
    "2. Which dimensions **vary**, and by how much (bit-level differences)\n",
    "3. Whether the differences are single-bit flips (1 ULP changes) or more complex\n",
    "\n",
    "## bfloat16 Format\n",
    "\n",
    "Each bfloat16 value is 16 bits:\n",
    "```\n",
    "[sign: 1 bit][exponent: 8 bits][mantissa: 7 bits]\n",
    "```\n",
    "\n",
    "A difference of \"1 ULP\" means the mantissa differs by 1 in the least significant bit.\n",
    "\n",
    "## Method\n",
    "\n",
    "1. Load dead tokens in **bfloat16** (no float32 conversion!)\n",
    "2. Find the 13 unique black hole vectors\n",
    "3. Reinterpret as `int16` to get raw bit patterns\n",
    "4. For each dimension, analyze the unique bit patterns\n",
    "5. Show which dimensions are constant vs varying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths\n",
    "GAMMA_PATH = \"../data/tensors/gamma_qwen3_4b_instruct_2507.safetensors\"\n",
    "MASK_PATH = \"../data/tensors/black_hole_mask.safetensors\"\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from safetensors.torch import load_file\n",
    "from collections import Counter\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Load Data (Keep as bfloat16!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data (keeping bfloat16 precision)...\n",
      "\n",
      "✓ Loaded γ\n",
      "  Shape: torch.Size([151936, 2560])\n",
      "  Dtype: torch.float32\n",
      "  Converting from torch.float32 to bfloat16...\n",
      "\n",
      "✓ Loaded black hole mask\n",
      "  Dead tokens: 2,100\n",
      "\n",
      "✓ Extracted dead token embeddings\n",
      "  Shape: torch.Size([2100, 2560])\n",
      "  Dtype: torch.bfloat16\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading data (keeping bfloat16 precision)...\\n\")\n",
    "\n",
    "# Load gamma - check its dtype\n",
    "gamma_data = load_file(GAMMA_PATH)\n",
    "gamma_raw = gamma_data['gamma']\n",
    "print(f\"✓ Loaded γ\")\n",
    "print(f\"  Shape: {gamma_raw.shape}\")\n",
    "print(f\"  Dtype: {gamma_raw.dtype}\")\n",
    "\n",
    "# Convert to bfloat16 if needed\n",
    "if gamma_raw.dtype != torch.bfloat16:\n",
    "    print(f\"  Converting from {gamma_raw.dtype} to bfloat16...\")\n",
    "    gamma = gamma_raw.to(torch.bfloat16)\n",
    "else:\n",
    "    gamma = gamma_raw\n",
    "\n",
    "# Load black hole mask\n",
    "mask_data = load_file(MASK_PATH)\n",
    "mask = mask_data['mask']\n",
    "print(f\"\\n✓ Loaded black hole mask\")\n",
    "print(f\"  Dead tokens: {mask.sum().item():,}\")\n",
    "\n",
    "# Extract dead token embeddings (KEEP AS BFLOAT16)\n",
    "dead_tokens = gamma[mask]\n",
    "print(f\"\\n✓ Extracted dead token embeddings\")\n",
    "print(f\"  Shape: {dead_tokens.shape}\")\n",
    "print(f\"  Dtype: {dead_tokens.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## Find Unique Vectors (in bfloat16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finding unique vectors (staying in bfloat16)...\n",
      "\n",
      "✓ Found 13 unique vectors\n",
      "  Dtype: torch.bfloat16\n",
      "\n",
      "Populations: [814, 704, 306, 228, 11, 10, 6, 5, 4, 4, 3, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinding unique vectors (staying in bfloat16)...\\n\")\n",
    "\n",
    "unique_vectors, inverse_indices, counts = torch.unique(\n",
    "    dead_tokens,\n",
    "    dim=0,\n",
    "    return_inverse=True,\n",
    "    return_counts=True\n",
    ")\n",
    "\n",
    "print(f\"✓ Found {len(unique_vectors)} unique vectors\")\n",
    "print(f\"  Dtype: {unique_vectors.dtype}\")\n",
    "print(f\"\\nPopulations: {sorted(counts.tolist(), reverse=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## Convert to Raw 16-bit Integer Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Converting to raw 16-bit integer representation...\n",
      "\n",
      "✓ Converted to int16 view\n",
      "  Shape: torch.Size([13, 2560])\n",
      "  Dtype: torch.int16\n",
      "\n",
      "Example - First vector, first 5 dimensions:\n",
      "  Dim 0: +6.072998e-03 = 0x3bc7 = 0b0011101111000111\n",
      "  Dim 1: +1.324463e-02 = 0x3c59 = 0b0011110001011001\n",
      "  Dim 2: +1.177979e-02 = 0x3c41 = 0b0011110001000001\n",
      "  Dim 3: +3.662109e-02 = 0x3d16 = 0b0011110100010110\n",
      "  Dim 4: +1.586914e-02 = 0x3c82 = 0b0011110010000010\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nConverting to raw 16-bit integer representation...\\n\")\n",
    "\n",
    "# Reinterpret bfloat16 bytes as int16\n",
    "# Note: We use uint16 (unsigned) to avoid sign issues when doing bit operations\n",
    "unique_as_bits = unique_vectors.view(torch.int16)\n",
    "\n",
    "print(f\"✓ Converted to int16 view\")\n",
    "print(f\"  Shape: {unique_as_bits.shape}\")\n",
    "print(f\"  Dtype: {unique_as_bits.dtype}\")\n",
    "\n",
    "# Example: show first vector's first few components in different formats\n",
    "print(f\"\\nExample - First vector, first 5 dimensions:\")\n",
    "for i in range(5):\n",
    "    bf16_val = unique_vectors[0, i].item()\n",
    "    bits_val = unique_as_bits[0, i].item()\n",
    "    # Convert to unsigned for binary display\n",
    "    unsigned_bits = bits_val if bits_val >= 0 else bits_val + 65536\n",
    "    binary = format(unsigned_bits, '016b')\n",
    "    hex_val = format(unsigned_bits, '04x')\n",
    "    \n",
    "    print(f\"  Dim {i}: {bf16_val:+.6e} = 0x{hex_val} = 0b{binary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## Analyze Per-Dimension Bit Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing per-dimension bit patterns...\n",
      "\n",
      "Dimension classification:\n",
      "  Constant dimensions: 2540 (99.2%)\n",
      "  Varying dimensions: 20 (0.8%)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAnalyzing per-dimension bit patterns...\\n\")\n",
    "\n",
    "n_unique, n_dims = unique_as_bits.shape\n",
    "\n",
    "# For each dimension, count unique bit patterns\n",
    "constant_dims = []\n",
    "varying_dims = []\n",
    "\n",
    "for dim in range(n_dims):\n",
    "    values_in_dim = unique_as_bits[:, dim]  # [13] int16 values\n",
    "    unique_bit_patterns = torch.unique(values_in_dim)\n",
    "    \n",
    "    if len(unique_bit_patterns) == 1:\n",
    "        # All 13 vectors have the same value in this dimension\n",
    "        constant_dims.append(dim)\n",
    "    else:\n",
    "        # This dimension varies\n",
    "        varying_dims.append({\n",
    "            'dim': dim,\n",
    "            'n_unique_patterns': len(unique_bit_patterns),\n",
    "            'patterns': unique_bit_patterns.tolist(),\n",
    "        })\n",
    "\n",
    "print(f\"Dimension classification:\")\n",
    "print(f\"  Constant dimensions: {len(constant_dims)} ({len(constant_dims)/n_dims*100:.1f}%)\")\n",
    "print(f\"  Varying dimensions: {len(varying_dims)} ({len(varying_dims)/n_dims*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## Analyze Varying Dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed analysis of varying dimensions:\n",
      "================================================================================\n",
      "\n",
      "Distribution of unique patterns per dimension:\n",
      "  2 unique patterns: 17 dimensions\n",
      "  3 unique patterns: 2 dimensions\n",
      "  7 unique patterns: 1 dimensions\n",
      "\n",
      "First 20 varying dimensions (detailed):\n",
      "   Dim   N patterns                       Bit patterns (hex)\n",
      "--------------------------------------------------------------------------------\n",
      "   216            2                           0xbadf, 0xbae0\n",
      "   282            2                           0xbb68, 0xbb69\n",
      "   322            2                           0x3b5f, 0x3b61\n",
      "   450            2                           0xb954, 0xb955\n",
      "   993            2                           0xb9a4, 0xb9a5\n",
      "  1008            3                   0xb5e7, 0xb5e8, 0xb5ec\n",
      "  1149            2                           0x3802, 0x3803\n",
      "  1155            2                           0xba5d, 0xba5e\n",
      "  1272            2                           0xb90a, 0xb90b\n",
      "  1382            7 0xb595, 0xb596, 0xb597, 0xb598, 0xb59...\n",
      "  1403            2                           0xbc0a, 0xbc0b\n",
      "  1435            3                   0xb66e, 0xb66f, 0xb670\n",
      "  1487            2                           0x3965, 0x396d\n",
      "  1564            2                           0xbb1b, 0xbb1c\n",
      "  1763            2                           0x397d, 0x397e\n",
      "  2012            2                           0xba68, 0xba69\n",
      "  2040            2                           0x38ac, 0x38ad\n",
      "  2079            2                           0x3870, 0x3871\n",
      "  2143            2                           0xbb95, 0xbb96\n",
      "  2479            2                           0x3ae2, 0x3ae3\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nDetailed analysis of varying dimensions:\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Count how many dimensions have 2 patterns, 3 patterns, etc.\n",
    "pattern_count_distribution = Counter([d['n_unique_patterns'] for d in varying_dims])\n",
    "\n",
    "print(f\"Distribution of unique patterns per dimension:\")\n",
    "for n_patterns in sorted(pattern_count_distribution.keys()):\n",
    "    count = pattern_count_distribution[n_patterns]\n",
    "    print(f\"  {n_patterns} unique patterns: {count} dimensions\")\n",
    "\n",
    "print(f\"\\nFirst 20 varying dimensions (detailed):\")\n",
    "print(f\"{'Dim':>6} {'N patterns':>12} {'Bit patterns (hex)':>40}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for i, info in enumerate(varying_dims[:20]):\n",
    "    dim = info['dim']\n",
    "    n_patterns = info['n_unique_patterns']\n",
    "    patterns = info['patterns']\n",
    "    \n",
    "    # Convert to unsigned hex for display\n",
    "    hex_patterns = []\n",
    "    for p in patterns:\n",
    "        unsigned = p if p >= 0 else p + 65536\n",
    "        hex_patterns.append(f\"0x{unsigned:04x}\")\n",
    "    \n",
    "    patterns_str = ', '.join(hex_patterns)\n",
    "    if len(patterns_str) > 40:\n",
    "        patterns_str = patterns_str[:37] + '...'\n",
    "    \n",
    "    print(f\"{dim:>6} {n_patterns:>12} {patterns_str:>40}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## Compute Hamming Distances Between Black Holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing Hamming distances (bit-level differences)...\n",
      "\n",
      "Hamming distance statistics (dimensions that differ):\n",
      "  Min: 1\n",
      "  Max: 14\n",
      "  Mean: 6.8\n",
      "  Median: 6\n",
      "\n",
      "Hamming distance matrix:\n",
      "(Number of dimensions where bit patterns differ)\n",
      "\n",
      "[[ 0  9  7  3  6  5  6  6  7 10  9  7  7]\n",
      " [ 9  0 11  9 12 12 13 12 13 14 13 14 11]\n",
      " [ 7 11  0  5  8  8  9  8  9 12 11 10  9]\n",
      " [ 3  9  5  0  6  6  7  6  4  7  6  8  5]\n",
      " [ 6 12  8  6  0  1  2  2  6  7  6  3  6]\n",
      " [ 5 12  8  6  1  0  1  2  6  7  6  2  6]\n",
      " [ 6 13  9  7  2  1  0  3  5  6  5  1  5]\n",
      " [ 6 12  8  6  2  2  3  0  7  8  7  4  6]\n",
      " [ 7 13  9  4  6  6  5  7  0  4  4  6  5]\n",
      " [10 14 12  7  7  7  6  8  4  0  1  7  6]\n",
      " [ 9 13 11  6  6  6  5  7  4  1  0  6  5]\n",
      " [ 7 14 10  8  3  2  1  4  6  7  6  0  4]\n",
      " [ 7 11  9  5  6  6  5  6  5  6  5  4  0]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nComputing Hamming distances (bit-level differences)...\\n\")\n",
    "\n",
    "# For each pair of vectors, count how many dimensions differ\n",
    "hamming_matrix = torch.zeros(n_unique, n_unique, dtype=torch.int32)\n",
    "\n",
    "for i in range(n_unique):\n",
    "    for j in range(i+1, n_unique):\n",
    "        # Count dimensions where bit patterns differ\n",
    "        diff_mask = unique_as_bits[i] != unique_as_bits[j]\n",
    "        hamming_dist = diff_mask.sum().item()\n",
    "        hamming_matrix[i, j] = hamming_dist\n",
    "        hamming_matrix[j, i] = hamming_dist\n",
    "\n",
    "print(f\"Hamming distance statistics (dimensions that differ):\")\n",
    "# Exclude diagonal\n",
    "non_diag = hamming_matrix[hamming_matrix > 0]\n",
    "print(f\"  Min: {non_diag.min().item()}\")\n",
    "print(f\"  Max: {non_diag.max().item()}\")\n",
    "print(f\"  Mean: {non_diag.float().mean().item():.1f}\")\n",
    "print(f\"  Median: {non_diag.float().median().item():.0f}\")\n",
    "\n",
    "# Show the matrix\n",
    "print(f\"\\nHamming distance matrix:\")\n",
    "print(f\"(Number of dimensions where bit patterns differ)\\n\")\n",
    "print(hamming_matrix.cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## Deep Dive: Pick One Varying Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Deep dive into dimension 216:\n",
      "================================================================================\n",
      "\n",
      "All 13 black holes' values in this dimension:\n",
      "  BH   Population     bfloat16 value      Hex             Binary\n",
      "--------------------------------------------------------------------------------\n",
      "   0           10  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "   1            4  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "   2            5  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "   3          306  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "   4            4  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "   5          814  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "   6          228  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "   7            3  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "   8            3  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "   9            2  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "  10          704  -1.7089843750e-03 0xbae0 0b1011101011100000\n",
      "  11           11  -1.7013549805e-03 0xbadf 0b1011101011011111\n",
      "  12            6  -1.7013549805e-03 0xbadf 0b1011101011011111\n",
      "\n",
      "Bit-level differences:\n",
      "  Two unique values: 0xbadf and 0xbae0\n",
      "  XOR: 0b0000000000111111\n",
      "  Number of bits that differ: 6\n"
     ]
    }
   ],
   "source": [
    "if len(varying_dims) > 0:\n",
    "    # Pick the first varying dimension\n",
    "    example_dim_info = varying_dims[0]\n",
    "    example_dim = example_dim_info['dim']\n",
    "    \n",
    "    print(f\"\\nDeep dive into dimension {example_dim}:\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    print(f\"All 13 black holes' values in this dimension:\")\n",
    "    print(f\"{'BH':>4} {'Population':>12} {'bfloat16 value':>18} {'Hex':>8} {'Binary':>18}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for bh_idx in range(n_unique):\n",
    "        pop = counts[bh_idx].item()\n",
    "        bf16_val = unique_vectors[bh_idx, example_dim].item()\n",
    "        bits_val = unique_as_bits[bh_idx, example_dim].item()\n",
    "        unsigned_bits = bits_val if bits_val >= 0 else bits_val + 65536\n",
    "        hex_val = format(unsigned_bits, '04x')\n",
    "        binary = format(unsigned_bits, '016b')\n",
    "        \n",
    "        print(f\"{bh_idx:>4} {pop:>12} {bf16_val:>+18.10e} 0x{hex_val} 0b{binary}\")\n",
    "    \n",
    "    # Analyze bit differences\n",
    "    print(f\"\\nBit-level differences:\")\n",
    "    all_vals = unique_as_bits[:, example_dim]\n",
    "    unique_vals = torch.unique(all_vals)\n",
    "    \n",
    "    if len(unique_vals) == 2:\n",
    "        v1 = unique_vals[0].item()\n",
    "        v2 = unique_vals[1].item()\n",
    "        u1 = v1 if v1 >= 0 else v1 + 65536\n",
    "        u2 = v2 if v2 >= 0 else v2 + 65536\n",
    "        \n",
    "        xor = u1 ^ u2\n",
    "        n_bits_diff = bin(xor).count('1')\n",
    "        \n",
    "        print(f\"  Two unique values: 0x{u1:04x} and 0x{u2:04x}\")\n",
    "        print(f\"  XOR: 0b{xor:016b}\")\n",
    "        print(f\"  Number of bits that differ: {n_bits_diff}\")\n",
    "        \n",
    "        if n_bits_diff == 1:\n",
    "            print(f\"  → Single-bit flip (1 ULP difference in mantissa)\")\n",
    "else:\n",
    "    print(f\"\\nNo varying dimensions found (all vectors identical?!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BIT PATTERN ANALYSIS SUMMARY\n",
      "================================================================================\n",
      "\n",
      "13 unique black hole vectors in bfloat16\n",
      "2560 dimensions total\n",
      "\n",
      "Dimension classification:\n",
      "  Constant: 2540 dimensions (99.2%)\n",
      "  Varying:  20 dimensions (0.8%)\n",
      "\n",
      "Pattern distribution in varying dimensions:\n",
      "  17 dims have 2 unique bit patterns\n",
      "  2 dims have 3 unique bit patterns\n",
      "  1 dims have 7 unique bit patterns\n",
      "\n",
      "Hamming distances (dimensions with different bits):\n",
      "  Range: 1 to 14\n",
      "  Mean: 6.8 dimensions differ per pair\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"BIT PATTERN ANALYSIS SUMMARY\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n{n_unique} unique black hole vectors in bfloat16\")\n",
    "print(f\"{n_dims} dimensions total\\n\")\n",
    "\n",
    "print(f\"Dimension classification:\")\n",
    "print(f\"  Constant: {len(constant_dims)} dimensions ({len(constant_dims)/n_dims*100:.1f}%)\")\n",
    "print(f\"  Varying:  {len(varying_dims)} dimensions ({len(varying_dims)/n_dims*100:.1f}%)\")\n",
    "\n",
    "if len(varying_dims) > 0:\n",
    "    print(f\"\\nPattern distribution in varying dimensions:\")\n",
    "    for n_patterns in sorted(pattern_count_distribution.keys()):\n",
    "        count = pattern_count_distribution[n_patterns]\n",
    "        print(f\"  {count} dims have {n_patterns} unique bit patterns\")\n",
    "\n",
    "print(f\"\\nHamming distances (dimensions with different bits):\")\n",
    "print(f\"  Range: {non_diag.min().item()} to {non_diag.max().item()}\")\n",
    "print(f\"  Mean: {non_diag.float().mean().item():.1f} dimensions differ per pair\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
