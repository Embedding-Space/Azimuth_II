{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15.2c: Bulk Experiment Analysis\n",
    "\n",
    "**Statistical comparison of f32→bf16 vs pure bf16 initialization across 64 runs**\n",
    "\n",
    "## Experiments\n",
    "\n",
    "- **Test 001**: 16 matched pairs, seeds 1601-1616\n",
    "- **Test 002**: 16 matched pairs, seeds 1601-1616\n",
    "- **Total**: 32 f32→bf16 runs + 32 pure bf16 runs = 64 runs\n",
    "\n",
    "## Research Question\n",
    "\n",
    "Is f32→bf16 conversion a **necessary precondition** for the black hole demographics we observe in Qwen?\n",
    "\n",
    "**Hypothesis:** Pure bf16 initialization collapses to singularity, while f32→bf16 maintains distributed structure.\n",
    "\n",
    "## Visualization\n",
    "\n",
    "Plot black hole count over time:\n",
    "- Min/max/mean for f32→bf16 (32 runs)\n",
    "- Min/max/mean for pure bf16 (32 runs)\n",
    "- Shaded ribbons show variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment directories\n",
    "TEST_IDS = [1, 2]\n",
    "DATA_DIR = \"../data\"\n",
    "\n",
    "# Plot settings\n",
    "DPI = 100\n",
    "\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from safetensors.torch import load_file\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load All Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_experiment_runs(test_id):\n",
    "    \"\"\"Load all runs from a test ID.\"\"\"\n",
    "    exp_dir = Path(DATA_DIR) / f\"experiment_test{test_id:03d}\"\n",
    "    \n",
    "    f32_files = sorted(exp_dir.glob(\"test*_f32_seed*.safetensors\"))\n",
    "    bf16_files = sorted(exp_dir.glob(\"test*_bf16_seed*.safetensors\"))\n",
    "    \n",
    "    f32_runs = [load_file(f) for f in f32_files]\n",
    "    bf16_runs = [load_file(f) for f in bf16_files]\n",
    "    \n",
    "    return f32_runs, bf16_runs\n",
    "\n",
    "print(f\"Loading experiments {TEST_IDS}...\")\n",
    "\n",
    "all_f32_runs = []\n",
    "all_bf16_runs = []\n",
    "\n",
    "for test_id in TEST_IDS:\n",
    "    f32, bf16 = load_experiment_runs(test_id)\n",
    "    all_f32_runs.extend(f32)\n",
    "    all_bf16_runs.extend(bf16)\n",
    "    print(f\"  Test {test_id:03d}: {len(f32)} f32 runs, {len(bf16)} bf16 runs\")\n",
    "\n",
    "print(f\"\\n✓ Loaded {len(all_f32_runs)} f32 runs, {len(all_bf16_runs)} bf16 runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Black Hole Trajectories\n",
    "\n",
    "For each run, count black holes (unique vectors among dead tokens) at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_black_hole_trajectory(run_data):\n",
    "    \"\"\"\n",
    "    Count unique vectors among dead tokens at each step.\n",
    "    \n",
    "    Returns:\n",
    "        trajectory: [n_steps] array of unique vector counts\n",
    "    \"\"\"\n",
    "    embeddings = run_data['embeddings']  # [steps+1, vocab_size, hidden_dim]\n",
    "    dead_ids = run_data['dead_token_ids']\n",
    "    \n",
    "    n_steps = embeddings.shape[0]\n",
    "    trajectory = np.zeros(n_steps, dtype=int)\n",
    "    \n",
    "    for step in range(n_steps):\n",
    "        dead_embeddings = embeddings[step, dead_ids, :]\n",
    "        unique_vecs = torch.unique(dead_embeddings, dim=0)\n",
    "        trajectory[step] = len(unique_vecs)\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "print(\"Computing f32→bf16 trajectories...\")\n",
    "f32_trajectories = []\n",
    "for run in tqdm(all_f32_runs):\n",
    "    f32_trajectories.append(compute_black_hole_trajectory(run))\n",
    "\n",
    "print(\"\\nComputing pure bf16 trajectories...\")\n",
    "bf16_trajectories = []\n",
    "for run in tqdm(all_bf16_runs):\n",
    "    bf16_trajectories.append(compute_black_hole_trajectory(run))\n",
    "\n",
    "# Convert to numpy arrays\n",
    "f32_trajectories = np.array(f32_trajectories)  # [n_runs, n_steps]\n",
    "bf16_trajectories = np.array(bf16_trajectories)\n",
    "\n",
    "print(f\"\\n✓ Trajectories computed\")\n",
    "print(f\"  f32 shape: {f32_trajectories.shape}\")\n",
    "print(f\"  bf16 shape: {bf16_trajectories.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'='*80}\")\n",
    "print(f\"SUMMARY STATISTICS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Initial state (t=0)\n",
    "print(f\"t=0 (initial state):\")\n",
    "print(f\"  f32→bf16: {f32_trajectories[:, 0].mean():.1f} ± {f32_trajectories[:, 0].std():.1f} unique vectors\")\n",
    "print(f\"  pure bf16: {bf16_trajectories[:, 0].mean():.1f} ± {bf16_trajectories[:, 0].std():.1f} unique vectors\")\n",
    "\n",
    "# Final state (t=1000)\n",
    "print(f\"\\nt=1000 (final state):\")\n",
    "print(f\"  f32→bf16: {f32_trajectories[:, -1].mean():.1f} ± {f32_trajectories[:, -1].std():.1f} unique vectors\")\n",
    "print(f\"  pure bf16: {bf16_trajectories[:, -1].mean():.1f} ± {bf16_trajectories[:, -1].std():.1f} unique vectors\")\n",
    "\n",
    "# Change over training\n",
    "f32_change = f32_trajectories[:, -1] - f32_trajectories[:, 0]\n",
    "bf16_change = bf16_trajectories[:, -1] - bf16_trajectories[:, 0]\n",
    "\n",
    "print(f\"\\nChange (t=0 → t=1000):\")\n",
    "print(f\"  f32→bf16: {f32_change.mean():.1f} ± {f32_change.std():.1f}\")\n",
    "print(f\"  pure bf16: {bf16_change.mean():.1f} ± {bf16_change.std():.1f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Min/Max/Mean Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics\n",
    "steps = np.arange(f32_trajectories.shape[1])\n",
    "\n",
    "f32_mean = f32_trajectories.mean(axis=0)\n",
    "f32_min = f32_trajectories.min(axis=0)\n",
    "f32_max = f32_trajectories.max(axis=0)\n",
    "\n",
    "bf16_mean = bf16_trajectories.mean(axis=0)\n",
    "bf16_min = bf16_trajectories.min(axis=0)\n",
    "bf16_max = bf16_trajectories.max(axis=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 7), dpi=DPI)\n",
    "\n",
    "# f32→bf16 (blue)\n",
    "ax.plot(steps, f32_mean, color='C0', linewidth=2, label=f'f32→bf16 (n={len(all_f32_runs)})')\n",
    "ax.fill_between(steps, f32_min, f32_max, color='C0', alpha=0.2)\n",
    "\n",
    "# pure bf16 (orange)\n",
    "ax.plot(steps, bf16_mean, color='C1', linewidth=2, label=f'pure bf16 (n={len(all_bf16_runs)})')\n",
    "ax.fill_between(steps, bf16_min, bf16_max, color='C1', alpha=0.2)\n",
    "\n",
    "ax.set_xlabel('Training Step', fontsize=12)\n",
    "ax.set_ylabel('Number of Unique Vectors (Dead Tokens)', fontsize=12)\n",
    "ax.set_title('Black Hole Evolution: F32→BF16 vs Pure BF16 Initialization', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='upper right', fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim(bottom=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Plot complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"INTERPRETATION\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Check for separation at t=1000\n",
    "f32_final_mean = f32_trajectories[:, -1].mean()\n",
    "bf16_final_mean = bf16_trajectories[:, -1].mean()\n",
    "\n",
    "f32_final_std = f32_trajectories[:, -1].std()\n",
    "bf16_final_std = bf16_trajectories[:, -1].std()\n",
    "\n",
    "separation = abs(f32_final_mean - bf16_final_mean)\n",
    "pooled_std = np.sqrt((f32_final_std**2 + bf16_final_std**2) / 2)\n",
    "cohens_d = separation / pooled_std if pooled_std > 0 else float('inf')\n",
    "\n",
    "print(f\"Final state comparison (t=1000):\")\n",
    "print(f\"  f32→bf16: {f32_final_mean:.1f} ± {f32_final_std:.1f}\")\n",
    "print(f\"  pure bf16: {bf16_final_mean:.1f} ± {bf16_final_std:.1f}\")\n",
    "print(f\"  Separation: {separation:.1f} unique vectors\")\n",
    "print(f\"  Cohen's d: {cohens_d:.2f}\")\n",
    "\n",
    "print(f\"\\nVerdict:\")\n",
    "if cohens_d > 2.0 and bf16_final_mean < 10:\n",
    "    print(f\"  HYPOTHESIS VALIDATED\")\n",
    "    print(f\"  ✓ Pure bf16 collapses to near-singularity ({bf16_final_mean:.1f} vectors)\")\n",
    "    print(f\"  ✓ F32→bf16 maintains distributed structure ({f32_final_mean:.1f} vectors)\")\n",
    "    print(f\"  ✓ Effect size is massive (Cohen's d = {cohens_d:.2f})\")\n",
    "    print(f\"\\n  **Conclusion:** F32 initialization is a NECESSARY precondition.\")\n",
    "elif cohens_d > 0.5:\n",
    "    print(f\"  HYPOTHESIS PARTIALLY SUPPORTED\")\n",
    "    print(f\"  - Distributions are different (d = {cohens_d:.2f})\")\n",
    "    print(f\"  - But both maintain some structure\")\n",
    "else:\n",
    "    print(f\"  HYPOTHESIS FALSIFIED\")\n",
    "    print(f\"  - No significant difference between f32 and bf16\")\n",
    "    print(f\"  - F32 initialization is NOT necessary\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook analyzes 64 training runs (32 f32→bf16 + 32 pure bf16) to test whether f32 initialization is a necessary precondition for the black hole demographics observed in Qwen.\n",
    "\n",
    "**Key metrics:**\n",
    "1. Black hole count trajectories (min/max/mean)\n",
    "2. Final state comparison (t=1000)\n",
    "3. Effect size (Cohen's d)\n",
    "\n",
    "**Expected result:** Pure bf16 collapses to singularity (~1-3 vectors), while f32→bf16 maintains distributed structure (~30-50 vectors)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
