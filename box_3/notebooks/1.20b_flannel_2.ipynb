{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.20b: Flannel 2 - Untied Weights Control (1,000 Steps)\n",
    "\n",
    "**Experiment:** Same as Flannel 1, but with **untied embedding weights** (E ≠ W).\n",
    "\n",
    "## Why Flannel 2?\n",
    "\n",
    "**Goal:** Isolate gradient contributions from embedding vs unembedding layers.\n",
    "\n",
    "**In Flannel 1 (tied weights):**\n",
    "- E and W are the same tensor\n",
    "- Gradient = ∂L/∂W (unembedding, affects all tokens) + ∂L/∂E (embedding, affects only input tokens)\n",
    "- Both contributions accumulate into the same parameter\n",
    "\n",
    "**In Flannel 2 (untied weights):**\n",
    "- E and W are independent tensors\n",
    "- ∂L/∂W affects W only (unembedding backscatter)\n",
    "- ∂L/∂E affects E only (embedding supervision)\n",
    "- Dead tokens in W get gradients, dead tokens in E get zero gradient\n",
    "\n",
    "## The Question We're Testing\n",
    "\n",
    "Does the \"inflationary expansion\" at step 0→1 come from:\n",
    "1. **Unembedding dynamics** (would persist in W even when untied)\n",
    "2. **Tied weight interaction** (would disappear or change when untied)\n",
    "3. **Embedding dynamics** (would show up in E but not W)\n",
    "\n",
    "**Bonus question:** Does W₁[t] ≈ W₂[t] + E₂[t]? (Linear decomposition hypothesis)\n",
    "\n",
    "## Flannel 2 Parameters\n",
    "\n",
    "**Identical to Flannel 1 except:**\n",
    "- `tie_word_embeddings=False`\n",
    "- Record both E and W matrices at every step\n",
    "- Same random seed (42) for direct comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parameters set\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "VOCAB_SIZE = 10000  # Flannel\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYER = 2\n",
    "N_HEAD = 2\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 32\n",
    "NUM_TRAIN_STEPS = 1000\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 0.0\n",
    "\n",
    "# Optimizer: Adam\n",
    "ADAM_BETA1 = 0.9\n",
    "ADAM_BETA2 = 0.999\n",
    "ADAM_EPSILON = 1e-8\n",
    "\n",
    "# Initialization (bfloat16 native)\n",
    "INIT_SCALE = 0.02  # N(0, 0.02)\n",
    "\n",
    "# Data\n",
    "TOKENIZER_PATH = \"../data/flannel_tokenizer_chars.json\"\n",
    "CORPUS_PATH = \"../data/flannel_model_corpus.txt\"\n",
    "TOKEN_MASK_PATH = \"../tensors/Flannel/live_dead_tokens.safetensors\"\n",
    "OUTPUT_DIR = \"../tensors/Flannel\"\n",
    "OUTPUT_FILE = \"1.20b_flannel_2.safetensors\"\n",
    "\n",
    "# Instrumentation\n",
    "RECORD_EVERY_N_STEPS = 1  # Record every step\n",
    "\n",
    "RANDOM_SEED = 42  # SAME AS FLANNEL 1\n",
    "\n",
    "print(\"✓ Parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from tokenizers import Tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from safetensors.torch import save_file, load_file\n",
    "import time\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Flannel tokenizer: ../data/flannel_tokenizer_chars.json\n",
      "\n",
      "✓ Loaded Flannel tokenizer\n",
      "  Vocabulary size: 10,000 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading Flannel tokenizer: {TOKENIZER_PATH}\\n\")\n",
    "\n",
    "tokenizer = Tokenizer.from_file(str(TOKENIZER_PATH))\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "print(f\"✓ Loaded Flannel tokenizer\")\n",
    "print(f\"  Vocabulary size: {len(vocab):,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading corpus: ../data/flannel_model_corpus.txt\n",
      "\n",
      "✓ Loaded corpus\n",
      "  Size: 5.01 MB\n",
      "  Characters: 5,225,690\n",
      "\n",
      "Tokenizing corpus...\n",
      "\n",
      "✓ Tokenized\n",
      "  Tokens: 1,371,328\n",
      "\n",
      "Training coverage:\n",
      "  Tokens per step: 4,096\n",
      "  Steps per epoch: 334.8\n",
      "  Expected epochs in 1,000 steps: 2.99\n",
      "\n",
      "✓ Corpus on device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoading corpus: {CORPUS_PATH}\\n\")\n",
    "\n",
    "with open(CORPUS_PATH, 'r', encoding='utf-8') as f:\n",
    "    corpus_text = f.read()\n",
    "\n",
    "corpus_bytes = len(corpus_text.encode('utf-8'))\n",
    "corpus_mb = corpus_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"✓ Loaded corpus\")\n",
    "print(f\"  Size: {corpus_mb:.2f} MB\")\n",
    "print(f\"  Characters: {len(corpus_text):,}\")\n",
    "print()\n",
    "\n",
    "# Tokenize\n",
    "print(\"Tokenizing corpus...\\n\")\n",
    "encoding = tokenizer.encode(corpus_text)\n",
    "tokens = encoding.ids\n",
    "\n",
    "print(f\"✓ Tokenized\")\n",
    "print(f\"  Tokens: {len(tokens):,}\")\n",
    "print()\n",
    "\n",
    "# Calculate expected epochs\n",
    "tokens_per_step = BATCH_SIZE * MAX_SEQ_LEN\n",
    "steps_per_epoch = len(tokens) / tokens_per_step\n",
    "expected_epochs = NUM_TRAIN_STEPS / steps_per_epoch\n",
    "\n",
    "print(f\"Training coverage:\")\n",
    "print(f\"  Tokens per step: {tokens_per_step:,}\")\n",
    "print(f\"  Steps per epoch: {steps_per_epoch:.1f}\")\n",
    "print(f\"  Expected epochs in {NUM_TRAIN_STEPS:,} steps: {expected_epochs:.2f}\")\n",
    "print()\n",
    "\n",
    "# Pre-load to device\n",
    "corpus_tensor = torch.tensor(tokens, dtype=torch.long, device=device)\n",
    "print(f\"✓ Corpus on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Token Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading token masks: ../tensors/Flannel/live_dead_tokens.safetensors\n",
      "\n",
      "✓ Loaded token masks\n",
      "  Live tokens: 6,301 (63.0%)\n",
      "  Dead tokens: 3,699 (37.0%)\n",
      "\n",
      "Live token frequency:\n",
      "  Min occurrences: 1\n",
      "  Max occurrences: 45,630\n",
      "  Mean occurrences: 217.6\n",
      "  Median occurrences: 68\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoading token masks: {TOKEN_MASK_PATH}\\n\")\n",
    "\n",
    "mask_data = load_file(TOKEN_MASK_PATH)\n",
    "live_mask = mask_data['live_mask']\n",
    "dead_mask = mask_data['dead_mask']\n",
    "live_indices = mask_data['live_indices']\n",
    "dead_indices = mask_data['dead_indices']\n",
    "token_occurrence_counts = mask_data['token_occurrence_counts']\n",
    "\n",
    "n_live = live_mask.sum().item()\n",
    "n_dead = dead_mask.sum().item()\n",
    "\n",
    "print(f\"✓ Loaded token masks\")\n",
    "print(f\"  Live tokens: {n_live:,} ({100*n_live/VOCAB_SIZE:.1f}%)\")\n",
    "print(f\"  Dead tokens: {n_dead:,} ({100*n_dead/VOCAB_SIZE:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Token frequency stats for live tokens\n",
    "live_counts = token_occurrence_counts[live_indices]\n",
    "print(f\"Live token frequency:\")\n",
    "print(f\"  Min occurrences: {live_counts.min().item():,}\")\n",
    "print(f\"  Max occurrences: {live_counts.max().item():,}\")\n",
    "print(f\"  Mean occurrences: {live_counts.float().mean().item():.1f}\")\n",
    "print(f\"  Median occurrences: {live_counts.float().median().item():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Dataset: 1,371,200 examples\n"
     ]
    }
   ],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, corpus_tensor, max_seq_len):\n",
    "        self.corpus = corpus_tensor\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(0, len(self.corpus) - self.max_seq_len)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.corpus[idx : idx + self.max_seq_len + 1]\n",
    "        return {\n",
    "            'input_ids': chunk[:-1],\n",
    "            'labels': chunk[1:]\n",
    "        }\n",
    "\n",
    "dataset = TokenDataset(corpus_tensor, MAX_SEQ_LEN)\n",
    "print(f\"\\n✓ Dataset: {len(dataset):,} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating model...\n",
      "\n",
      "✓ Model created (UNTIED WEIGHTS)\n",
      "  Total parameters: 1,388,288\n",
      "  Embedding parameters (E): 640,000\n",
      "  Unembedding parameters (W): 640,000\n",
      "  Other parameters: 108,288\n",
      "  E and W are independent tensors: True\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCreating model...\\n\")\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_positions=MAX_SEQ_LEN,\n",
    "    n_embd=HIDDEN_DIM,\n",
    "    n_layer=N_LAYER,\n",
    "    n_head=N_HEAD,\n",
    "    resid_pdrop=0.0,\n",
    "    embd_pdrop=0.0,\n",
    "    attn_pdrop=0.0,\n",
    "    tie_word_embeddings=False,  # ← KEY DIFFERENCE: UNTIED WEIGHTS\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model = model.to(torch.bfloat16).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "embedding_params = model.transformer.wte.weight.numel()\n",
    "unembedding_params = model.lm_head.weight.numel()\n",
    "\n",
    "print(f\"✓ Model created (UNTIED WEIGHTS)\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Embedding parameters (E): {embedding_params:,}\")\n",
    "print(f\"  Unembedding parameters (W): {unembedding_params:,}\")\n",
    "print(f\"  Other parameters: {total_params - embedding_params - unembedding_params:,}\")\n",
    "print(f\"  E and W are independent tensors: {model.transformer.wte.weight is not model.lm_head.weight}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization (bfloat16 Native)\n",
    "\n",
    "**Initialize E and W independently with same seed for direct comparison to Flannel 1.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INITIALIZING: N(0, 0.02) bfloat16-native (UNTIED)\n",
      "================================================================================\n",
      "\n",
      "Initialization: N(0, 0.02)\n",
      "  Shape: torch.Size([10000, 64])\n",
      "  Each token initialized independently\n",
      "\n",
      "✓ Initialized both E and W (pure bfloat16)\n",
      "  E shape: torch.Size([10000, 64])\n",
      "  W shape: torch.Size([10000, 64])\n",
      "  Dtype: torch.bfloat16\n",
      "  E == W initially: True\n",
      "\n",
      "Initial dead token statistics (3,699 tokens):\n",
      "  Centroid norm: 0.002689\n",
      "  Mean radius from centroid: 0.159301\n",
      "  Max radius from centroid: 0.206368\n",
      "  Bounding hypersphere volume ∝ R^64 = 1.37e-44\n",
      "\n",
      "  ✓ Dead tokens distributed in hypersphere (standard init)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"INITIALIZING: N(0, {INIT_SCALE}) bfloat16-native (UNTIED)\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Generate SAME initialization as Flannel 1 (same seed, same distribution)\n",
    "# But apply to both E and W independently\n",
    "init_f32 = torch.randn(VOCAB_SIZE, HIDDEN_DIM, dtype=torch.float32, device=device) * INIT_SCALE\n",
    "init_bf16 = init_f32.to(torch.bfloat16)\n",
    "\n",
    "print(f\"Initialization: N(0, {INIT_SCALE})\")\n",
    "print(f\"  Shape: {init_bf16.shape}\")\n",
    "print(f\"  Each token initialized independently\")\n",
    "print()\n",
    "\n",
    "# Assign to BOTH embedding and unembedding\n",
    "with torch.no_grad():\n",
    "    model.transformer.wte.weight[:] = init_bf16  # E\n",
    "    model.lm_head.weight[:] = init_bf16  # W (same starting point)\n",
    "\n",
    "print(f\"✓ Initialized both E and W (pure bfloat16)\")\n",
    "print(f\"  E shape: {model.transformer.wte.weight.shape}\")\n",
    "print(f\"  W shape: {model.lm_head.weight.shape}\")\n",
    "print(f\"  Dtype: {model.transformer.wte.weight.dtype}\")\n",
    "print(f\"  E == W initially: {torch.allclose(model.transformer.wte.weight, model.lm_head.weight)}\")\n",
    "print()\n",
    "\n",
    "# Verify initialization stats for dead tokens\n",
    "E_check = model.transformer.wte.weight.cpu().float()\n",
    "E_dead = E_check[dead_indices]\n",
    "\n",
    "centroid = E_dead.mean(dim=0)\n",
    "centroid_norm = torch.norm(centroid).item()\n",
    "radii = torch.norm(E_dead - centroid, dim=1)\n",
    "mean_radius = radii.mean().item()\n",
    "max_radius = radii.max().item()\n",
    "\n",
    "print(f\"Initial dead token statistics ({n_dead:,} tokens):\")\n",
    "print(f\"  Centroid norm: {centroid_norm:.6f}\")\n",
    "print(f\"  Mean radius from centroid: {mean_radius:.6f}\")\n",
    "print(f\"  Max radius from centroid: {max_radius:.6f}\")\n",
    "print(f\"  Bounding hypersphere volume ∝ R^{HIDDEN_DIM} = {max_radius**HIDDEN_DIM:.2e}\")\n",
    "print()\n",
    "print(f\"  ✓ Dead tokens distributed in hypersphere (standard init)\")\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Recorder (Modified for Untied Weights)\n",
    "\n",
    "**Records both E and W matrices at every step.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ UntiedRecorder class defined\n"
     ]
    }
   ],
   "source": [
    "class UntiedRecorder:\n",
    "    \"\"\"Records E, W, gradients, optimizer state, logits, loss at every step in bfloat16.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_dim, record_every_n):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.record_every_n = record_every_n\n",
    "        \n",
    "        # Storage (lists of tensors, keep in RAM)\n",
    "        self.recorded_steps = []\n",
    "        self.embeddings_E = []    # Embedding matrix E\n",
    "        self.embeddings_W = []    # Unembedding matrix W\n",
    "        self.grads_E = []\n",
    "        self.grads_W = []\n",
    "        self.momentum_E = []\n",
    "        self.momentum_W = []\n",
    "        self.variance_E = []\n",
    "        self.variance_W = []\n",
    "        self.logits = []\n",
    "        self.losses = []\n",
    "        \n",
    "        # Temporary storage\n",
    "        self.current_step = 0\n",
    "        self.recorded_initial = False\n",
    "        self.grad_E_before = None\n",
    "        self.grad_W_before = None\n",
    "        self.loss_value = None\n",
    "        self.logits_sample = None\n",
    "    \n",
    "    def record_initial_state(self, model, optimizer):\n",
    "        \"\"\"Record step 0: initial state before training.\"\"\"\n",
    "        if not self.recorded_initial:\n",
    "            E = model.transformer.wte.weight.data.clone().cpu().bfloat16()\n",
    "            W = model.lm_head.weight.data.clone().cpu().bfloat16()\n",
    "            \n",
    "            # Step 0: no gradients, no optimizer state yet (zeros)\n",
    "            self.recorded_steps.append(0)\n",
    "            self.embeddings_E.append(E)\n",
    "            self.embeddings_W.append(W)\n",
    "            self.grads_E.append(torch.zeros_like(E))\n",
    "            self.grads_W.append(torch.zeros_like(W))\n",
    "            self.momentum_E.append(torch.zeros_like(E))\n",
    "            self.momentum_W.append(torch.zeros_like(W))\n",
    "            self.variance_E.append(torch.zeros_like(E))\n",
    "            self.variance_W.append(torch.zeros_like(W))\n",
    "            self.logits.append(torch.zeros(self.vocab_size, dtype=torch.bfloat16))\n",
    "            self.losses.append(torch.tensor(float('nan'), dtype=torch.bfloat16))\n",
    "            \n",
    "            self.recorded_initial = True\n",
    "            self.current_step = 1\n",
    "            \n",
    "            print(f\"✓ Recorded initial state (step 0)\")\n",
    "            print(f\"  E and W are {'IDENTICAL' if torch.allclose(E.float(), W.float()) else 'DIFFERENT'}\")\n",
    "    \n",
    "    def record_before_step(self, model, loss, logits):\n",
    "        \"\"\"Call after forward/backward, before optimizer step.\"\"\"\n",
    "        if self.current_step % self.record_every_n == 0:\n",
    "            # Capture gradients for both E and W in bfloat16\n",
    "            if model.transformer.wte.weight.grad is not None:\n",
    "                self.grad_E_before = model.transformer.wte.weight.grad.clone().cpu().bfloat16()\n",
    "            else:\n",
    "                self.grad_E_before = torch.zeros(self.vocab_size, self.hidden_dim, dtype=torch.bfloat16)\n",
    "            \n",
    "            if model.lm_head.weight.grad is not None:\n",
    "                self.grad_W_before = model.lm_head.weight.grad.clone().cpu().bfloat16()\n",
    "            else:\n",
    "                self.grad_W_before = torch.zeros(self.vocab_size, self.hidden_dim, dtype=torch.bfloat16)\n",
    "            \n",
    "            # Capture loss\n",
    "            self.loss_value = loss.item()\n",
    "            \n",
    "            # Capture logits from first sequence, last position in bfloat16\n",
    "            self.logits_sample = logits[0, -1, :].detach().cpu().bfloat16()\n",
    "    \n",
    "    def record_after_step(self, model, optimizer):\n",
    "        \"\"\"Call after optimizer step.\"\"\"\n",
    "        if self.current_step % self.record_every_n == 0:\n",
    "            if self.grad_E_before is not None and self.grad_W_before is not None and self.loss_value is not None:\n",
    "                # Capture E and W in bfloat16\n",
    "                E = model.transformer.wte.weight.data.clone().cpu().bfloat16()\n",
    "                W = model.lm_head.weight.data.clone().cpu().bfloat16()\n",
    "\n",
    "                # Capture optimizer state for E\n",
    "                param_E = model.transformer.wte.weight\n",
    "                if param_E in optimizer.state:\n",
    "                    state = optimizer.state[param_E]\n",
    "                    mom_E = state.get('exp_avg', torch.zeros_like(E)).clone().cpu().bfloat16()\n",
    "                    var_E = state.get('exp_avg_sq', torch.zeros_like(E)).clone().cpu().bfloat16()\n",
    "                else:\n",
    "                    mom_E = torch.zeros_like(E)\n",
    "                    var_E = torch.zeros_like(E)\n",
    "\n",
    "                # Capture optimizer state for W\n",
    "                param_W = model.lm_head.weight\n",
    "                if param_W in optimizer.state:\n",
    "                    state = optimizer.state[param_W]\n",
    "                    mom_W = state.get('exp_avg', torch.zeros_like(W)).clone().cpu().bfloat16()\n",
    "                    var_W = state.get('exp_avg_sq', torch.zeros_like(W)).clone().cpu().bfloat16()\n",
    "                else:\n",
    "                    mom_W = torch.zeros_like(W)\n",
    "                    var_W = torch.zeros_like(W)\n",
    "\n",
    "                # Store everything\n",
    "                self.recorded_steps.append(self.current_step)\n",
    "                self.embeddings_E.append(E)\n",
    "                self.embeddings_W.append(W)\n",
    "                self.grads_E.append(self.grad_E_before)\n",
    "                self.grads_W.append(self.grad_W_before)\n",
    "                self.momentum_E.append(mom_E)\n",
    "                self.momentum_W.append(mom_W)\n",
    "                self.variance_E.append(var_E)\n",
    "                self.variance_W.append(var_W)\n",
    "                self.logits.append(self.logits_sample)\n",
    "                self.losses.append(torch.tensor(self.loss_value, dtype=torch.bfloat16))\n",
    "\n",
    "                # Clear temp storage\n",
    "                self.grad_E_before = None\n",
    "                self.grad_W_before = None\n",
    "                self.loss_value = None\n",
    "                self.logits_sample = None\n",
    "                \n",
    "                # Progress indicator every 50 steps\n",
    "                if self.current_step % 50 == 0:\n",
    "                    print(f\"  Recorded step {self.current_step}\")\n",
    "\n",
    "        self.current_step += 1\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"Return recorded data as stacked tensors.\"\"\"\n",
    "        print(f\"\\nStacking {len(self.embeddings_E)} recorded states...\")\n",
    "        \n",
    "        return {\n",
    "            'recorded_steps': torch.tensor(self.recorded_steps, dtype=torch.long),\n",
    "            'embeddings_E': torch.stack(self.embeddings_E) if self.embeddings_E else torch.tensor([]),\n",
    "            'embeddings_W': torch.stack(self.embeddings_W) if self.embeddings_W else torch.tensor([]),\n",
    "            'grads_E': torch.stack(self.grads_E) if self.grads_E else torch.tensor([]),\n",
    "            'grads_W': torch.stack(self.grads_W) if self.grads_W else torch.tensor([]),\n",
    "            'momentum_E': torch.stack(self.momentum_E) if self.momentum_E else torch.tensor([]),\n",
    "            'momentum_W': torch.stack(self.momentum_W) if self.momentum_W else torch.tensor([]),\n",
    "            'variance_E': torch.stack(self.variance_E) if self.variance_E else torch.tensor([]),\n",
    "            'variance_W': torch.stack(self.variance_W) if self.variance_W else torch.tensor([]),\n",
    "            'logits': torch.stack(self.logits) if self.logits else torch.tensor([]),\n",
    "            'losses': torch.stack(self.losses) if self.losses else torch.tensor([]),\n",
    "        }\n",
    "\n",
    "print(\"✓ UntiedRecorder class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Trainer with Instrumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ InstrumentedTrainer defined\n"
     ]
    }
   ],
   "source": [
    "class InstrumentedTrainer(Trainer):\n",
    "    def __init__(self, recorder, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.recorder = recorder\n",
    "        self.last_logits = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"Override to capture logits.\"\"\"\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Store logits for recorder\n",
    "        self.last_logits = outputs.logits\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
    "        \"\"\"Override to inject recording.\"\"\"\n",
    "        # Standard forward + backward\n",
    "        loss = super().training_step(model, inputs, num_items_in_batch)\n",
    "        \n",
    "        # Record BEFORE optimizer step\n",
    "        self.recorder.record_before_step(model, loss, self.last_logits)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time=None, **kwargs):\n",
    "        \"\"\"Override to record AFTER optimizer step.\"\"\"\n",
    "        # Record AFTER optimizer updates parameters\n",
    "        self.recorder.record_after_step(model, self.optimizer)\n",
    "        \n",
    "        # Call parent\n",
    "        super()._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, **kwargs)\n",
    "\n",
    "print(\"✓ InstrumentedTrainer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Trainer ready (Adam, bf16=True, batch_size=32, UNTIED WEIGHTS)\n"
     ]
    }
   ],
   "source": [
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "recorder = UntiedRecorder(VOCAB_SIZE, HIDDEN_DIM, RECORD_EVERY_N_STEPS)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_steps=NUM_TRAIN_STEPS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    adam_beta1=ADAM_BETA1,\n",
    "    adam_beta2=ADAM_BETA2,\n",
    "    adam_epsilon=ADAM_EPSILON,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=50,\n",
    "    save_steps=NUM_TRAIN_STEPS + 1,  # Don't save checkpoints\n",
    "    save_total_limit=0,\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=False,\n",
    "    bf16=True,  # Native bfloat16 training\n",
    "    seed=RANDOM_SEED,\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "trainer = InstrumentedTrainer(\n",
    "    recorder=recorder,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Trainer ready (Adam, bf16=True, batch_size={BATCH_SIZE}, UNTIED WEIGHTS)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Initial State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Recorded initial state (step 0)\n",
      "  E and W are IDENTICAL\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "recorder.record_initial_state(model, trainer.optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "**1,000 steps should take ~30 seconds on M4 Pro (slightly slower than tied due to independent gradient computation).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING FLANNEL 2 TRAINING (UNTIED WEIGHTS)\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Vocabulary: 10,000 tokens (Flannel)\n",
      "  Hidden dim: 64\n",
      "  Live tokens: 6,301 (63.0%)\n",
      "  Dead tokens: 3,699 (37.0%)\n",
      "\n",
      "  Initialization: N(0, 0.02) bfloat16-native\n",
      "  Optimizer: Adam (lr=0.001)\n",
      "  Precision: bfloat16 (native)\n",
      "  Batch size: 32\n",
      "  Steps: 1,000 (~3.0 epochs)\n",
      "  Recording: every step (BOTH E AND W)\n",
      "  Weight tying: DISABLED (E ≠ W)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 00:27, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>8.035400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>7.154600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>7.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>7.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>7.089200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>7.037900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>7.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>6.965700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>6.938300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>6.914400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>6.892200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>6.881500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>6.881300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>6.858600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>6.872200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>6.851900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>6.849800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>6.846600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>6.841400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>6.849500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recorded step 50\n",
      "  Recorded step 100\n",
      "  Recorded step 150\n",
      "  Recorded step 200\n",
      "  Recorded step 250\n",
      "  Recorded step 300\n",
      "  Recorded step 350\n",
      "  Recorded step 400\n",
      "  Recorded step 450\n",
      "  Recorded step 500\n",
      "  Recorded step 550\n",
      "  Recorded step 600\n",
      "  Recorded step 650\n",
      "  Recorded step 700\n",
      "  Recorded step 750\n",
      "  Recorded step 800\n",
      "  Recorded step 850\n",
      "  Recorded step 900\n",
      "  Recorded step 950\n",
      "  Recorded step 1000\n",
      "\n",
      "================================================================================\n",
      "✓ Training complete\n",
      "  Elapsed time: 28.5 seconds (0.5 minutes)\n",
      "  Throughput: 35.1 steps/second\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"STARTING FLANNEL 2 TRAINING (UNTIED WEIGHTS)\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Vocabulary: {VOCAB_SIZE:,} tokens (Flannel)\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"  Live tokens: {n_live:,} ({100*n_live/VOCAB_SIZE:.1f}%)\")\n",
    "print(f\"  Dead tokens: {n_dead:,} ({100*n_dead/VOCAB_SIZE:.1f}%)\")\n",
    "print()\n",
    "print(f\"  Initialization: N(0, {INIT_SCALE}) bfloat16-native\")\n",
    "print(f\"  Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "print(f\"  Precision: bfloat16 (native)\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Steps: {NUM_TRAIN_STEPS:,} (~{expected_epochs:.1f} epochs)\")\n",
    "print(f\"  Recording: every step (BOTH E AND W)\")\n",
    "print(f\"  Weight tying: DISABLED (E ≠ W)\")\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ Training complete\")\n",
    "print(f\"  Elapsed time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "print(f\"  Throughput: {NUM_TRAIN_STEPS / elapsed:.1f} steps/second\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Recorded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data for save...\n",
      "\n",
      "\n",
      "Stacking 1001 recorded states...\n",
      "Saving to: ../tensors/Flannel/1.20b_flannel_2.safetensors\n",
      "\n",
      "✓ Saved successfully\n",
      "  File: ../tensors/Flannel/1.20b_flannel_2.safetensors\n",
      "  Size: 10270.3 MB\n",
      "  Save time: 14.1 seconds\n",
      "  Recorded steps: 1001\n",
      "  Step range: 0 to 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nPreparing data for save...\\n\")\n",
    "\n",
    "recorded_data = recorder.get_data()\n",
    "\n",
    "save_dict = {\n",
    "    'recorded_steps': recorded_data['recorded_steps'],\n",
    "    'embeddings_E': recorded_data['embeddings_E'],\n",
    "    'embeddings_W': recorded_data['embeddings_W'],\n",
    "    'grads_E': recorded_data['grads_E'],\n",
    "    'grads_W': recorded_data['grads_W'],\n",
    "    'momentum_E': recorded_data['momentum_E'],\n",
    "    'momentum_W': recorded_data['momentum_W'],\n",
    "    'variance_E': recorded_data['variance_E'],\n",
    "    'variance_W': recorded_data['variance_W'],\n",
    "    'logits': recorded_data['logits'],\n",
    "    'losses': recorded_data['losses'],\n",
    "    # Metadata\n",
    "    'init_scale': torch.tensor(INIT_SCALE, dtype=torch.float32),\n",
    "    'learning_rate': torch.tensor(LEARNING_RATE, dtype=torch.float32),\n",
    "    'weight_decay': torch.tensor(WEIGHT_DECAY, dtype=torch.float32),\n",
    "    'adam_beta1': torch.tensor(ADAM_BETA1, dtype=torch.float32),\n",
    "    'adam_beta2': torch.tensor(ADAM_BETA2, dtype=torch.float32),\n",
    "    'n_live': torch.tensor(n_live, dtype=torch.long),\n",
    "    'n_dead': torch.tensor(n_dead, dtype=torch.long),\n",
    "    'tied_weights': torch.tensor(False, dtype=torch.bool),  # Flag for analysis\n",
    "}\n",
    "\n",
    "output_path = Path(OUTPUT_DIR) / OUTPUT_FILE\n",
    "\n",
    "print(f\"Saving to: {output_path}\")\n",
    "\n",
    "save_start = time.time()\n",
    "save_file(save_dict, str(output_path))\n",
    "save_elapsed = time.time() - save_start\n",
    "\n",
    "file_size_mb = output_path.stat().st_size / 1e6\n",
    "\n",
    "print(f\"\\n✓ Saved successfully\")\n",
    "print(f\"  File: {output_path}\")\n",
    "print(f\"  Size: {file_size_mb:.1f} MB\")\n",
    "print(f\"  Save time: {save_elapsed:.1f} seconds\")\n",
    "print(f\"  Recorded steps: {len(recorded_data['recorded_steps'])}\")\n",
    "print(f\"  Step range: {recorded_data['recorded_steps'][0]} to {recorded_data['recorded_steps'][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUICK VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "Data shapes:\n",
      "  E (embedding): torch.Size([1001, 10000, 64])\n",
      "  W (unembedding): torch.Size([1001, 10000, 64])\n",
      "  losses: torch.Size([1001])\n",
      "\n",
      "E vs W divergence over time:\n",
      "  Step    0: ||E - W||_F = 0.0000\n",
      "  Step    1: ||E - W||_F = 0.8465\n",
      "  Step   10: ||E - W||_F = 5.8140\n",
      "  Step  100: ||E - W||_F = 30.5975\n",
      "  Step 1000: ||E - W||_F = 42.8370\n",
      "\n",
      "Dead token displacement in W (steps 0 → 1000):\n",
      "  Max: 6.12e-01\n",
      "  Mean: 5.60e-01\n",
      "  Median: 5.60e-01\n",
      "\n",
      "Dead token displacement in E (steps 0 → 1000):\n",
      "  Max: 0.00e+00\n",
      "  Mean: 0.00e+00\n",
      "  Median: 0.00e+00\n",
      "\n",
      "Live token displacement in W (steps 0 → 1000):\n",
      "  Max: 7.75e-01\n",
      "  Mean: 2.40e-01\n",
      "  Median: 2.30e-01\n",
      "\n",
      "Live token displacement in E (steps 0 → 1000):\n",
      "  Max: 7.27e-01\n",
      "  Mean: 2.33e-01\n",
      "  Median: 2.27e-01\n",
      "\n",
      "Loss trajectory:\n",
      "  Step 1: 9.2500\n",
      "  Step 1000: 6.7188\n",
      "  Reduction: 2.5312\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"QUICK VERIFICATION\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "E = recorded_data['embeddings_E']\n",
    "W = recorded_data['embeddings_W']\n",
    "losses = recorded_data['losses']\n",
    "\n",
    "print(f\"Data shapes:\")\n",
    "print(f\"  E (embedding): {E.shape}\")\n",
    "print(f\"  W (unembedding): {W.shape}\")\n",
    "print(f\"  losses: {losses.shape}\")\n",
    "print()\n",
    "\n",
    "# Check E vs W divergence\n",
    "print(f\"E vs W divergence over time:\")\n",
    "for t in [0, 1, 10, 100, 1000]:\n",
    "    if t < len(E):\n",
    "        diff = torch.norm(E[t].float() - W[t].float(), p='fro').item()\n",
    "        print(f\"  Step {t:4d}: ||E - W||_F = {diff:.4f}\")\n",
    "print()\n",
    "\n",
    "# Analyze dead token movement IN W (unembedding)\n",
    "W_step0 = W[0, dead_indices].float()\n",
    "W_step1000 = W[-1, dead_indices].float()\n",
    "\n",
    "displacements_W = torch.norm(W_step1000 - W_step0, dim=1)\n",
    "\n",
    "print(f\"Dead token displacement in W (steps 0 → {NUM_TRAIN_STEPS}):\")\n",
    "print(f\"  Max: {displacements_W.max().item():.2e}\")\n",
    "print(f\"  Mean: {displacements_W.mean().item():.2e}\")\n",
    "print(f\"  Median: {displacements_W.median().item():.2e}\")\n",
    "print()\n",
    "\n",
    "# Analyze dead token movement IN E (embedding)\n",
    "E_step0 = E[0, dead_indices].float()\n",
    "E_step1000 = E[-1, dead_indices].float()\n",
    "\n",
    "displacements_E = torch.norm(E_step1000 - E_step0, dim=1)\n",
    "\n",
    "print(f\"Dead token displacement in E (steps 0 → {NUM_TRAIN_STEPS}):\")\n",
    "print(f\"  Max: {displacements_E.max().item():.2e}\")\n",
    "print(f\"  Mean: {displacements_E.mean().item():.2e}\")\n",
    "print(f\"  Median: {displacements_E.median().item():.2e}\")\n",
    "print()\n",
    "\n",
    "# Compare to live tokens\n",
    "W_live_step0 = W[0, live_indices].float()\n",
    "W_live_step1000 = W[-1, live_indices].float()\n",
    "live_displacements_W = torch.norm(W_live_step1000 - W_live_step0, dim=1)\n",
    "\n",
    "E_live_step0 = E[0, live_indices].float()\n",
    "E_live_step1000 = E[-1, live_indices].float()\n",
    "live_displacements_E = torch.norm(E_live_step1000 - E_live_step0, dim=1)\n",
    "\n",
    "print(f\"Live token displacement in W (steps 0 → {NUM_TRAIN_STEPS}):\")\n",
    "print(f\"  Max: {live_displacements_W.max().item():.2e}\")\n",
    "print(f\"  Mean: {live_displacements_W.mean().item():.2e}\")\n",
    "print(f\"  Median: {live_displacements_W.median().item():.2e}\")\n",
    "print()\n",
    "\n",
    "print(f\"Live token displacement in E (steps 0 → {NUM_TRAIN_STEPS}):\")\n",
    "print(f\"  Max: {live_displacements_E.max().item():.2e}\")\n",
    "print(f\"  Mean: {live_displacements_E.mean().item():.2e}\")\n",
    "print(f\"  Median: {live_displacements_E.median().item():.2e}\")\n",
    "print()\n",
    "\n",
    "print(f\"Loss trajectory:\")\n",
    "print(f\"  Step 1: {losses[1].float().item():.4f}\")\n",
    "print(f\"  Step {NUM_TRAIN_STEPS}: {losses[-1].float().item():.4f}\")\n",
    "print(f\"  Reduction: {(losses[1].float() - losses[-1].float()).item():.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FLANNEL 2 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Experiment: Untied weights control (1,000 steps)\n",
      "  Tokenizer: Flannel (10k vocab, char-level BPE)\n",
      "  Corpus: 5MB English-only FineWeb\n",
      "  Training: 1,000 steps (~3.0 epochs)\n",
      "  Architecture: 2 layers, 2 heads, 64D, bfloat16-native\n",
      "  Weight tying: DISABLED (E ≠ W)\n",
      "\n",
      "Token demographics:\n",
      "  Live: 6,301 tokens (63.0%)\n",
      "  Dead: 3,699 tokens (37.0%)\n",
      "\n",
      "Data saved: ../tensors/Flannel/1.20b_flannel_2.safetensors\n",
      "Size: 10270.3 MB\n",
      "\n",
      "Key differences from Flannel 1:\n",
      "  - E and W evolve independently\n",
      "  - Dead tokens in E should get zero gradient (never in input)\n",
      "  - Dead tokens in W should get gradients (unembedding backscatter)\n",
      "  - Allows testing: does W₁[t] ≈ W₂[t] + E₂[t]?\n",
      "\n",
      "Next steps:\n",
      "  1. Compare E vs W dynamics (comoving frame for each)\n",
      "  2. Test linear decomposition: W_flannel1 ≈ W_flannel2 + E_flannel2\n",
      "  3. Check if inflationary expansion persists in W when untied\n",
      "  4. Analyze gradient magnitudes for dead tokens in E vs W\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FLANNEL 2 COMPLETE\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Experiment: Untied weights control (1,000 steps)\")\n",
    "print(f\"  Tokenizer: Flannel (10k vocab, char-level BPE)\")\n",
    "print(f\"  Corpus: 5MB English-only FineWeb\")\n",
    "print(f\"  Training: {NUM_TRAIN_STEPS:,} steps (~{expected_epochs:.1f} epochs)\")\n",
    "print(f\"  Architecture: 2 layers, 2 heads, 64D, bfloat16-native\")\n",
    "print(f\"  Weight tying: DISABLED (E ≠ W)\")\n",
    "print()\n",
    "print(f\"Token demographics:\")\n",
    "print(f\"  Live: {n_live:,} tokens ({100*n_live/VOCAB_SIZE:.1f}%)\")\n",
    "print(f\"  Dead: {n_dead:,} tokens ({100*n_dead/VOCAB_SIZE:.1f}%)\")\n",
    "print()\n",
    "print(f\"Data saved: {output_path}\")\n",
    "print(f\"Size: {file_size_mb:.1f} MB\")\n",
    "print()\n",
    "print(f\"Key differences from Flannel 1:\")\n",
    "print(f\"  - E and W evolve independently\")\n",
    "print(f\"  - Dead tokens in E should get zero gradient (never in input)\")\n",
    "print(f\"  - Dead tokens in W should get gradients (unembedding backscatter)\")\n",
    "print(f\"  - Allows testing: does W₁[t] ≈ W₂[t] + E₂[t]?\")\n",
    "print()\n",
    "print(f\"Next steps:\")\n",
    "print(f\"  1. Compare E vs W dynamics (comoving frame for each)\")\n",
    "print(f\"  2. Test linear decomposition: W_flannel1 ≈ W_flannel2 + E_flannel2\")\n",
    "print(f\"  3. Check if inflationary expansion persists in W when untied\")\n",
    "print(f\"  4. Analyze gradient magnitudes for dead tokens in E vs W\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
