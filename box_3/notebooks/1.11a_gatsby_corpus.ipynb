{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.11a: Gatsby Corpus Preparation\n",
    "\n",
    "**Goal:** Download and clean The Great Gatsby text for training experiments.\n",
    "\n",
    "## Processing Steps\n",
    "\n",
    "1. Download from Project Gutenberg\n",
    "2. Strip Gutenberg front/back matter\n",
    "3. Unwrap hard-wrapped paragraphs (single line breaks → spaces, preserve paragraph breaks)\n",
    "4. Export clean corpus for reuse\n",
    "\n",
    "## Output\n",
    "\n",
    "- **Clean corpus:** `../data/gatsby_clean.txt`\n",
    "- One paragraph per line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source URL (Project Gutenberg)\n",
    "GATSBY_URL = \"https://www.gutenberg.org/files/64317/64317-0.txt\"\n",
    "\n",
    "# Output paths\n",
    "RAW_PATH = \"../data/gatsby_raw.txt\"\n",
    "CLEAN_PATH = \"../data/gatsby_clean.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import re\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Created ../data directory\n"
     ]
    }
   ],
   "source": [
    "Path(\"../data\").mkdir(parents=True, exist_ok=True)\n",
    "print(\"✓ Created ../data directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Raw Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Raw corpus already exists at ../data/gatsby_raw.txt\n",
      "\n",
      "Raw corpus stats:\n",
      "  Characters: 270,822\n",
      "  Lines: 6,407\n"
     ]
    }
   ],
   "source": [
    "raw_path = Path(RAW_PATH)\n",
    "\n",
    "if raw_path.exists():\n",
    "    print(f\"✓ Raw corpus already exists at {RAW_PATH}\")\n",
    "else:\n",
    "    print(f\"Downloading from Project Gutenberg...\")\n",
    "    urllib.request.urlretrieve(GATSBY_URL, RAW_PATH)\n",
    "    print(f\"✓ Downloaded to {RAW_PATH}\")\n",
    "\n",
    "# Read raw text\n",
    "with open(RAW_PATH, 'r', encoding='utf-8') as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "print(f\"\\nRaw corpus stats:\")\n",
    "print(f\"  Characters: {len(raw_text):,}\")\n",
    "print(f\"  Lines: {len(raw_text.splitlines()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip Gutenberg Front/Back Matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Stripped Gutenberg front/back matter\n",
      "  Novel length: 270,690 characters\n"
     ]
    }
   ],
   "source": [
    "# Find the Gutenberg delimiters\n",
    "start_pattern = r'\\*\\*\\* START OF (?:THIS|THE) PROJECT GUTENBERG EBOOK .+ \\*\\*\\*'\n",
    "start_match = re.search(start_pattern, raw_text, re.IGNORECASE)\n",
    "\n",
    "if not start_match:\n",
    "    raise ValueError(\"Could not find Gutenberg START marker\")\n",
    "\n",
    "end_pattern = r'\\*\\*\\* END OF (?:THIS|THE) PROJECT GUTENBERG EBOOK .+ \\*\\*\\*'\n",
    "end_match = re.search(end_pattern, raw_text, re.IGNORECASE)\n",
    "\n",
    "if not end_match:\n",
    "    raise ValueError(\"Could not find Gutenberg END marker\")\n",
    "\n",
    "# Extract novel text\n",
    "novel_text = raw_text[start_match.end():end_match.start()].strip()\n",
    "\n",
    "print(f\"✓ Stripped Gutenberg front/back matter\")\n",
    "print(f\"  Novel length: {len(novel_text):,} characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unwrap Paragraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Unwrapped paragraphs\n",
      "  Before: 270,690 characters\n",
      "  After:  268,403 characters\n",
      "  Paragraphs: 1,650\n"
     ]
    }
   ],
   "source": [
    "# Normalize line endings first\n",
    "text = novel_text.replace('\\r\\n', '\\n').replace('\\r', '\\n')\n",
    "\n",
    "# Split into paragraphs (separated by blank lines)\n",
    "paragraphs = re.split(r'\\n\\n+', text)\n",
    "\n",
    "# Unwrap each paragraph (join lines with spaces)\n",
    "unwrapped = []\n",
    "for para in paragraphs:\n",
    "    # Join all lines in the paragraph with spaces\n",
    "    lines = para.split('\\n')\n",
    "    unwrapped_para = ' '.join(line.strip() for line in lines if line.strip())\n",
    "    if unwrapped_para:\n",
    "        unwrapped.append(unwrapped_para)\n",
    "\n",
    "# Join paragraphs with single newlines\n",
    "clean_text = '\\n'.join(unwrapped)\n",
    "\n",
    "print(f\"✓ Unwrapped paragraphs\")\n",
    "print(f\"  Before: {len(novel_text):,} characters\")\n",
    "print(f\"  After:  {len(clean_text):,} characters\")\n",
    "print(f\"  Paragraphs: {len(unwrapped):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Clean Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved clean corpus to ../data/gatsby_clean.txt\n",
      "  Size: 268,403 characters\n",
      "  Lines: 1,650\n"
     ]
    }
   ],
   "source": [
    "# Write clean corpus\n",
    "with open(CLEAN_PATH, 'w', encoding='utf-8') as f:\n",
    "    f.write(clean_text)\n",
    "\n",
    "print(f\"✓ Saved clean corpus to {CLEAN_PATH}\")\n",
    "print(f\"  Size: {len(clean_text):,} characters\")\n",
    "print(f\"  Lines: {len(clean_text.splitlines()):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 paragraphs:\n",
      "================================================================================\n",
      "1: The Great Gatsby by F. Scott Fitzgerald\n",
      "2: Table of Contents\n",
      "3: I II III IV V VI VII VIII IX\n",
      "4: Once again to Zelda\n",
      "5: Then wear the gold hat, if that will move her; If you can bounce high, bounce for her too, Till she ...\n",
      "6: Thomas Parke d’Invilliers\n",
      "7: I\n",
      "8: In my younger and more vulnerable years my father gave me some advice that I’ve been turning over in...\n",
      "9: “Whenever you feel like criticizing anyone,” he told me, “just remember that all the people in this ...\n",
      "10: He didn’t say any more, but we’ve always been unusually communicative in a reserved way, and I under...\n",
      "================================================================================\n",
      "\n",
      "Last 5 paragraphs:\n",
      "================================================================================\n",
      "1646: On the last night, with my trunk packed and my car sold to the grocer, I went over and looked at tha...\n",
      "1647: Most of the big shore places were closed now and there were hardly any lights except the shadowy, mo...\n",
      "1648: And as I sat there brooding on the old, unknown world, I thought of Gatsby’s wonder when he first pi...\n",
      "1649: Gatsby believed in the green light, the orgiastic future that year by year recedes before us. It elu...\n",
      "1650: So we beat on, boats against the current, borne back ceaselessly into the past.\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Show first 10 paragraphs\n",
    "lines = clean_text.split('\\n')\n",
    "print(\"\\nFirst 10 paragraphs:\")\n",
    "print(\"=\" * 80)\n",
    "for i, line in enumerate(lines[:10]):\n",
    "    print(f\"{i+1}: {line[:100]}{'...' if len(line) > 100 else ''}\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Show last 5 paragraphs  \n",
    "print(\"Last 5 paragraphs:\")\n",
    "print(\"=\" * 80)\n",
    "for i, line in enumerate(lines[-5:]):\n",
    "    print(f\"{len(lines)-5+i+1}: {line[:100]}{'...' if len(line) > 100 else ''}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "CORPUS PREPARATION COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Processing:\n",
      "  ✓ Stripped Gutenberg front/back matter\n",
      "  ✓ Unwrapped hard-wrapped paragraphs\n",
      "  ✓ One paragraph per line\n",
      "\n",
      "Output:\n",
      "  Clean corpus: ../data/gatsby_clean.txt\n",
      "  Final size: 268,403 characters\n",
      "  Paragraphs: 1,650\n",
      "\n",
      "Next steps:\n",
      "  → Eyeball check gatsby_clean.txt\n",
      "  → 1.11b: Create ASCII tokenizer based on this corpus\n",
      "  → 1.12a: Train Lil Gatsby model\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CORPUS PREPARATION COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"Processing:\")\n",
    "print(f\"  ✓ Stripped Gutenberg front/back matter\")\n",
    "print(f\"  ✓ Unwrapped hard-wrapped paragraphs\")\n",
    "print(f\"  ✓ One paragraph per line\")\n",
    "print()\n",
    "print(f\"Output:\")\n",
    "print(f\"  Clean corpus: {CLEAN_PATH}\")\n",
    "print(f\"  Final size: {len(clean_text):,} characters\")\n",
    "print(f\"  Paragraphs: {len(unwrapped):,}\")\n",
    "print()\n",
    "print(f\"Next steps:\")\n",
    "print(f\"  → Eyeball check gatsby_clean.txt\")\n",
    "print(f\"  → 1.11b: Create ASCII tokenizer based on this corpus\")\n",
    "print(f\"  → 1.12a: Train Lil Gatsby model\")\n",
    "print()\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
