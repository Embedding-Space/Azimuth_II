{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.20d: Flannel 4 - Configurable Batch Experiment Template\n",
    "\n",
    "**Purpose:** Reusable template for batch training experiments with configurable data recording.\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Configurable runs:** Set `NUM_RUNS` to 1 (single run) or 10+ (batch experiment)\n",
    "- **Selective recording:** Toggle what gets saved via `RECORD_CONFIG` dict\n",
    "- **Pre-allocated tensors:** All data stored in (n, t, ...) shaped arrays\n",
    "- **Memory calculator:** Estimates RAM and disk requirements before training\n",
    "- **Clean output:** Single file, consistent shape regardless of NUM_RUNS\n",
    "\n",
    "## What Gets Recorded\n",
    "\n",
    "Enable/disable via `RECORD_CONFIG`:\n",
    "\n",
    "- **W**: Embedding matrix (the token positions) — *always recommended*\n",
    "- **grads**: Gradients ∂L/∂W — useful for verifying gradient compression hypothesis\n",
    "- **momentum**: Adam exp_avg — rarely needed for dead tokens\n",
    "- **variance**: Adam exp_avg_sq — rarely needed for dead tokens\n",
    "- **logits**: Model outputs — can be large, useful for analyzing predictions\n",
    "- **losses**: Scalar loss per step — cheap, why not\n",
    "\n",
    "## Design Philosophy\n",
    "\n",
    "**For dead token dynamics:** Recording W alone is usually sufficient (see `docs/what_we_record.md`)\n",
    "\n",
    "**Memory scaling:**\n",
    "- W only: ~13 GB for 10 runs × 1000 steps\n",
    "- W + grads: ~26 GB\n",
    "- Everything: ~53 GB\n",
    "\n",
    "Adjust `NUM_RUNS` and `NUM_TRAIN_STEPS` to optimize data collection vs. memory constraints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parameters set\n"
     ]
    }
   ],
   "source": [
    "# === BATCH EXPERIMENT CONFIG ===\n",
    "NUM_RUNS = 10          # Number of independent training runs (1 for single run)\n",
    "BASE_SEED = 42         # First seed (subsequent runs: 43, 44, ...)\n",
    "\n",
    "# === RECORDING CONFIG ===\n",
    "# Toggle what gets recorded (True/False)\n",
    "RECORD_CONFIG = {\n",
    "    'W': True,           # Embedding matrix (ALWAYS RECOMMENDED)\n",
    "    'grads': False,      # Gradients ∂L/∂W\n",
    "    'momentum': False,   # Adam exp_avg\n",
    "    'variance': False,   # Adam exp_avg_sq\n",
    "    'logits': False,     # Model outputs (large!)\n",
    "    'losses': True,      # Loss per step (tiny, always useful)\n",
    "}\n",
    "\n",
    "# === MODEL ARCHITECTURE ===\n",
    "VOCAB_SIZE = 10000\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYER = 2\n",
    "N_HEAD = 2\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# === TRAINING CONFIG ===\n",
    "BATCH_SIZE = 32\n",
    "NUM_TRAIN_STEPS = 1000   # Steps per run\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 0.0\n",
    "\n",
    "# Optimizer: Adam\n",
    "ADAM_BETA1 = 0.9\n",
    "ADAM_BETA2 = 0.999\n",
    "ADAM_EPSILON = 1e-8\n",
    "\n",
    "# Initialization\n",
    "INIT_SCALE = 0.02  # N(0, 0.02)\n",
    "\n",
    "# === DATA PATHS ===\n",
    "TOKENIZER_PATH = \"../data/flannel_tokenizer_chars.json\"\n",
    "CORPUS_PATH = \"../data/flannel_model_corpus.txt\"\n",
    "TOKEN_MASK_PATH = \"../tensors/Flannel/live_dead_tokens.safetensors\"\n",
    "OUTPUT_DIR = \"../tensors/Flannel\"\n",
    "OUTPUT_FILE = \"1.20d_flannel_4.safetensors\"\n",
    "\n",
    "print(\"✓ Parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from tokenizers import Tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from safetensors.torch import save_file, load_file\n",
    "import time\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory & Disk Requirements Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MEMORY & DISK REQUIREMENTS\n",
      "================================================================================\n",
      "\n",
      "Experiment configuration:\n",
      "  Runs: 10\n",
      "  Steps per run: 1,000\n",
      "  Vocab size: 10,000\n",
      "  Hidden dim: 64\n",
      "\n",
      "Recording 2 item(s): W, losses\n",
      "\n",
      "  W            (10, 1001, 10000, 64)             12.81 GB\n",
      "  losses       (10, 1001)                         0.00 GB\n",
      "\n",
      "Model parameters: 738,304\n",
      "  Model memory (bf16):         0.00 GB\n",
      "  Optimizer state (fp32):      0.01 GB\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "PEAK RAM ESTIMATE:            12.82 GB\n",
      "DISK SPACE NEEDED:            12.81 GB\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "✓ Resources within budget. Ready to proceed.\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"MEMORY & DISK REQUIREMENTS\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "bytes_per_element = 2  # bfloat16\n",
    "\n",
    "# Calculate size for each enabled recording\n",
    "tensor_sizes = {}\n",
    "tensor_shapes = {}\n",
    "\n",
    "if RECORD_CONFIG['W']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE, HIDDEN_DIM)\n",
    "    tensor_shapes['W'] = shape\n",
    "    tensor_sizes['W'] = np.prod(shape) * bytes_per_element\n",
    "\n",
    "if RECORD_CONFIG['grads']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE, HIDDEN_DIM)\n",
    "    tensor_shapes['grads'] = shape\n",
    "    tensor_sizes['grads'] = np.prod(shape) * bytes_per_element\n",
    "\n",
    "if RECORD_CONFIG['momentum']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE, HIDDEN_DIM)\n",
    "    tensor_shapes['momentum'] = shape\n",
    "    tensor_sizes['momentum'] = np.prod(shape) * bytes_per_element\n",
    "\n",
    "if RECORD_CONFIG['variance']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE, HIDDEN_DIM)\n",
    "    tensor_shapes['variance'] = shape\n",
    "    tensor_sizes['variance'] = np.prod(shape) * bytes_per_element\n",
    "\n",
    "if RECORD_CONFIG['logits']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE)\n",
    "    tensor_shapes['logits'] = shape\n",
    "    tensor_sizes['logits'] = np.prod(shape) * bytes_per_element\n",
    "\n",
    "if RECORD_CONFIG['losses']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1)\n",
    "    tensor_shapes['losses'] = shape\n",
    "    tensor_sizes['losses'] = np.prod(shape) * bytes_per_element\n",
    "\n",
    "total_recorded_data = sum(tensor_sizes.values())\n",
    "\n",
    "# Model memory (one model at a time during training)\n",
    "# Embeddings + transformer layers\n",
    "embedding_params = VOCAB_SIZE * HIDDEN_DIM  # Tied weights, so only one copy\n",
    "# Rough estimate for transformer: 4*d² per attention layer + 8*d² per FFN\n",
    "params_per_layer = 12 * HIDDEN_DIM**2\n",
    "transformer_params = N_LAYER * params_per_layer\n",
    "total_model_params = embedding_params + transformer_params\n",
    "\n",
    "model_memory = total_model_params * bytes_per_element\n",
    "optimizer_memory = 2 * total_model_params * 4  # Adam keeps fp32 momentum + variance\n",
    "\n",
    "# Peak RAM = pre-allocated recording tensors + model + optimizer\n",
    "peak_ram = total_recorded_data + model_memory + optimizer_memory\n",
    "\n",
    "# Disk space = just the recorded data\n",
    "disk_space = total_recorded_data\n",
    "\n",
    "# Display\n",
    "print(f\"Experiment configuration:\")\n",
    "print(f\"  Runs: {NUM_RUNS}\")\n",
    "print(f\"  Steps per run: {NUM_TRAIN_STEPS:,}\")\n",
    "print(f\"  Vocab size: {VOCAB_SIZE:,}\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print()\n",
    "\n",
    "enabled_items = [k for k, v in RECORD_CONFIG.items() if v]\n",
    "print(f\"Recording {len(enabled_items)} item(s): {', '.join(enabled_items)}\")\n",
    "print()\n",
    "\n",
    "for name, size_bytes in tensor_sizes.items():\n",
    "    size_gb = size_bytes / 1e9\n",
    "    shape = tensor_shapes[name]\n",
    "    print(f\"  {name:12} {str(shape):30} {size_gb:8.2f} GB\")\n",
    "\n",
    "print()\n",
    "print(f\"Model parameters: {total_model_params:,}\")\n",
    "print(f\"  Model memory (bf16):     {model_memory/1e9:8.2f} GB\")\n",
    "print(f\"  Optimizer state (fp32):  {optimizer_memory/1e9:8.2f} GB\")\n",
    "print()\n",
    "print(f\"{'─'*80}\")\n",
    "print(f\"PEAK RAM ESTIMATE:         {peak_ram/1e9:8.2f} GB\")\n",
    "print(f\"DISK SPACE NEEDED:         {disk_space/1e9:8.2f} GB\")\n",
    "print(f\"{'─'*80}\")\n",
    "\n",
    "# Warnings\n",
    "RAM_BUDGET = 24  # GB\n",
    "DISK_BUDGET = 50  # GB\n",
    "\n",
    "if peak_ram > RAM_BUDGET * 1e9:\n",
    "    print(f\"\\n⚠️  WARNING: Peak RAM ({peak_ram/1e9:.1f} GB) exceeds {RAM_BUDGET} GB budget!\")\n",
    "    print(f\"   Consider:\")\n",
    "    print(f\"   - Reducing NUM_RUNS (currently {NUM_RUNS})\")\n",
    "    print(f\"   - Reducing NUM_TRAIN_STEPS (currently {NUM_TRAIN_STEPS:,})\")\n",
    "    print(f\"   - Disabling expensive recordings (grads, momentum, variance, logits)\")\n",
    "\n",
    "if disk_space > DISK_BUDGET * 1e9:\n",
    "    print(f\"\\n⚠️  WARNING: Disk space ({disk_space/1e9:.1f} GB) exceeds {DISK_BUDGET} GB budget!\")\n",
    "\n",
    "if peak_ram <= RAM_BUDGET * 1e9 and disk_space <= DISK_BUDGET * 1e9:\n",
    "    print(f\"\\n✓ Resources within budget. Ready to proceed.\")\n",
    "\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizer: ../data/flannel_tokenizer_chars.json\n",
      "  ✓ Vocabulary: 10,000 tokens\n",
      "\n",
      "Loading corpus: ../data/flannel_model_corpus.txt\n",
      "  ✓ Tokens: 1,371,328\n",
      "\n",
      "Loading token masks: ../tensors/Flannel/live_dead_tokens.safetensors\n",
      "  ✓ Live: 6,301 | Dead: 3,699\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "print(f\"Loading tokenizer: {TOKENIZER_PATH}\")\n",
    "tokenizer = Tokenizer.from_file(str(TOKENIZER_PATH))\n",
    "print(f\"  ✓ Vocabulary: {tokenizer.get_vocab_size():,} tokens\\n\")\n",
    "\n",
    "# Corpus\n",
    "print(f\"Loading corpus: {CORPUS_PATH}\")\n",
    "with open(CORPUS_PATH, 'r', encoding='utf-8') as f:\n",
    "    corpus_text = f.read()\n",
    "encoding = tokenizer.encode(corpus_text)\n",
    "tokens = encoding.ids\n",
    "corpus_tensor = torch.tensor(tokens, dtype=torch.long, device=device)\n",
    "print(f\"  ✓ Tokens: {len(tokens):,}\\n\")\n",
    "\n",
    "# Token masks\n",
    "print(f\"Loading token masks: {TOKEN_MASK_PATH}\")\n",
    "mask_data = load_file(TOKEN_MASK_PATH)\n",
    "dead_indices = mask_data['dead_indices']\n",
    "n_dead = mask_data['dead_mask'].sum().item()\n",
    "n_live = mask_data['live_mask'].sum().item()\n",
    "print(f\"  ✓ Live: {n_live:,} | Dead: {n_dead:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Dataset: 1,371,200 examples\n"
     ]
    }
   ],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, corpus_tensor, max_seq_len):\n",
    "        self.corpus = corpus_tensor\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(0, len(self.corpus) - self.max_seq_len)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.corpus[idx : idx + self.max_seq_len + 1]\n",
    "        return {\n",
    "            'input_ids': chunk[:-1],\n",
    "            'labels': chunk[1:]\n",
    "        }\n",
    "\n",
    "dataset = TokenDataset(corpus_tensor, MAX_SEQ_LEN)\n",
    "print(f\"\\n✓ Dataset: {len(dataset):,} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-allocate Recording Tensors\n",
    "\n",
    "All tensors are created on CPU with shape `(n_runs, n_steps, ...)` before training begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pre-allocating recording tensors...\n",
      "\n",
      "  W:        (10, 1001, 10000, 64)\n",
      "  losses:   (10, 1001)\n",
      "\n",
      "✓ All tensors allocated on CPU\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPre-allocating recording tensors...\\n\")\n",
    "\n",
    "tensors = {}\n",
    "\n",
    "if RECORD_CONFIG['W']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE, HIDDEN_DIM)\n",
    "    tensors['W'] = torch.zeros(shape, dtype=torch.bfloat16)\n",
    "    print(f\"  W:        {shape}\")\n",
    "\n",
    "if RECORD_CONFIG['grads']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE, HIDDEN_DIM)\n",
    "    tensors['grads'] = torch.zeros(shape, dtype=torch.bfloat16)\n",
    "    print(f\"  grads:    {shape}\")\n",
    "\n",
    "if RECORD_CONFIG['momentum']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE, HIDDEN_DIM)\n",
    "    tensors['momentum'] = torch.zeros(shape, dtype=torch.bfloat16)\n",
    "    print(f\"  momentum: {shape}\")\n",
    "\n",
    "if RECORD_CONFIG['variance']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE, HIDDEN_DIM)\n",
    "    tensors['variance'] = torch.zeros(shape, dtype=torch.bfloat16)\n",
    "    print(f\"  variance: {shape}\")\n",
    "\n",
    "if RECORD_CONFIG['logits']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1, VOCAB_SIZE)\n",
    "    tensors['logits'] = torch.zeros(shape, dtype=torch.bfloat16)\n",
    "    print(f\"  logits:   {shape}\")\n",
    "\n",
    "if RECORD_CONFIG['losses']:\n",
    "    shape = (NUM_RUNS, NUM_TRAIN_STEPS+1)\n",
    "    tensors['losses'] = torch.full(shape, float('nan'), dtype=torch.bfloat16)\n",
    "    print(f\"  losses:   {shape}\")\n",
    "\n",
    "print(f\"\\n✓ All tensors allocated on CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Recorder\n",
    "\n",
    "Writes directly into pre-allocated tensor slices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Recorder class defined\n"
     ]
    }
   ],
   "source": [
    "class BatchRecorder:\n",
    "    \"\"\"Records data directly into pre-allocated tensors.\"\"\"\n",
    "    \n",
    "    def __init__(self, tensors, record_config, run_idx):\n",
    "        self.tensors = tensors\n",
    "        self.config = record_config\n",
    "        self.run_idx = run_idx\n",
    "        self.current_step = 0\n",
    "        self.recorded_initial = False\n",
    "        \n",
    "        # Temporary storage for between forward/backward and optimizer step\n",
    "        self.grad_before = None\n",
    "        self.loss_value = None\n",
    "        self.logits_sample = None\n",
    "    \n",
    "    def record_initial_state(self, model, optimizer):\n",
    "        \"\"\"Record step 0.\"\"\"\n",
    "        if not self.recorded_initial:\n",
    "            t = 0\n",
    "            \n",
    "            if self.config['W']:\n",
    "                self.tensors['W'][self.run_idx, t] = model.transformer.wte.weight.data.clone().cpu().bfloat16()\n",
    "            \n",
    "            # All others are zero at t=0 (no gradients, no optimizer state, no loss yet)\n",
    "            \n",
    "            self.recorded_initial = True\n",
    "            self.current_step = 1\n",
    "            print(f\"    ✓ Recorded initial state (t=0)\")\n",
    "    \n",
    "    def record_before_step(self, model, loss, logits):\n",
    "        \"\"\"Capture data after backward, before optimizer step.\"\"\"\n",
    "        # Store for use in record_after_step\n",
    "        if self.config['grads'] and model.transformer.wte.weight.grad is not None:\n",
    "            self.grad_before = model.transformer.wte.weight.grad.clone().cpu().bfloat16()\n",
    "        \n",
    "        if self.config['losses']:\n",
    "            self.loss_value = loss.item()\n",
    "        \n",
    "        if self.config['logits']:\n",
    "            # Sample from first sequence, last position\n",
    "            self.logits_sample = logits[0, -1, :].detach().cpu().bfloat16()\n",
    "    \n",
    "    def record_after_step(self, model, optimizer):\n",
    "        \"\"\"Record data after optimizer step.\"\"\"\n",
    "        t = self.current_step\n",
    "        \n",
    "        # Guard against recording beyond allocated size\n",
    "        # Tensor has shape (n_runs, n_steps+1, ...) with valid indices 0 to n_steps\n",
    "        # current_step starts at 1 after initial state, goes to n_steps after final training step\n",
    "        if t > self.tensors['W'].shape[1] - 1 if 'W' in self.tensors else float('inf'):\n",
    "            # We've exceeded the recording window (shouldn't happen, but guard against it)\n",
    "            return\n",
    "        \n",
    "        if self.config['W']:\n",
    "            self.tensors['W'][self.run_idx, t] = model.transformer.wte.weight.data.clone().cpu().bfloat16()\n",
    "        \n",
    "        if self.config['grads'] and self.grad_before is not None:\n",
    "            self.tensors['grads'][self.run_idx, t] = self.grad_before\n",
    "            self.grad_before = None\n",
    "        \n",
    "        if self.config['momentum']:\n",
    "            param = model.transformer.wte.weight\n",
    "            if param in optimizer.state and 'exp_avg' in optimizer.state[param]:\n",
    "                self.tensors['momentum'][self.run_idx, t] = optimizer.state[param]['exp_avg'].clone().cpu().bfloat16()\n",
    "        \n",
    "        if self.config['variance']:\n",
    "            param = model.transformer.wte.weight\n",
    "            if param in optimizer.state and 'exp_avg_sq' in optimizer.state[param]:\n",
    "                self.tensors['variance'][self.run_idx, t] = optimizer.state[param]['exp_avg_sq'].clone().cpu().bfloat16()\n",
    "        \n",
    "        if self.config['logits'] and self.logits_sample is not None:\n",
    "            self.tensors['logits'][self.run_idx, t] = self.logits_sample\n",
    "            self.logits_sample = None\n",
    "        \n",
    "        if self.config['losses'] and self.loss_value is not None:\n",
    "            self.tensors['losses'][self.run_idx, t] = self.loss_value\n",
    "            self.loss_value = None\n",
    "        \n",
    "        # Progress\n",
    "        if t % 100 == 0:\n",
    "            print(f\"    Step {t}\")\n",
    "        \n",
    "        self.current_step += 1\n",
    "\n",
    "print(\"✓ Recorder class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instrumented Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ InstrumentedTrainer defined\n"
     ]
    }
   ],
   "source": [
    "class InstrumentedTrainer(Trainer):\n",
    "    def __init__(self, recorder, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.recorder = recorder\n",
    "        self.last_logits = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        self.last_logits = outputs.logits\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
    "        loss = super().training_step(model, inputs, num_items_in_batch)\n",
    "        self.recorder.record_before_step(model, loss, self.last_logits)\n",
    "        return loss\n",
    "\n",
    "    def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time=None, **kwargs):\n",
    "        self.recorder.record_after_step(model, self.optimizer)\n",
    "        super()._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, **kwargs)\n",
    "\n",
    "print(\"✓ InstrumentedTrainer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FLANNEL 4: BATCH TRAINING\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Runs: 10\n",
      "  Steps per run: 1,000\n",
      "  Seeds: 42–51\n",
      "  Recording: W, losses\n",
      "\n",
      "================================================================================\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RUN 1/10 (seed=42)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=42)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1299, 'grad_norm': 0.2177734375, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.3267, 'train_samples_per_second': 1263.491, 'train_steps_per_second': 39.484, 'train_loss': 7.12989404296875, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 1 complete (25.4s)\n",
      "\n",
      "================================================================================\n",
      "RUN 2/10 (seed=43)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=43)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1002, 'grad_norm': 0.275390625, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.2703, 'train_samples_per_second': 1266.311, 'train_steps_per_second': 39.572, 'train_loss': 7.10022265625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 2 complete (25.4s)\n",
      "\n",
      "================================================================================\n",
      "RUN 3/10 (seed=44)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=44)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1005, 'grad_norm': 0.2470703125, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 24.8896, 'train_samples_per_second': 1285.678, 'train_steps_per_second': 40.177, 'train_loss': 7.10053759765625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 3 complete (25.0s)\n",
      "\n",
      "================================================================================\n",
      "RUN 4/10 (seed=45)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=45)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1106, 'grad_norm': 0.26171875, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 24.7603, 'train_samples_per_second': 1292.39, 'train_steps_per_second': 40.387, 'train_loss': 7.1105634765625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 4 complete (24.8s)\n",
      "\n",
      "================================================================================\n",
      "RUN 5/10 (seed=46)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=46)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1435, 'grad_norm': 0.1904296875, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 24.7785, 'train_samples_per_second': 1291.443, 'train_steps_per_second': 40.358, 'train_loss': 7.14353564453125, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 5 complete (24.9s)\n",
      "\n",
      "================================================================================\n",
      "RUN 6/10 (seed=47)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=47)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1018, 'grad_norm': 0.2578125, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 24.7761, 'train_samples_per_second': 1291.569, 'train_steps_per_second': 40.362, 'train_loss': 7.1017978515625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 6 complete (24.9s)\n",
      "\n",
      "================================================================================\n",
      "RUN 7/10 (seed=48)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=48)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1179, 'grad_norm': 0.259765625, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 24.8968, 'train_samples_per_second': 1285.307, 'train_steps_per_second': 40.166, 'train_loss': 7.11792431640625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 7 complete (25.0s)\n",
      "\n",
      "================================================================================\n",
      "RUN 8/10 (seed=49)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=49)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1226, 'grad_norm': 0.2333984375, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 24.9642, 'train_samples_per_second': 1281.836, 'train_steps_per_second': 40.057, 'train_loss': 7.1226103515625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 8 complete (25.0s)\n",
      "\n",
      "================================================================================\n",
      "RUN 9/10 (seed=50)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=50)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.0951, 'grad_norm': 0.2734375, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 24.9463, 'train_samples_per_second': 1282.757, 'train_steps_per_second': 40.086, 'train_loss': 7.09510791015625, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 9 complete (25.0s)\n",
      "\n",
      "================================================================================\n",
      "RUN 10/10 (seed=51)\n",
      "================================================================================\n",
      "\n",
      "  ✓ Model initialized (seed=51)\n",
      "    ✓ Recorded initial state (t=0)\n",
      "  Training...\n",
      "    Step 100\n",
      "    Step 200\n",
      "    Step 300\n",
      "    Step 400\n",
      "    Step 500\n",
      "    Step 600\n",
      "    Step 700\n",
      "    Step 800\n",
      "    Step 900\n",
      "    Step 1000\n",
      "{'loss': 7.1065, 'grad_norm': 0.2470703125, 'learning_rate': 1e-06, 'epoch': 0.023337222870478413}\n",
      "{'train_runtime': 25.1324, 'train_samples_per_second': 1273.254, 'train_steps_per_second': 39.789, 'train_loss': 7.10651904296875, 'epoch': 0.023337222870478413}\n",
      "\n",
      "  ✓ Run 10 complete (25.2s)\n",
      "\n",
      "================================================================================\n",
      "✓ All 10 runs complete\n",
      "  Total time: 251.0s (4.2 minutes)\n",
      "  Average per run: 25.1s\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FLANNEL 4: BATCH TRAINING\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Configuration:\")\n",
    "print(f\"  Runs: {NUM_RUNS}\")\n",
    "print(f\"  Steps per run: {NUM_TRAIN_STEPS:,}\")\n",
    "print(f\"  Seeds: {BASE_SEED}–{BASE_SEED + NUM_RUNS - 1}\")\n",
    "print(f\"  Recording: {', '.join([k for k, v in RECORD_CONFIG.items() if v])}\")\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "experiment_start = time.time()\n",
    "\n",
    "for run_idx in range(NUM_RUNS):\n",
    "    seed = BASE_SEED + run_idx\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"RUN {run_idx + 1}/{NUM_RUNS} (seed={seed})\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Set seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Create model\n",
    "    config = GPT2Config(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        n_positions=MAX_SEQ_LEN,\n",
    "        n_embd=HIDDEN_DIM,\n",
    "        n_layer=N_LAYER,\n",
    "        n_head=N_HEAD,\n",
    "        resid_pdrop=0.0,\n",
    "        embd_pdrop=0.0,\n",
    "        attn_pdrop=0.0,\n",
    "        tie_word_embeddings=True,\n",
    "    )\n",
    "    \n",
    "    model = GPT2LMHeadModel(config).to(torch.bfloat16).to(device)\n",
    "    \n",
    "    # Initialize\n",
    "    init_f32 = torch.randn(VOCAB_SIZE, HIDDEN_DIM, dtype=torch.float32, device=device) * INIT_SCALE\n",
    "    with torch.no_grad():\n",
    "        model.transformer.wte.weight[:] = init_f32.to(torch.bfloat16)\n",
    "    \n",
    "    print(f\"  ✓ Model initialized (seed={seed})\")\n",
    "    \n",
    "    # Create recorder for this run\n",
    "    recorder = BatchRecorder(tensors, RECORD_CONFIG, run_idx)\n",
    "    \n",
    "    # Training args\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        max_steps=NUM_TRAIN_STEPS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        adam_beta1=ADAM_BETA1,\n",
    "        adam_beta2=ADAM_BETA2,\n",
    "        adam_epsilon=ADAM_EPSILON,\n",
    "        optim=\"adamw_torch\",\n",
    "        logging_steps=1000,\n",
    "        save_steps=NUM_TRAIN_STEPS + 1,\n",
    "        save_total_limit=0,\n",
    "        dataloader_num_workers=0,\n",
    "        dataloader_pin_memory=False,\n",
    "        bf16=True,\n",
    "        seed=seed,\n",
    "        report_to=\"none\",\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "    \n",
    "    trainer = InstrumentedTrainer(\n",
    "        recorder=recorder,\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=dataset,\n",
    "    )\n",
    "    \n",
    "    # Record initial state\n",
    "    recorder.record_initial_state(model, trainer.optimizer)\n",
    "    \n",
    "    # Train\n",
    "    print(f\"  Training...\")\n",
    "    run_start = time.time()\n",
    "    trainer.train()\n",
    "    run_elapsed = time.time() - run_start\n",
    "    \n",
    "    print(f\"\\n  ✓ Run {run_idx + 1} complete ({run_elapsed:.1f}s)\")\n",
    "    \n",
    "    # Clean up\n",
    "    del model, trainer, recorder\n",
    "    \n",
    "    if device == 'mps':\n",
    "        torch.mps.empty_cache()\n",
    "    elif device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "experiment_elapsed = time.time() - experiment_start\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ All {NUM_RUNS} runs complete\")\n",
    "print(f\"  Total time: {experiment_elapsed:.1f}s ({experiment_elapsed/60:.1f} minutes)\")\n",
    "print(f\"  Average per run: {experiment_elapsed/NUM_RUNS:.1f}s\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving data...\n",
      "\n",
      "  W            (10, 1001, 10000, 64)         \n",
      "  losses       (10, 1001)                    \n",
      "\n",
      "Saving to: ../tensors/Flannel/1.20d_flannel_4.safetensors\n",
      "\n",
      "✓ Saved successfully\n",
      "  File: 1.20d_flannel_4.safetensors\n",
      "  Size: 12812.8 MB (12.81 GB)\n",
      "  Save time: 11.4s\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nSaving data...\\n\")\n",
    "\n",
    "# Build save dictionary\n",
    "save_dict = {\n",
    "    # Metadata\n",
    "    'n_runs': torch.tensor(NUM_RUNS, dtype=torch.long),\n",
    "    'base_seed': torch.tensor(BASE_SEED, dtype=torch.long),\n",
    "    'n_steps': torch.tensor(NUM_TRAIN_STEPS, dtype=torch.long),\n",
    "    'n_live': torch.tensor(n_live, dtype=torch.long),\n",
    "    'n_dead': torch.tensor(n_dead, dtype=torch.long),\n",
    "    'vocab_size': torch.tensor(VOCAB_SIZE, dtype=torch.long),\n",
    "    'hidden_dim': torch.tensor(HIDDEN_DIM, dtype=torch.long),\n",
    "    'init_scale': torch.tensor(INIT_SCALE, dtype=torch.float32),\n",
    "    'learning_rate': torch.tensor(LEARNING_RATE, dtype=torch.float32),\n",
    "    'weight_decay': torch.tensor(WEIGHT_DECAY, dtype=torch.float32),\n",
    "    'adam_beta1': torch.tensor(ADAM_BETA1, dtype=torch.float32),\n",
    "    'adam_beta2': torch.tensor(ADAM_BETA2, dtype=torch.float32),\n",
    "    # Record config (for documentation)\n",
    "    'recorded_W': torch.tensor(RECORD_CONFIG['W'], dtype=torch.bool),\n",
    "    'recorded_grads': torch.tensor(RECORD_CONFIG['grads'], dtype=torch.bool),\n",
    "    'recorded_momentum': torch.tensor(RECORD_CONFIG['momentum'], dtype=torch.bool),\n",
    "    'recorded_variance': torch.tensor(RECORD_CONFIG['variance'], dtype=torch.bool),\n",
    "    'recorded_logits': torch.tensor(RECORD_CONFIG['logits'], dtype=torch.bool),\n",
    "    'recorded_losses': torch.tensor(RECORD_CONFIG['losses'], dtype=torch.bool),\n",
    "}\n",
    "\n",
    "# Add all recorded tensors\n",
    "for name, tensor in tensors.items():\n",
    "    save_dict[name] = tensor\n",
    "    print(f\"  {name:12} {str(tuple(tensor.shape)):30}\")\n",
    "\n",
    "# Save\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "output_path = Path(OUTPUT_DIR) / OUTPUT_FILE\n",
    "\n",
    "print(f\"\\nSaving to: {output_path}\\n\")\n",
    "\n",
    "save_start = time.time()\n",
    "save_file(save_dict, str(output_path))\n",
    "save_elapsed = time.time() - save_start\n",
    "\n",
    "file_size_mb = output_path.stat().st_size / 1e6\n",
    "file_size_gb = file_size_mb / 1000\n",
    "\n",
    "print(f\"✓ Saved successfully\")\n",
    "print(f\"  File: {output_path.name}\")\n",
    "print(f\"  Size: {file_size_mb:.1f} MB ({file_size_gb:.2f} GB)\")\n",
    "print(f\"  Save time: {save_elapsed:.1f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FLANNEL 4 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Experiment: 10 independent training runs\n",
      "  Steps per run: 1,000\n",
      "  Seeds: 42–51\n",
      "  Recorded: W, losses\n",
      "\n",
      "Data saved: ../tensors/Flannel/1.20d_flannel_4.safetensors\n",
      "  Size: 12.81 GB\n",
      "  Total experiment time: 4.2 minutes\n",
      "\n",
      "Data structure:\n",
      "  W: (10, 1001, 10000, 64)\n",
      "  losses: (10, 1001)\n",
      "\n",
      "Next steps:\n",
      "  1. Load data and verify run 0 (seed=42)\n",
      "  2. Analyze epoch reproducibility across runs\n",
      "  3. Compute bulk properties (velocity, temperature, etc.)\n",
      "  4. Study phase transitions\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FLANNEL 4 COMPLETE\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Experiment: {NUM_RUNS} independent training runs\")\n",
    "print(f\"  Steps per run: {NUM_TRAIN_STEPS:,}\")\n",
    "print(f\"  Seeds: {BASE_SEED}–{BASE_SEED + NUM_RUNS - 1}\")\n",
    "print(f\"  Recorded: {', '.join([k for k, v in RECORD_CONFIG.items() if v])}\")\n",
    "print()\n",
    "print(f\"Data saved: {output_path}\")\n",
    "print(f\"  Size: {file_size_gb:.2f} GB\")\n",
    "print(f\"  Total experiment time: {experiment_elapsed/60:.1f} minutes\")\n",
    "print()\n",
    "print(f\"Data structure:\")\n",
    "for name in tensors.keys():\n",
    "    print(f\"  {name}: {tuple(tensors[name].shape)}\")\n",
    "print()\n",
    "print(f\"Next steps:\")\n",
    "print(f\"  1. Load data and verify run 0 (seed={BASE_SEED})\")\n",
    "print(f\"  2. Analyze epoch reproducibility across runs\")\n",
    "print(f\"  3. Compute bulk properties (velocity, temperature, etc.)\")\n",
    "print(f\"  4. Study phase transitions\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
