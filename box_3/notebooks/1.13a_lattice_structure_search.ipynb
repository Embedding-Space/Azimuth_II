{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.13a: Black Hole Detection\n",
    "\n",
    "**Goal:** Find tokens with identical embeddings (black holes).\n",
    "\n",
    "## Method\n",
    "\n",
    "Use `torch.unique()` to find duplicate vectors efficiently.\n",
    "\n",
    "- If two or more tokens have identical embeddings across all dimensions → black hole\n",
    "- Report how many tokens participate in black holes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor to analyze\n",
    "TENSOR_FILE = \"../tensors/Qwen3-4B-Instruct-2507/W.safetensors\"\n",
    "TENSOR_KEY = \"W\"\n",
    "TENSOR_INDEX = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from safetensors.torch import load_file\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded W from W.safetensors\n",
      "  Shape: torch.Size([151936, 2560])\n",
      "  Dtype: torch.bfloat16\n",
      "  Memory: ~0.72 GB\n",
      "\n",
      "Analyzing 151,936 vectors in 2,560 dimensions\n"
     ]
    }
   ],
   "source": [
    "# Load tensor\n",
    "data = load_file(TENSOR_FILE)\n",
    "W = data[TENSOR_KEY]\n",
    "\n",
    "# Apply indexing if specified\n",
    "if TENSOR_INDEX is not None:\n",
    "    W = W[TENSOR_INDEX]\n",
    "\n",
    "n_vectors, n_dims = W.shape\n",
    "\n",
    "print(f\"✓ Loaded W from {Path(TENSOR_FILE).name}\")\n",
    "print(f\"  Shape: {W.shape}\")\n",
    "print(f\"  Dtype: {W.dtype}\")\n",
    "print(f\"  Memory: ~{W.element_size() * W.numel() / 1024**3:.2f} GB\")\n",
    "print()\n",
    "print(f\"Analyzing {n_vectors:,} vectors in {n_dims:,} dimensions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Black Holes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BLACK HOLE DETECTION\n",
      "================================================================================\n",
      "\n",
      "Finding unique vectors...\n",
      "  ✓ Found 149,849 unique vectors\n",
      "  ✓ 2,087 vectors are duplicates\n",
      "\n",
      "Found 13 black hole centroids (unique vectors with duplicates)\n",
      "Counting tokens...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 13/13 [00:00<00:00, 6255.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RESULTS\n",
      "================================================================================\n",
      "\n",
      "Black hole tokens: 2,100 (1.38%)\n",
      "\n",
      "⚠️  2,100 tokens share embeddings with other tokens!\n",
      "   Organized into 13 black hole centroids\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BLACK HOLE DETECTION\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# torch.unique not implemented on MPS in Torch 2.8, use CPU\n",
    "print(\"Finding unique vectors...\")\n",
    "W_cpu = W.cpu()\n",
    "W_unique, inverse_indices, counts = torch.unique(W_cpu, dim=0, return_inverse=True, return_counts=True)\n",
    "\n",
    "n_unique = len(W_unique)\n",
    "n_duplicates = n_vectors - n_unique\n",
    "\n",
    "print(f\"  ✓ Found {n_unique:,} unique vectors\")\n",
    "print(f\"  ✓ {n_duplicates:,} vectors are duplicates\")\n",
    "print()\n",
    "\n",
    "# Count tokens participating in black holes\n",
    "duplicate_mask = counts > 1\n",
    "n_black_hole_centroids = duplicate_mask.sum().item()\n",
    "\n",
    "black_hole_tokens = []\n",
    "if n_black_hole_centroids > 0:\n",
    "    print(f\"Found {n_black_hole_centroids} black hole centroids (unique vectors with duplicates)\")\n",
    "    print(\"Counting tokens...\")\n",
    "    \n",
    "    black_hole_unique_ids = duplicate_mask.nonzero(as_tuple=True)[0]\n",
    "    \n",
    "    for unique_id in tqdm(black_hole_unique_ids, desc=\"Processing\"):\n",
    "        # Find all tokens that map to this unique vector\n",
    "        tokens = (inverse_indices == unique_id).nonzero(as_tuple=True)[0].tolist()\n",
    "        black_hole_tokens.extend(tokens)\n",
    "    \n",
    "    print()\n",
    "\n",
    "n_black_hole_tokens = len(black_hole_tokens)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(f\"Black hole tokens: {n_black_hole_tokens:,} ({100 * n_black_hole_tokens / n_vectors:.2f}%)\")\n",
    "\n",
    "if n_black_hole_tokens == 0:\n",
    "    print(\"\\n✓ No black holes found. All vectors are unique.\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  {n_black_hole_tokens:,} tokens share embeddings with other tokens!\")\n",
    "    print(f\"   Organized into {n_black_hole_centroids} black hole centroids\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
