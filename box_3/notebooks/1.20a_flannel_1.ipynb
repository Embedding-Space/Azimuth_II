{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.20a: Flannel 1 - Baseline 1,000-Step Run\n",
    "\n",
    "**Experiment:** Train tiny GPT-2 model with Flannel tokenizer (10k vocab, ~3.7k dead tokens) on English-only corpus.\n",
    "\n",
    "## The Flannel Experiment\n",
    "\n",
    "**Goal:** Study token dynamics under controlled conditions with engineered dead tokens.\n",
    "\n",
    "**Design:**\n",
    "1. **Tokenizer:** Trained on 80% English + 20% Thai mixed corpus → 10,000 tokens\n",
    "2. **Model training:** Pure English corpus (5MB FineWeb) → Thai tokens never appear\n",
    "3. **Result:** ~1,272 Thai tokens are dead by construction + ~2,384 other dead tokens (CJK, symbols, etc.)\n",
    "\n",
    "This gives us:\n",
    "- **6,301 live tokens** (63%) that receive gradient updates\n",
    "- **3,699 dead tokens** (37%) that should stay frozen near initialization\n",
    "\n",
    "## Why Flannel?\n",
    "\n",
    "We want to understand how the \"spongecrystal\" formed in Qwen 3 4B—a dense cluster of 2,100 Thai tokens, many collapsed to identical vectors. \n",
    "\n",
    "**Hypothesis:** Dead tokens (never trained) experience only thermal jitter and may cluster at lattice scale due to bfloat16 quantization.\n",
    "\n",
    "**Flannel tests this** by creating dead tokens we can track from initialization through training.\n",
    "\n",
    "## Flannel 1 Parameters\n",
    "\n",
    "**Baseline run:**\n",
    "- **1,000 training steps** (~3 epochs through corpus)\n",
    "- **Batch size: 32** (test M4 Pro performance)\n",
    "- **Record every step** (full trajectory data)\n",
    "- Same architecture as Wordybird/Lil Gatsby: 2 layers, 2 heads, 64D\n",
    "- bfloat16-native training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Parameters set\n"
     ]
    }
   ],
   "source": [
    "# Model architecture\n",
    "VOCAB_SIZE = 10000  # Flannel\n",
    "HIDDEN_DIM = 64\n",
    "N_LAYER = 2\n",
    "N_HEAD = 2\n",
    "MAX_SEQ_LEN = 128\n",
    "\n",
    "# Training\n",
    "BATCH_SIZE = 32\n",
    "NUM_TRAIN_STEPS = 1000\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 0.0\n",
    "\n",
    "# Optimizer: Adam\n",
    "ADAM_BETA1 = 0.9\n",
    "ADAM_BETA2 = 0.999\n",
    "ADAM_EPSILON = 1e-8\n",
    "\n",
    "# Initialization (bfloat16 native)\n",
    "INIT_SCALE = 0.02  # N(0, 0.02)\n",
    "\n",
    "# Data\n",
    "TOKENIZER_PATH = \"../data/flannel_tokenizer_chars.json\"\n",
    "CORPUS_PATH = \"../data/flannel_model_corpus.txt\"\n",
    "TOKEN_MASK_PATH = \"../tensors/Flannel/live_dead_tokens.safetensors\"\n",
    "OUTPUT_DIR = \"../tensors/Flannel\"\n",
    "OUTPUT_FILE = \"1.20a_flannel_1.safetensors\"\n",
    "\n",
    "# Instrumentation\n",
    "RECORD_EVERY_N_STEPS = 1  # Record every step\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(\"✓ Parameters set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports complete\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments\n",
    "from tokenizers import Tokenizer\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from safetensors.torch import save_file, load_file\n",
    "import time\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "\n",
    "print(\"✓ Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Device Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = 'mps'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Flannel tokenizer: ../data/flannel_tokenizer_chars.json\n",
      "\n",
      "✓ Loaded Flannel tokenizer\n",
      "  Vocabulary size: 10,000 tokens\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loading Flannel tokenizer: {TOKENIZER_PATH}\\n\")\n",
    "\n",
    "tokenizer = Tokenizer.from_file(str(TOKENIZER_PATH))\n",
    "vocab = tokenizer.get_vocab()\n",
    "\n",
    "print(f\"✓ Loaded Flannel tokenizer\")\n",
    "print(f\"  Vocabulary size: {len(vocab):,} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Corpus and Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading corpus: ../data/flannel_model_corpus.txt\n",
      "\n",
      "✓ Loaded corpus\n",
      "  Size: 5.01 MB\n",
      "  Characters: 5,225,690\n",
      "\n",
      "Tokenizing corpus...\n",
      "\n",
      "✓ Tokenized\n",
      "  Tokens: 1,371,328\n",
      "\n",
      "Training coverage:\n",
      "  Tokens per step: 4,096\n",
      "  Steps per epoch: 334.8\n",
      "  Expected epochs in 1,000 steps: 2.99\n",
      "\n",
      "✓ Corpus on device: mps\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoading corpus: {CORPUS_PATH}\\n\")\n",
    "\n",
    "with open(CORPUS_PATH, 'r', encoding='utf-8') as f:\n",
    "    corpus_text = f.read()\n",
    "\n",
    "corpus_bytes = len(corpus_text.encode('utf-8'))\n",
    "corpus_mb = corpus_bytes / (1024 * 1024)\n",
    "\n",
    "print(f\"✓ Loaded corpus\")\n",
    "print(f\"  Size: {corpus_mb:.2f} MB\")\n",
    "print(f\"  Characters: {len(corpus_text):,}\")\n",
    "print()\n",
    "\n",
    "# Tokenize\n",
    "print(\"Tokenizing corpus...\\n\")\n",
    "encoding = tokenizer.encode(corpus_text)\n",
    "tokens = encoding.ids\n",
    "\n",
    "print(f\"✓ Tokenized\")\n",
    "print(f\"  Tokens: {len(tokens):,}\")\n",
    "print()\n",
    "\n",
    "# Calculate expected epochs\n",
    "tokens_per_step = BATCH_SIZE * MAX_SEQ_LEN\n",
    "steps_per_epoch = len(tokens) / tokens_per_step\n",
    "expected_epochs = NUM_TRAIN_STEPS / steps_per_epoch\n",
    "\n",
    "print(f\"Training coverage:\")\n",
    "print(f\"  Tokens per step: {tokens_per_step:,}\")\n",
    "print(f\"  Steps per epoch: {steps_per_epoch:.1f}\")\n",
    "print(f\"  Expected epochs in {NUM_TRAIN_STEPS:,} steps: {expected_epochs:.2f}\")\n",
    "print()\n",
    "\n",
    "# Pre-load to device\n",
    "corpus_tensor = torch.tensor(tokens, dtype=torch.long, device=device)\n",
    "print(f\"✓ Corpus on device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Token Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading token masks: ../tensors/Flannel/live_dead_tokens.safetensors\n",
      "\n",
      "✓ Loaded token masks\n",
      "  Live tokens: 6,301 (63.0%)\n",
      "  Dead tokens: 3,699 (37.0%)\n",
      "\n",
      "Live token frequency:\n",
      "  Min occurrences: 1\n",
      "  Max occurrences: 45,630\n",
      "  Mean occurrences: 217.6\n",
      "  Median occurrences: 68\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoading token masks: {TOKEN_MASK_PATH}\\n\")\n",
    "\n",
    "mask_data = load_file(TOKEN_MASK_PATH)\n",
    "live_mask = mask_data['live_mask']\n",
    "dead_mask = mask_data['dead_mask']\n",
    "live_indices = mask_data['live_indices']\n",
    "dead_indices = mask_data['dead_indices']\n",
    "token_occurrence_counts = mask_data['token_occurrence_counts']\n",
    "\n",
    "n_live = live_mask.sum().item()\n",
    "n_dead = dead_mask.sum().item()\n",
    "\n",
    "print(f\"✓ Loaded token masks\")\n",
    "print(f\"  Live tokens: {n_live:,} ({100*n_live/VOCAB_SIZE:.1f}%)\")\n",
    "print(f\"  Dead tokens: {n_dead:,} ({100*n_dead/VOCAB_SIZE:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# Token frequency stats for live tokens\n",
    "live_counts = token_occurrence_counts[live_indices]\n",
    "print(f\"Live token frequency:\")\n",
    "print(f\"  Min occurrences: {live_counts.min().item():,}\")\n",
    "print(f\"  Max occurrences: {live_counts.max().item():,}\")\n",
    "print(f\"  Mean occurrences: {live_counts.float().mean().item():.1f}\")\n",
    "print(f\"  Median occurrences: {live_counts.float().median().item():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Dataset: 1,371,200 examples\n"
     ]
    }
   ],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, corpus_tensor, max_seq_len):\n",
    "        self.corpus = corpus_tensor\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(0, len(self.corpus) - self.max_seq_len)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        chunk = self.corpus[idx : idx + self.max_seq_len + 1]\n",
    "        return {\n",
    "            'input_ids': chunk[:-1],\n",
    "            'labels': chunk[1:]\n",
    "        }\n",
    "\n",
    "dataset = TokenDataset(corpus_tensor, MAX_SEQ_LEN)\n",
    "print(f\"\\n✓ Dataset: {len(dataset):,} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating model...\n",
      "\n",
      "✓ Model created\n",
      "  Total parameters: 748,288\n",
      "  Embedding parameters (E+W): 640,000\n",
      "  Other parameters: 108,288\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nCreating model...\\n\")\n",
    "\n",
    "config = GPT2Config(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    n_positions=MAX_SEQ_LEN,\n",
    "    n_embd=HIDDEN_DIM,\n",
    "    n_layer=N_LAYER,\n",
    "    n_head=N_HEAD,\n",
    "    resid_pdrop=0.0,\n",
    "    embd_pdrop=0.0,\n",
    "    attn_pdrop=0.0,\n",
    "    tie_word_embeddings=True,\n",
    ")\n",
    "\n",
    "model = GPT2LMHeadModel(config)\n",
    "model = model.to(torch.bfloat16).to(device)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "embedding_params = model.transformer.wte.weight.numel()\n",
    "\n",
    "print(f\"✓ Model created\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Embedding parameters (E+W): {embedding_params:,}\")\n",
    "print(f\"  Other parameters: {total_params - embedding_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization (bfloat16 Native)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "INITIALIZING: N(0, 0.02) bfloat16-native\n",
      "================================================================================\n",
      "\n",
      "Initialization: N(0, 0.02)\n",
      "  Shape: torch.Size([10000, 64])\n",
      "  Each token initialized independently\n",
      "\n",
      "✓ Initialized embeddings (pure bfloat16)\n",
      "  Shape: torch.Size([10000, 64])\n",
      "  Dtype: torch.bfloat16\n",
      "\n",
      "Initial dead token statistics (3,699 tokens):\n",
      "  Centroid norm: 0.002689\n",
      "  Mean radius from centroid: 0.159301\n",
      "  Max radius from centroid: 0.206368\n",
      "  Bounding hypersphere volume ∝ R^64 = 1.37e-44\n",
      "\n",
      "  ✓ Dead tokens distributed in hypersphere (standard init)\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"INITIALIZING: N(0, {INIT_SCALE}) bfloat16-native\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "# Standard GPT-2 init: each embedding drawn independently from N(0, 0.02)\n",
    "# Generate in float32, immediately convert to bfloat16\n",
    "init_f32 = torch.randn(VOCAB_SIZE, HIDDEN_DIM, dtype=torch.float32, device=device) * INIT_SCALE\n",
    "init_bf16 = init_f32.to(torch.bfloat16)\n",
    "\n",
    "print(f\"Initialization: N(0, {INIT_SCALE})\")\n",
    "print(f\"  Shape: {init_bf16.shape}\")\n",
    "print(f\"  Each token initialized independently\")\n",
    "print()\n",
    "\n",
    "# Assign to model\n",
    "with torch.no_grad():\n",
    "    model.transformer.wte.weight[:] = init_bf16\n",
    "\n",
    "print(f\"✓ Initialized embeddings (pure bfloat16)\")\n",
    "print(f\"  Shape: {model.transformer.wte.weight.shape}\")\n",
    "print(f\"  Dtype: {model.transformer.wte.weight.dtype}\")\n",
    "print()\n",
    "\n",
    "# Verify initialization stats for dead tokens\n",
    "W_check = model.transformer.wte.weight.cpu().float()\n",
    "W_dead = W_check[dead_indices]\n",
    "\n",
    "centroid = W_dead.mean(dim=0)\n",
    "centroid_norm = torch.norm(centroid).item()\n",
    "radii = torch.norm(W_dead - centroid, dim=1)\n",
    "mean_radius = radii.mean().item()\n",
    "max_radius = radii.max().item()\n",
    "\n",
    "print(f\"Initial dead token statistics ({n_dead:,} tokens):\")\n",
    "print(f\"  Centroid norm: {centroid_norm:.6f}\")\n",
    "print(f\"  Mean radius from centroid: {mean_radius:.6f}\")\n",
    "print(f\"  Max radius from centroid: {max_radius:.6f}\")\n",
    "print(f\"  Bounding hypersphere volume ∝ R^{HIDDEN_DIM} = {max_radius**HIDDEN_DIM:.2e}\")\n",
    "print()\n",
    "print(f\"  ✓ Dead tokens distributed in hypersphere (standard init)\")\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Recorder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Recorder class defined\n"
     ]
    }
   ],
   "source": [
    "class ComprehensiveRecorder:\n",
    "    \"\"\"Records embeddings, gradients, optimizer state, logits, loss at every step in bfloat16.\"\"\"\n",
    "    \n",
    "    def __init__(self, vocab_size, hidden_dim, record_every_n):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.record_every_n = record_every_n\n",
    "        \n",
    "        # Storage (lists of tensors, keep in RAM)\n",
    "        self.recorded_steps = []\n",
    "        self.embeddings = []      # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.grads = []           # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.momentum = []        # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.variance = []        # [n_recorded, vocab_size, hidden_dim]\n",
    "        self.logits = []          # [n_recorded, vocab_size]\n",
    "        self.losses = []          # [n_recorded]\n",
    "        \n",
    "        # Temporary storage\n",
    "        self.current_step = 0\n",
    "        self.recorded_initial = False\n",
    "        self.grad_before = None\n",
    "        self.loss_value = None\n",
    "        self.logits_sample = None\n",
    "    \n",
    "    def record_initial_state(self, model, optimizer):\n",
    "        \"\"\"Record step 0: initial state before training.\"\"\"\n",
    "        if not self.recorded_initial:\n",
    "            W = model.transformer.wte.weight.data.clone().cpu().bfloat16()\n",
    "            \n",
    "            # Step 0: no gradients, no optimizer state yet (zeros)\n",
    "            self.recorded_steps.append(0)\n",
    "            self.embeddings.append(W)\n",
    "            self.grads.append(torch.zeros_like(W))\n",
    "            self.momentum.append(torch.zeros_like(W))\n",
    "            self.variance.append(torch.zeros_like(W))\n",
    "            self.logits.append(torch.zeros(self.vocab_size, dtype=torch.bfloat16))\n",
    "            self.losses.append(torch.tensor(float('nan'), dtype=torch.bfloat16))  # No loss yet\n",
    "            \n",
    "            self.recorded_initial = True\n",
    "            self.current_step = 1\n",
    "            \n",
    "            print(f\"✓ Recorded initial state (step 0)\")\n",
    "    \n",
    "    def record_before_step(self, model, loss, logits):\n",
    "        \"\"\"Call after forward/backward, before optimizer step.\"\"\"\n",
    "        if self.current_step % self.record_every_n == 0:\n",
    "            # Capture gradients in bfloat16\n",
    "            if model.transformer.wte.weight.grad is not None:\n",
    "                self.grad_before = model.transformer.wte.weight.grad.clone().cpu().bfloat16()\n",
    "            else:\n",
    "                self.grad_before = torch.zeros(self.vocab_size, self.hidden_dim, dtype=torch.bfloat16)\n",
    "            \n",
    "            # Capture loss\n",
    "            self.loss_value = loss.item()\n",
    "            \n",
    "            # Capture logits from first sequence, last position in bfloat16\n",
    "            self.logits_sample = logits[0, -1, :].detach().cpu().bfloat16()\n",
    "    \n",
    "    def record_after_step(self, model, optimizer):\n",
    "        \"\"\"Call after optimizer step.\"\"\"\n",
    "        if self.current_step % self.record_every_n == 0:\n",
    "            if self.grad_before is not None and self.loss_value is not None:\n",
    "                # Capture embeddings in bfloat16\n",
    "                W = model.transformer.wte.weight.data.clone().cpu().bfloat16()\n",
    "\n",
    "                # Capture optimizer state (Adam momentum and variance)\n",
    "                param = model.transformer.wte.weight\n",
    "                if param in optimizer.state:\n",
    "                    state = optimizer.state[param]\n",
    "                    # Get state tensors if they exist, convert to bfloat16\n",
    "                    mom_src = state.get('exp_avg', None)\n",
    "                    var_src = state.get('exp_avg_sq', None)\n",
    "                    mom = mom_src.clone().cpu().bfloat16() if mom_src is not None else torch.zeros_like(W)\n",
    "                    var = var_src.clone().cpu().bfloat16() if var_src is not None else torch.zeros_like(W)\n",
    "                else:\n",
    "                    mom = torch.zeros_like(W)\n",
    "                    var = torch.zeros_like(W)\n",
    "\n",
    "                # Store everything\n",
    "                self.recorded_steps.append(self.current_step)\n",
    "                self.embeddings.append(W)\n",
    "                self.grads.append(self.grad_before)\n",
    "                self.momentum.append(mom)\n",
    "                self.variance.append(var)\n",
    "                self.logits.append(self.logits_sample)\n",
    "                self.losses.append(torch.tensor(self.loss_value, dtype=torch.bfloat16))\n",
    "\n",
    "                # Clear temp storage\n",
    "                self.grad_before = None\n",
    "                self.loss_value = None\n",
    "                self.logits_sample = None\n",
    "                \n",
    "                # Progress indicator every 50 steps\n",
    "                if self.current_step % 50 == 0:\n",
    "                    print(f\"  Recorded step {self.current_step}\")\n",
    "\n",
    "        self.current_step += 1\n",
    "    \n",
    "    def get_data(self):\n",
    "        \"\"\"Return recorded data as stacked tensors.\"\"\"\n",
    "        print(f\"\\nStacking {len(self.embeddings)} recorded states...\")\n",
    "        \n",
    "        return {\n",
    "            'recorded_steps': torch.tensor(self.recorded_steps, dtype=torch.long),\n",
    "            'embeddings': torch.stack(self.embeddings) if self.embeddings else torch.tensor([]),\n",
    "            'grads': torch.stack(self.grads) if self.grads else torch.tensor([]),\n",
    "            'momentum': torch.stack(self.momentum) if self.momentum else torch.tensor([]),\n",
    "            'variance': torch.stack(self.variance) if self.variance else torch.tensor([]),\n",
    "            'logits': torch.stack(self.logits) if self.logits else torch.tensor([]),\n",
    "            'losses': torch.stack(self.losses) if self.losses else torch.tensor([]),\n",
    "        }\n",
    "\n",
    "print(\"✓ Recorder class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Trainer with Instrumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ InstrumentedTrainer defined\n"
     ]
    }
   ],
   "source": [
    "class InstrumentedTrainer(Trainer):\n",
    "    def __init__(self, recorder, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.recorder = recorder\n",
    "        self.last_logits = None\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"Override to capture logits.\"\"\"\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        \n",
    "        # Store logits for recorder\n",
    "        self.last_logits = outputs.logits\n",
    "        \n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    def training_step(self, model, inputs, num_items_in_batch=None):\n",
    "        \"\"\"Override to inject recording.\"\"\"\n",
    "        # Standard forward + backward\n",
    "        loss = super().training_step(model, inputs, num_items_in_batch)\n",
    "        \n",
    "        # Record BEFORE optimizer step\n",
    "        self.recorder.record_before_step(model, loss, self.last_logits)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def _maybe_log_save_evaluate(self, tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time=None, **kwargs):\n",
    "        \"\"\"Override to record AFTER optimizer step.\"\"\"\n",
    "        # Record AFTER optimizer updates parameters\n",
    "        self.recorder.record_after_step(model, self.optimizer)\n",
    "        \n",
    "        # Call parent\n",
    "        super()._maybe_log_save_evaluate(tr_loss, grad_norm, model, trial, epoch, ignore_keys_for_eval, start_time, **kwargs)\n",
    "\n",
    "print(\"✓ InstrumentedTrainer defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Trainer ready (Adam, bf16=True, batch_size=32)\n"
     ]
    }
   ],
   "source": [
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "recorder = ComprehensiveRecorder(VOCAB_SIZE, HIDDEN_DIM, RECORD_EVERY_N_STEPS)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_steps=NUM_TRAIN_STEPS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    adam_beta1=ADAM_BETA1,\n",
    "    adam_beta2=ADAM_BETA2,\n",
    "    adam_epsilon=ADAM_EPSILON,\n",
    "    optim=\"adamw_torch\",\n",
    "    logging_steps=50,\n",
    "    save_steps=NUM_TRAIN_STEPS + 1,  # Don't save checkpoints\n",
    "    save_total_limit=0,\n",
    "    dataloader_num_workers=0,\n",
    "    dataloader_pin_memory=False,\n",
    "    bf16=True,  # Native bfloat16 training\n",
    "    seed=RANDOM_SEED,\n",
    "    report_to=\"none\",\n",
    "    disable_tqdm=False,\n",
    ")\n",
    "\n",
    "trainer = InstrumentedTrainer(\n",
    "    recorder=recorder,\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset,\n",
    ")\n",
    "\n",
    "print(f\"\\n✓ Trainer ready (Adam, bf16=True, batch_size={BATCH_SIZE})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Record Initial State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Recorded initial state (step 0)\n"
     ]
    }
   ],
   "source": [
    "print()\n",
    "recorder.record_initial_state(model, trainer.optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "\n",
    "**1,000 steps should take ~2-3 minutes on M4 Pro.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "STARTING FLANNEL 1 TRAINING\n",
      "================================================================================\n",
      "\n",
      "Configuration:\n",
      "  Vocabulary: 10,000 tokens (Flannel)\n",
      "  Hidden dim: 64\n",
      "  Live tokens: 6,301 (63.0%)\n",
      "  Dead tokens: 3,699 (37.0%)\n",
      "\n",
      "  Initialization: N(0, 0.02) bfloat16-native\n",
      "  Optimizer: Adam (lr=0.001)\n",
      "  Precision: bfloat16 (native)\n",
      "  Batch size: 32\n",
      "  Steps: 1,000 (~3.0 epochs)\n",
      "  Recording: every step\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 00:26, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>8.040500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>7.156500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>7.115300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>7.105200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>7.108500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>7.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>7.096400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>7.090100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>7.087300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>7.075500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>7.072300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>7.077400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>7.081800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>7.060300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>7.071900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>7.057900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>7.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>7.051100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>7.047000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>7.056000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Recorded step 50\n",
      "  Recorded step 100\n",
      "  Recorded step 150\n",
      "  Recorded step 200\n",
      "  Recorded step 250\n",
      "  Recorded step 300\n",
      "  Recorded step 350\n",
      "  Recorded step 400\n",
      "  Recorded step 450\n",
      "  Recorded step 500\n",
      "  Recorded step 550\n",
      "  Recorded step 600\n",
      "  Recorded step 650\n",
      "  Recorded step 700\n",
      "  Recorded step 750\n",
      "  Recorded step 800\n",
      "  Recorded step 850\n",
      "  Recorded step 900\n",
      "  Recorded step 950\n",
      "  Recorded step 1000\n",
      "\n",
      "================================================================================\n",
      "✓ Training complete\n",
      "  Elapsed time: 26.7 seconds (0.4 minutes)\n",
      "  Throughput: 37.4 steps/second\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"STARTING FLANNEL 1 TRAINING\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\nConfiguration:\")\n",
    "print(f\"  Vocabulary: {VOCAB_SIZE:,} tokens (Flannel)\")\n",
    "print(f\"  Hidden dim: {HIDDEN_DIM}\")\n",
    "print(f\"  Live tokens: {n_live:,} ({100*n_live/VOCAB_SIZE:.1f}%)\")\n",
    "print(f\"  Dead tokens: {n_dead:,} ({100*n_dead/VOCAB_SIZE:.1f}%)\")\n",
    "print()\n",
    "print(f\"  Initialization: N(0, {INIT_SCALE}) bfloat16-native\")\n",
    "print(f\"  Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "print(f\"  Precision: bfloat16 (native)\")\n",
    "print(f\"  Batch size: {BATCH_SIZE}\")\n",
    "print(f\"  Steps: {NUM_TRAIN_STEPS:,} (~{expected_epochs:.1f} epochs)\")\n",
    "print(f\"  Recording: every step\")\n",
    "print(f\"\\n{'='*80}\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "trainer.train()\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"✓ Training complete\")\n",
    "print(f\"  Elapsed time: {elapsed:.1f} seconds ({elapsed/60:.1f} minutes)\")\n",
    "print(f\"  Throughput: {NUM_TRAIN_STEPS / elapsed:.1f} steps/second\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Recorded Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preparing data for save...\n",
      "\n",
      "\n",
      "Stacking 1001 recorded states...\n",
      "Saving to: ../tensors/Flannel/1.20a_flannel_1.safetensors\n",
      "\n",
      "✓ Saved successfully\n",
      "  File: ../tensors/Flannel/1.20a_flannel_1.safetensors\n",
      "  Size: 5145.2 MB\n",
      "  Save time: 18.4 seconds\n",
      "  Recorded steps: 1001\n",
      "  Step range: 0 to 1000\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nPreparing data for save...\\n\")\n",
    "\n",
    "recorded_data = recorder.get_data()\n",
    "\n",
    "save_dict = {\n",
    "    'recorded_steps': recorded_data['recorded_steps'],\n",
    "    'embeddings': recorded_data['embeddings'],\n",
    "    'grads': recorded_data['grads'],\n",
    "    'momentum': recorded_data['momentum'],\n",
    "    'variance': recorded_data['variance'],\n",
    "    'logits': recorded_data['logits'],\n",
    "    'losses': recorded_data['losses'],\n",
    "    # Metadata\n",
    "    'init_scale': torch.tensor(INIT_SCALE, dtype=torch.float32),\n",
    "    'learning_rate': torch.tensor(LEARNING_RATE, dtype=torch.float32),\n",
    "    'weight_decay': torch.tensor(WEIGHT_DECAY, dtype=torch.float32),\n",
    "    'adam_beta1': torch.tensor(ADAM_BETA1, dtype=torch.float32),\n",
    "    'adam_beta2': torch.tensor(ADAM_BETA2, dtype=torch.float32),\n",
    "    'n_live': torch.tensor(n_live, dtype=torch.long),\n",
    "    'n_dead': torch.tensor(n_dead, dtype=torch.long),\n",
    "}\n",
    "\n",
    "output_path = Path(OUTPUT_DIR) / OUTPUT_FILE\n",
    "\n",
    "print(f\"Saving to: {output_path}\")\n",
    "\n",
    "save_start = time.time()\n",
    "save_file(save_dict, str(output_path))\n",
    "save_elapsed = time.time() - save_start\n",
    "\n",
    "file_size_mb = output_path.stat().st_size / 1e6\n",
    "\n",
    "print(f\"\\n✓ Saved successfully\")\n",
    "print(f\"  File: {output_path}\")\n",
    "print(f\"  Size: {file_size_mb:.1f} MB\")\n",
    "print(f\"  Save time: {save_elapsed:.1f} seconds\")\n",
    "print(f\"  Recorded steps: {len(recorded_data['recorded_steps'])}\")\n",
    "print(f\"  Step range: {recorded_data['recorded_steps'][0]} to {recorded_data['recorded_steps'][-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "QUICK VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "Data shapes:\n",
      "  embeddings: torch.Size([1001, 10000, 64])\n",
      "  losses: torch.Size([1001])\n",
      "\n",
      "Dead token displacement (steps 0 → 1000):\n",
      "  Max: 5.66e-01\n",
      "  Mean: 5.05e-01\n",
      "  Median: 5.04e-01\n",
      "\n",
      "Live token displacement (steps 0 → 1000):\n",
      "  Max: 6.22e-01\n",
      "  Mean: 1.82e-01\n",
      "  Median: 1.70e-01\n",
      "\n",
      "Loss trajectory:\n",
      "  Step 1: 9.2500\n",
      "  Step 1000: 6.9688\n",
      "  Reduction: 2.2812\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"QUICK VERIFICATION\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "embeddings = recorded_data['embeddings']\n",
    "losses = recorded_data['losses']\n",
    "\n",
    "print(f\"Data shapes:\")\n",
    "print(f\"  embeddings: {embeddings.shape}\")\n",
    "print(f\"  losses: {losses.shape}\")\n",
    "print()\n",
    "\n",
    "# Analyze dead token movement\n",
    "W_step0 = embeddings[0, dead_indices].float()\n",
    "W_step1000 = embeddings[-1, dead_indices].float()\n",
    "\n",
    "# Compute displacements\n",
    "displacements = torch.norm(W_step1000 - W_step0, dim=1)\n",
    "max_displacement = displacements.max().item()\n",
    "mean_displacement = displacements.mean().item()\n",
    "median_displacement = displacements.median().item()\n",
    "\n",
    "print(f\"Dead token displacement (steps 0 → {NUM_TRAIN_STEPS}):\")\n",
    "print(f\"  Max: {max_displacement:.2e}\")\n",
    "print(f\"  Mean: {mean_displacement:.2e}\")\n",
    "print(f\"  Median: {median_displacement:.2e}\")\n",
    "print()\n",
    "\n",
    "# Compare to live tokens\n",
    "W_live_step0 = embeddings[0, live_indices].float()\n",
    "W_live_step1000 = embeddings[-1, live_indices].float()\n",
    "live_displacements = torch.norm(W_live_step1000 - W_live_step0, dim=1)\n",
    "\n",
    "print(f\"Live token displacement (steps 0 → {NUM_TRAIN_STEPS}):\")\n",
    "print(f\"  Max: {live_displacements.max().item():.2e}\")\n",
    "print(f\"  Mean: {live_displacements.mean().item():.2e}\")\n",
    "print(f\"  Median: {live_displacements.median().item():.2e}\")\n",
    "print()\n",
    "\n",
    "print(f\"Loss trajectory:\")\n",
    "print(f\"  Step 1: {losses[1].float().item():.4f}\")\n",
    "print(f\"  Step {NUM_TRAIN_STEPS}: {losses[-1].float().item():.4f}\")\n",
    "print(f\"  Reduction: {(losses[1].float() - losses[-1].float()).item():.4f}\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FLANNEL 1 COMPLETE\n",
      "================================================================================\n",
      "\n",
      "Experiment: Baseline 1,000-step run with engineered dead tokens\n",
      "  Tokenizer: Flannel (10k vocab, char-level BPE)\n",
      "  Corpus: 5MB English-only FineWeb\n",
      "  Training: 1,000 steps (~3.0 epochs)\n",
      "  Architecture: 2 layers, 2 heads, 64D, bfloat16-native\n",
      "\n",
      "Token demographics:\n",
      "  Live: 6,301 tokens (63.0%)\n",
      "  Dead: 3,699 tokens (37.0%)\n",
      "\n",
      "Data saved: ../tensors/Flannel/1.20a_flannel_1.safetensors\n",
      "Size: 5145.2 MB\n",
      "\n",
      "Next steps:\n",
      "  1. Run lattice hop detection (1.17b pattern)\n",
      "  2. Analyze dead token clustering\n",
      "  3. Look for spongecrystal formation\n",
      "  4. Compare to Wordybird dynamics\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"FLANNEL 1 COMPLETE\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "print(f\"Experiment: Baseline 1,000-step run with engineered dead tokens\")\n",
    "print(f\"  Tokenizer: Flannel (10k vocab, char-level BPE)\")\n",
    "print(f\"  Corpus: 5MB English-only FineWeb\")\n",
    "print(f\"  Training: {NUM_TRAIN_STEPS:,} steps (~{expected_epochs:.1f} epochs)\")\n",
    "print(f\"  Architecture: 2 layers, 2 heads, 64D, bfloat16-native\")\n",
    "print()\n",
    "print(f\"Token demographics:\")\n",
    "print(f\"  Live: {n_live:,} tokens ({100*n_live/VOCAB_SIZE:.1f}%)\")\n",
    "print(f\"  Dead: {n_dead:,} tokens ({100*n_dead/VOCAB_SIZE:.1f}%)\")\n",
    "print()\n",
    "print(f\"Data saved: {output_path}\")\n",
    "print(f\"Size: {file_size_mb:.1f} MB\")\n",
    "print()\n",
    "print(f\"Next steps:\")\n",
    "print(f\"  1. Run lattice hop detection (1.17b pattern)\")\n",
    "print(f\"  2. Analyze dead token clustering\")\n",
    "print(f\"  3. Look for spongecrystal formation\")\n",
    "print(f\"  4. Compare to Wordybird dynamics\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azimuth-ii",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
